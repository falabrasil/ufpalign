[92m[2021-10-23 07:41:29] run_data_prep.sh: gathering data from '/home/cassio/fb-gitlab/fb-audio-corpora/lapsbm16k'[0m
[92m[2021-10-23 07:41:29] run_data_prep.sh: copying lexicon from '/home/cassio/fb-github/lm-br/data/dict/lexicon.txt.gz'[0m
'/home/cassio/fb-github/lm-br/data/dict/lexicon.txt.gz' -> '/home/cassio/fb-gitlab/fb-audio-corpora/lapsbm16k/lexicon.txt.gz'
[93m[2021-10-23 07:41:29] run_data_prep.sh: copying LM small from '/home/cassio/fb-github/lm-br/data/dict/lexicon.txt.gz'[0m
'/home/cassio/fb-github/lm-br/data/lm/3-gram.1e-7.arpa.gz' -> '/home/cassio/fb-gitlab/fb-audio-corpora/lapsbm16k/3-gram.1e-7.arpa.gz'
[93m[2021-10-23 07:41:29] run_data_prep.sh: prep data[0m
fblocal/prep_data.sh: dataset will be random split. this might take a while... 
fblocal/prep_data.sh: creating train files:  000 001 002 003 004 005 006 007
fblocal/prep_data.sh: merging file 'text' for train dataset
fblocal/prep_data.sh: merging file 'wav.scp' for train dataset
fblocal/prep_data.sh: merging file 'utt2spk' for train dataset
fblocal/prep_data.sh: merging file 'spk2gender' for train dataset
fblocal/prep_data.sh: creating test files:  000 001 002 003 004 005 006 007
fblocal/prep_data.sh: merging file 'text' for test dataset
fblocal/prep_data.sh: merging file 'wav.scp' for test dataset
fblocal/prep_data.sh: merging file 'utt2spk' for test dataset
fblocal/prep_data.sh: merging file 'spk2gender' for test dataset
utils/validate_data_dir.sh: Successfully validated data-directory data//train
utils/validate_data_dir.sh: Successfully validated data-directory data//test
[94m[2021-10-23 07:41:38] run_data_prep.sh: prep dict[0m
fblocal/prep_dict.sh: adding UNK and SIL to lexicon.txt...
fblocal/prep_dict.sh: creating nonsilence_phones.txt file... 
fblocal/prep_dict.sh: creating silence_phones.txt file... 
fblocal/prep_dict.sh: creating optional_silence.txt file... 
[95m[2021-10-23 07:41:51] run_data_prep.sh: prep lang[0m
utils/prepare_lang.sh data/local/dict_nosp <UNK> data/local/lang_tmp_nosp/ data/lang_nosp/
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/extra_questions.txt ...
--> reading data/local/dict_nosp/extra_questions.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

**Creating data/local/dict_nosp/lexiconp.txt from data/local/dict_nosp/lexicon.txt
prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang_nosp/
Checking existence of separator file
separator file data/lang_nosp//subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_nosp//phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp//phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp//words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_nosp//phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang_nosp//phones/context_indep.txt
--> data/lang_nosp//phones/context_indep.int corresponds to data/lang_nosp//phones/context_indep.txt
--> data/lang_nosp//phones/context_indep.csl corresponds to data/lang_nosp//phones/context_indep.txt
--> data/lang_nosp//phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp//phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 152 entry/entries in data/lang_nosp//phones/nonsilence.txt
--> data/lang_nosp//phones/nonsilence.int corresponds to data/lang_nosp//phones/nonsilence.txt
--> data/lang_nosp//phones/nonsilence.csl corresponds to data/lang_nosp//phones/nonsilence.txt
--> data/lang_nosp//phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp//phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang_nosp//phones/silence.txt
--> data/lang_nosp//phones/silence.int corresponds to data/lang_nosp//phones/silence.txt
--> data/lang_nosp//phones/silence.csl corresponds to data/lang_nosp//phones/silence.txt
--> data/lang_nosp//phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp//phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp//phones/optional_silence.txt
--> data/lang_nosp//phones/optional_silence.int corresponds to data/lang_nosp//phones/optional_silence.txt
--> data/lang_nosp//phones/optional_silence.csl corresponds to data/lang_nosp//phones/optional_silence.txt
--> data/lang_nosp//phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp//phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 11 entry/entries in data/lang_nosp//phones/disambig.txt
--> data/lang_nosp//phones/disambig.int corresponds to data/lang_nosp//phones/disambig.txt
--> data/lang_nosp//phones/disambig.csl corresponds to data/lang_nosp//phones/disambig.txt
--> data/lang_nosp//phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp//phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in data/lang_nosp//phones/roots.txt
--> data/lang_nosp//phones/roots.int corresponds to data/lang_nosp//phones/roots.txt
--> data/lang_nosp//phones/roots.{txt, int} are OK

Checking data/lang_nosp//phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in data/lang_nosp//phones/sets.txt
--> data/lang_nosp//phones/sets.int corresponds to data/lang_nosp//phones/sets.txt
--> data/lang_nosp//phones/sets.{txt, int} are OK

Checking data/lang_nosp//phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang_nosp//phones/extra_questions.txt
--> data/lang_nosp//phones/extra_questions.int corresponds to data/lang_nosp//phones/extra_questions.txt
--> data/lang_nosp//phones/extra_questions.{txt, int} are OK

Checking data/lang_nosp//phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 162 entry/entries in data/lang_nosp//phones/word_boundary.txt
--> data/lang_nosp//phones/word_boundary.int corresponds to data/lang_nosp//phones/word_boundary.txt
--> data/lang_nosp//phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp//phones/optional_silence.txt
--> data/lang_nosp//phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp//phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp//phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_nosp//phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_nosp//phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_nosp//phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_nosp//phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 56 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 33 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_nosp//oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp//oov.txt
--> data/lang_nosp//oov.int corresponds to data/lang_nosp//oov.txt
--> data/lang_nosp//oov.{txt, int} are OK

--> data/lang_nosp//L.fst is olabel sorted
--> data/lang_nosp//L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang_nosp/]
[91m[2021-10-23 07:42:16] run_data_prep.sh: format lms[0m
utils/validate_lang.pl data/lang_nosp_test_tgsmall
Checking existence of separator file
separator file data/lang_nosp_test_tgsmall/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_nosp_test_tgsmall/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp_test_tgsmall/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp_test_tgsmall/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_nosp_test_tgsmall/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang_nosp_test_tgsmall/phones/context_indep.txt
--> data/lang_nosp_test_tgsmall/phones/context_indep.int corresponds to data/lang_nosp_test_tgsmall/phones/context_indep.txt
--> data/lang_nosp_test_tgsmall/phones/context_indep.csl corresponds to data/lang_nosp_test_tgsmall/phones/context_indep.txt
--> data/lang_nosp_test_tgsmall/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgsmall/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 152 entry/entries in data/lang_nosp_test_tgsmall/phones/nonsilence.txt
--> data/lang_nosp_test_tgsmall/phones/nonsilence.int corresponds to data/lang_nosp_test_tgsmall/phones/nonsilence.txt
--> data/lang_nosp_test_tgsmall/phones/nonsilence.csl corresponds to data/lang_nosp_test_tgsmall/phones/nonsilence.txt
--> data/lang_nosp_test_tgsmall/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgsmall/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang_nosp_test_tgsmall/phones/silence.txt
--> data/lang_nosp_test_tgsmall/phones/silence.int corresponds to data/lang_nosp_test_tgsmall/phones/silence.txt
--> data/lang_nosp_test_tgsmall/phones/silence.csl corresponds to data/lang_nosp_test_tgsmall/phones/silence.txt
--> data/lang_nosp_test_tgsmall/phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgsmall/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp_test_tgsmall/phones/optional_silence.txt
--> data/lang_nosp_test_tgsmall/phones/optional_silence.int corresponds to data/lang_nosp_test_tgsmall/phones/optional_silence.txt
--> data/lang_nosp_test_tgsmall/phones/optional_silence.csl corresponds to data/lang_nosp_test_tgsmall/phones/optional_silence.txt
--> data/lang_nosp_test_tgsmall/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgsmall/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 11 entry/entries in data/lang_nosp_test_tgsmall/phones/disambig.txt
--> data/lang_nosp_test_tgsmall/phones/disambig.int corresponds to data/lang_nosp_test_tgsmall/phones/disambig.txt
--> data/lang_nosp_test_tgsmall/phones/disambig.csl corresponds to data/lang_nosp_test_tgsmall/phones/disambig.txt
--> data/lang_nosp_test_tgsmall/phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgsmall/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in data/lang_nosp_test_tgsmall/phones/roots.txt
--> data/lang_nosp_test_tgsmall/phones/roots.int corresponds to data/lang_nosp_test_tgsmall/phones/roots.txt
--> data/lang_nosp_test_tgsmall/phones/roots.{txt, int} are OK

Checking data/lang_nosp_test_tgsmall/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in data/lang_nosp_test_tgsmall/phones/sets.txt
--> data/lang_nosp_test_tgsmall/phones/sets.int corresponds to data/lang_nosp_test_tgsmall/phones/sets.txt
--> data/lang_nosp_test_tgsmall/phones/sets.{txt, int} are OK

Checking data/lang_nosp_test_tgsmall/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang_nosp_test_tgsmall/phones/extra_questions.txt
--> data/lang_nosp_test_tgsmall/phones/extra_questions.int corresponds to data/lang_nosp_test_tgsmall/phones/extra_questions.txt
--> data/lang_nosp_test_tgsmall/phones/extra_questions.{txt, int} are OK

Checking data/lang_nosp_test_tgsmall/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 162 entry/entries in data/lang_nosp_test_tgsmall/phones/word_boundary.txt
--> data/lang_nosp_test_tgsmall/phones/word_boundary.int corresponds to data/lang_nosp_test_tgsmall/phones/word_boundary.txt
--> data/lang_nosp_test_tgsmall/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp_test_tgsmall/phones/optional_silence.txt
--> data/lang_nosp_test_tgsmall/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp_test_tgsmall/phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp_test_tgsmall/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_nosp_test_tgsmall/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_nosp_test_tgsmall/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_nosp_test_tgsmall/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_nosp_test_tgsmall/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 19 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 75 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_nosp_test_tgsmall/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp_test_tgsmall/oov.txt
--> data/lang_nosp_test_tgsmall/oov.int corresponds to data/lang_nosp_test_tgsmall/oov.txt
--> data/lang_nosp_test_tgsmall/oov.{txt, int} are OK

--> data/lang_nosp_test_tgsmall/L.fst is olabel sorted
--> data/lang_nosp_test_tgsmall/L_disambig.fst is olabel sorted
--> data/lang_nosp_test_tgsmall/G.fst is ilabel sorted
--> data/lang_nosp_test_tgsmall/G.fst has 469437 states
--> utils/lang/check_g_properties.pl successfully validated data/lang_nosp_test_tgsmall/G.fst
--> utils/lang/check_g_properties.pl succeeded.
--> SUCCESS [validating lang directory data/lang_nosp_test_tgsmall]
Succeeded in formatting data.
[96m[2021-10-23 07:42:35] run_data_prep.sh: data preparation successfully finished![0m
[91m[2021-10-23 07:42:35] run_gmm.sh: computing mfcc + cmvn[0m
steps/make_mfcc.sh --cmd run.pl --mem 2G --nj 8 data/train exp/make_mfcc/train mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for train
steps/compute_cmvn_stats.sh data/train exp/make_mfcc/train mfcc
Succeeded creating CMVN stats for train
steps/make_mfcc.sh --cmd run.pl --mem 2G --nj 8 data/test exp/make_mfcc/test mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/test
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for test
steps/compute_cmvn_stats.sh data/test exp/make_mfcc/test mfcc
Succeeded creating CMVN stats for test
[93m[2021-10-23 07:42:36] run_gmm.sh: training monophones[0m
steps/train_mono.sh --boost-silence 1.25 --nj 8 --cmd run.pl --mem 2G data/train data/lang_nosp exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/mono
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono/log/analyze_alignments.log
38 warnings in exp/mono/log/update.*.log
455 warnings in exp/mono/log/align.*.*.log
exp/mono: nj=8 align prob=-89.33 over 0.81h [retry=0.8%, fail=0.0%] states=124 gauss=996
steps/train_mono.sh: Done training monophone system in exp/mono
[95m[2021-10-23 07:42:57] run_gmm.sh: compiling mono graph (in bg)[0m
[95m[2021-10-23 07:42:57] run_gmm.sh: aligning monophones[0m
steps/align_si.sh --boost-silence 1.25 --nj 8 --cmd run.pl --mem 2G data/train data/lang_nosp exp/mono exp/mono_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/mono, putting alignments in exp/mono_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/mono_ali
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ali/log/analyze_alignments.log
steps/align_si.sh: done aligning data.
[96m[2021-10-23 07:42:59] run_gmm.sh: training tri-deltas[0m
steps/train_deltas.sh --boost-silence 1.25 --cmd run.pl --mem 2G 2000 10000 data/train data/lang_nosp exp/mono_ali exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/mono_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri1
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1/log/analyze_alignments.log
1 warnings in exp/tri1/log/build_tree.log
27 warnings in exp/tri1/log/align.*.*.log
72 warnings in exp/tri1/log/init_model.log
148 warnings in exp/tri1/log/update.*.log
exp/tri1: nj=8 align prob=-84.45 over 0.81h [retry=0.0%, fail=0.0%] states=640 gauss=10048 tree-impr=4.20
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
[95m[2021-10-23 07:43:15] run_gmm.sh: compiling tri-deltas graph (in bg)[0m
[96m[2021-10-23 07:43:15] run_gmm.sh: aligning triphones[0m
steps/align_si.sh --nj 8 --cmd run.pl --mem 2G data/train data/lang_nosp exp/tri1 exp/tri1_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri1, putting alignments in exp/tri1_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri1_ali
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1_ali/log/analyze_alignments.log
steps/align_si.sh: done aligning data.
[96m[2021-10-23 07:43:18] run_gmm.sh: training tri-lda[0m
steps/train_lda_mllt.sh --cmd run.pl --mem 2G --splice-opts --left-context=3 --right-context=3 2500 15000 data/train data/lang_nosp exp/tri1_ali exp/tri2b
steps/train_lda_mllt.sh: Accumulating LDA statistics.
steps/train_lda_mllt.sh: Accumulating tree stats
steps/train_lda_mllt.sh: Getting questions for tree clustering.
steps/train_lda_mllt.sh: Building the tree
steps/train_lda_mllt.sh: Initializing the model
steps/train_lda_mllt.sh: Converting alignments from exp/tri1_ali to use current tree
steps/train_lda_mllt.sh: Compiling graphs of transcripts
Training pass 1
Training pass 2
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 3
Training pass 4
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 5
Training pass 6
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri2b
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b/log/analyze_alignments.log
1 warnings in exp/tri2b/log/compile_questions.log
117 warnings in exp/tri2b/log/init_model.log
708 warnings in exp/tri2b/log/update.*.log
1 warnings in exp/tri2b/log/build_tree.log
24 warnings in exp/tri2b/log/align.*.*.log
exp/tri2b: nj=8 align prob=-43.97 over 0.81h [retry=0.0%, fail=0.0%] states=752 gauss=14249 tree-impr=4.29 lda-sum=20.79 mllt:impr,logdet=1.25,2.82
steps/train_lda_mllt.sh: Done training system with LDA+MLLT features in exp/tri2b
[93m[2021-10-23 07:43:57] run_gmm.sh: aligning tri-lda[0m
steps/align_si.sh --nj 8 --cmd run.pl --mem 2G --use-graphs true data/train data/lang_nosp exp/tri2b exp/tri2b_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri2b, putting alignments in exp/tri2b_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri2b_ali
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b_ali/log/analyze_alignments.log
steps/align_si.sh: done aligning data.
[93m[2021-10-23 07:44:00] run_gmm.sh: training tri-sat (1st time)[0m
steps/train_sat.sh --cmd run.pl --mem 2G 2500 15000 data/train data/lang_nosp exp/tri2b_ali exp/tri3b
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri2b_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from exp/tri2b_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri3b
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b/log/analyze_alignments.log
626 warnings in exp/tri3b/log/update.*.log
1 warnings in exp/tri3b/log/build_tree.log
10 warnings in exp/tri3b/log/est_alimdl.log
24 warnings in exp/tri3b/log/align.*.*.log
145 warnings in exp/tri3b/log/init_model.log
steps/train_sat.sh: Likelihood evolution:
-49.7845 -48.9787 -48.6487 -48.1992 -46.8191 -45.8644 -45.3595 -44.9982 -44.6862 -44.1985 -43.8191 -43.4355 -43.1786 -42.965 -42.7698 -42.5767 -42.3971 -42.2223 -42.0514 -41.8609 -41.6783 -41.555 -41.4476 -41.3384 -41.2365 -41.1409 -41.0431 -40.9283 -40.7961 -40.6522 -40.5125 -40.4187 -40.3569 -40.3149 
exp/tri3b: nj=8 align prob=-44.64 over 0.81h [retry=0.0%, fail=0.0%] states=880 gauss=14175 fmllr-impr=3.36 over 0.59h tree-impr=5.97
steps/train_sat.sh: done training SAT system in exp/tri3b
[91m[2021-10-23 07:44:44] run_gmm.sh: aligning tri-sat[0m
steps/align_fmllr.sh --nj 8 --cmd run.pl --mem 2G data/train data/lang_nosp exp/tri3b exp/tri3b_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri3b_ali
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b_ali/log/analyze_alignments.log
8 warnings in exp/tri3b_ali/log/align_pass2.*.log
8 warnings in exp/tri3b_ali/log/align_pass1.*.log
[93m[2021-10-23 07:44:53] run_gmm.sh: training tri-sat (2nd time)[0m
steps/train_sat.sh --cmd run.pl --mem 2G 4200 40000 data/train data/lang_nosp exp/tri3b_ali exp/tri4b
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: Using transforms from exp/tri3b_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from exp/tri3b_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
-0.0086452 -0.0114868
[info]: LG not stochastic.
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
-0.0086452 -0.0114868
[info]: CLG not stochastic.
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
-0.0086452 -0.0114868
[info]: LG not stochastic.
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
0 -0.0114868
[info]: CLG not stochastic.
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri4b
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri4b/log/analyze_alignments.log
1545 warnings in exp/tri4b/log/update.*.log
24 warnings in exp/tri4b/log/align.*.*.log
184 warnings in exp/tri4b/log/init_model.log
5 warnings in exp/tri4b/log/est_alimdl.log
1 warnings in exp/tri4b/log/build_tree.log
steps/train_sat.sh: Likelihood evolution:
-48.2529 -48.2399 -48.1537 -47.5103 -45.7736 -44.5226 -43.7444 -43.1434 -42.6461 -42.2028 -41.8759 -41.5226 -41.306 -41.1435 -40.997 -40.864 -40.7276 -40.5939 -40.4775 -40.3713 -40.2802 -40.2354 -40.2029 -40.1779 -40.1623 -40.1493 -40.1384 -40.1271 -40.1192 -40.1118 -40.1001 -40.0955 -40.0892 -40.0846 
exp/tri4b: nj=8 align prob=-44.70 over 0.81h [retry=0.0%, fail=0.0%] states=952 gauss=14140 fmllr-impr=0.49 over 0.59h tree-impr=6.63
steps/train_sat.sh: done training SAT system in exp/tri4b
[92m[2021-10-23 07:45:56] run_gmm.sh: adding sil and pron probs[0m
steps/get_prons.sh --cmd run.pl --mem 2G data/train data/lang_nosp exp/tri4b
steps/get_prons.sh: exp/tri4b/ali.1.gz exists, so starting from alignments.
steps/get_prons.sh: done writing prons to exp/tri4b/prons.*.gz, silence counts in 
steps/get_prons.sh: exp/tri4b/sil_counts_nowb.txt and pronunciation counts in 
steps/get_prons.sh: exp/tri4b/pron_counts.{int,txt}
steps/get_prons.sh: ... and also in exp/tri4b/pron_counts_nowb.txt
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/lexiconp.txt
--> reading data/local/dict_nosp/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexiconp.txt is OK

Checking lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt
--> lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt match

Checking data/local/dict_nosp/extra_questions.txt ...
--> reading data/local/dict_nosp/extra_questions.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

utils/dict_dir_add_pronprobs.sh: normalizing pronprobs so maximum is 1 for each word.
utils/dict_dir_add_pronprobs.sh: produced dictionary directory with probabilities in data/local/dict/
utils/dict_dir_add_pronprobs.sh: validating data/local/dict ..
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> reading data/local/dict/extra_questions.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local/dict]

Some low-probability prons include: 
# sort -k2,2 -n data/local/dict/lexiconp.txt  | head -n 8
!SIL 1 sil
<UNK> 1 spn
a 1 a
a-amilase 1 a a m i l a z i
a-hist√≥rica 1 a i s t O r i k a
a-hist√≥rico 1 a i s t O r i k u
a-z 1 a j s
aa 1 a a
utils/prepare_lang.sh data/local/dict <UNK> data/local/lang_tmp data/lang
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> reading data/local/dict/extra_questions.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local/dict]

prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang
Checking existence of separator file
separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 152 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 11 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 162 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 31 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 77 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
0.000433263 -0.0177229
HCLGa is not stochastic
utils/validate_lang.pl data/lang_test_tgsmall
Checking existence of separator file
separator file data/lang_test_tgsmall/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_test_tgsmall/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgsmall/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgsmall/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_test_tgsmall/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.int corresponds to data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.csl corresponds to data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 152 entry/entries in data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.int corresponds to data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.csl corresponds to data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.int corresponds to data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.csl corresponds to data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.int corresponds to data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.csl corresponds to data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 11 entry/entries in data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.int corresponds to data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.csl corresponds to data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in data/lang_test_tgsmall/phones/roots.txt
--> data/lang_test_tgsmall/phones/roots.int corresponds to data/lang_test_tgsmall/phones/roots.txt
--> data/lang_test_tgsmall/phones/roots.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in data/lang_test_tgsmall/phones/sets.txt
--> data/lang_test_tgsmall/phones/sets.int corresponds to data/lang_test_tgsmall/phones/sets.txt
--> data/lang_test_tgsmall/phones/sets.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang_test_tgsmall/phones/extra_questions.txt
--> data/lang_test_tgsmall/phones/extra_questions.int corresponds to data/lang_test_tgsmall/phones/extra_questions.txt
--> data/lang_test_tgsmall/phones/extra_questions.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 162 entry/entries in data/lang_test_tgsmall/phones/word_boundary.txt
--> data/lang_test_tgsmall/phones/word_boundary.int corresponds to data/lang_test_tgsmall/phones/word_boundary.txt
--> data/lang_test_tgsmall/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_test_tgsmall/phones/disambig.txt has "#0" and "#1"
--> data/lang_test_tgsmall/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_test_tgsmall/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_test_tgsmall/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_test_tgsmall/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_test_tgsmall/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 6 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 13 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_test_tgsmall/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgsmall/oov.txt
--> data/lang_test_tgsmall/oov.int corresponds to data/lang_test_tgsmall/oov.txt
--> data/lang_test_tgsmall/oov.{txt, int} are OK

--> data/lang_test_tgsmall/L.fst is olabel sorted
--> data/lang_test_tgsmall/L_disambig.fst is olabel sorted
--> data/lang_test_tgsmall/G.fst is ilabel sorted
--> data/lang_test_tgsmall/G.fst has 469437 states
--> utils/lang/check_g_properties.pl successfully validated data/lang_test_tgsmall/G.fst
--> utils/lang/check_g_properties.pl succeeded.
--> SUCCESS [validating lang directory data/lang_test_tgsmall]
Succeeded in formatting data.
[96m[2021-10-23 07:47:14] run_gmm.sh: compiling tri-sat graph (no bg)[0m
0.000488052 -0.024885
HCLGa is not stochastic
-0.00941825 -0.0120362
[info]: LG not stochastic.
0 -0.0120362
[info]: CLG not stochastic.
0.000488052 -0.0312973
HCLGa is not stochastic
[94m[2021-10-23 07:52:08] run_gmm.sh: GMM pipeline successfully executed![0m
[96m[2021-10-23 07:52:08] run_ivector_common.sh: preparing directory for low-resolution speed-perturbed data (for alignment)[0m
fix_data_dir.sh: kept all 630 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
utils/data/perturb_data_dir_speed_3way.sh: making sure the utt2dur and the reco2dur files are present
... in data/train, because obtaining it after speed-perturbing
... would be very slow, and you might need them.
utils/data/get_utt2dur.sh: data/train/utt2dur already exists with the expected length.  We won't recompute it.
utils/data/get_reco2dur.sh: data/train/wav.scp indexed by utt-id; copying utt2dur to reco2dur
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in data/train, in data/train_sp_speed0.9
fix_data_dir.sh: kept all 630 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_speed0.9/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_speed0.9
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in data/train, in data/train_sp_speed1.1
fix_data_dir.sh: kept all 630 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_speed1.1/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_speed1.1
utils/data/combine_data.sh data/train_sp data/train data/train_sp_speed0.9 data/train_sp_speed1.1
utils/data/combine_data.sh: combined utt2uniq
utils/data/combine_data.sh [info]: not combining segments as it does not exist
utils/data/combine_data.sh: combined utt2spk
utils/data/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/data/combine_data.sh: combined utt2dur
utils/data/combine_data.sh [info]: **not combining utt2num_frames as it does not exist everywhere**
utils/data/combine_data.sh: combined reco2dur
utils/data/combine_data.sh [info]: **not combining feats.scp as it does not exist everywhere**
utils/data/combine_data.sh: combined text
utils/data/combine_data.sh [info]: **not combining cmvn.scp as it does not exist everywhere**
utils/data/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/data/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/data/combine_data.sh: combined wav.scp
utils/data/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 1890 utterances.
fix_data_dir.sh: old files are kept in data/train_sp/.backup
utils/data/perturb_data_dir_speed_3way.sh: generated 3-way speed-perturbed version of data in data/train, in data/train_sp
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp
steps/make_mfcc.sh --cmd run.pl --mem 2G --nj 8 data/train_sp
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for train_sp
steps/compute_cmvn_stats.sh data/train_sp
Succeeded creating CMVN stats for train_sp
fix_data_dir.sh: kept all 1890 utterances.
fix_data_dir.sh: old files are kept in data/train_sp/.backup
[95m[2021-10-23 07:52:13] run_ivector_common.sh: aligning with the perturbed low-resolution data (mono)[0m
steps/align_fmllr.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang exp/mono exp/mono_ali_train_sp
steps/align_fmllr.sh: feature type is delta
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train_sp using exp/mono/final.mdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang exp/mono_ali_train_sp
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ali_train_sp/log/analyze_alignments.log
21 warnings in exp/mono_ali_train_sp/log/align_pass1.*.log
16 warnings in exp/mono_ali_train_sp/log/align_pass2.*.log
[91m[2021-10-23 07:52:19] run_ivector_common.sh: aligning with the perturbed low-resolution data (tri-deltas)[0m
steps/align_fmllr.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang exp/tri1 exp/tri1_ali_train_sp
steps/align_fmllr.sh: feature type is delta
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train_sp using exp/tri1/final.mdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang exp/tri1_ali_train_sp
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1_ali_train_sp/log/analyze_alignments.log
10 warnings in exp/tri1_ali_train_sp/log/align_pass1.*.log
10 warnings in exp/tri1_ali_train_sp/log/align_pass2.*.log
[96m[2021-10-23 07:52:27] run_ivector_common.sh: aligning with the perturbed low-resolution data (tri-sat)[0m
steps/align_fmllr.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang exp/tri4b exp/tri4b_ali_train_sp
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train_sp using exp/tri4b/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang exp/tri4b_ali_train_sp
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri4b_ali_train_sp/log/analyze_alignments.log
8 warnings in exp/tri4b_ali_train_sp/log/align_pass2.*.log
10 warnings in exp/tri4b_ali_train_sp/log/align_pass1.*.log
[95m[2021-10-23 07:52:45] run_ivector_common.sh: creating high-resolution MFCC features[0m
utils/copy_data_dir.sh: copied data from data/train_sp to data/train_sp_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_hires
utils/copy_data_dir.sh: copied data from data/test to data/test_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/test_hires
utils/data/perturb_data_dir_volume.sh: data/train_sp_hires/feats.scp exists; moving it to data/train_sp_hires/.backup/ as it wouldn't be valid any more.
utils/data/perturb_data_dir_volume.sh: added volume perturbation to the data in data/train_sp_hires
steps/make_mfcc.sh --nj 16 --mfcc-config conf/mfcc_hires.conf --cmd run.pl --mem 2G data/train_sp_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for train_sp_hires
steps/compute_cmvn_stats.sh data/train_sp_hires
Succeeded creating CMVN stats for train_sp_hires
fix_data_dir.sh: kept all 1890 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_hires/.backup
steps/make_mfcc.sh --nj 16 --mfcc-config conf/mfcc_hires.conf --cmd run.pl --mem 2G data/test_hires
steps/make_mfcc.sh: moving data/test_hires/feats.scp to data/test_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/test_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for test_hires
steps/compute_cmvn_stats.sh data/test_hires
Succeeded creating CMVN stats for test_hires
fix_data_dir.sh: kept all 70 utterances.
fix_data_dir.sh: old files are kept in data/test_hires/.backup
[94m[2021-10-23 07:52:50] run_ivector_common.sh: making a subset of data to train the diagonal UBM and the PCA transform.[0m
utils/data/subset_data_dir.sh: reducing #utt from 1890 to 472
[95m[2021-10-23 07:52:50] run_ivector_common.sh: computing a PCA transform from the hires data.[0m
steps/online/nnet2/get_pca_transform.sh --cmd run.pl --mem 2G --splice-opts --left-context=3 --right-context=3 --max-utts 10000 --subsample 2 exp/nnet3/diag_ubm/train_sp_hires_subset exp/nnet3/pca_transform
Done estimating PCA transform in exp/nnet3/pca_transform
[93m[2021-10-23 07:52:51] run_ivector_common.sh: training the diagonal UBM.[0m
steps/online/nnet2/train_diag_ubm.sh --cmd run.pl --mem 2G --nj 8 --num-frames 700000 --num-threads 2 exp/nnet3/diag_ubm/train_sp_hires_subset 512 exp/nnet3/pca_transform exp/nnet3/diag_ubm
steps/online/nnet2/train_diag_ubm.sh: Directory exp/nnet3/diag_ubm already exists. Backing up diagonal UBM in exp/nnet3/diag_ubm/backup.edl
steps/online/nnet2/train_diag_ubm.sh: initializing model from E-M in memory, 
steps/online/nnet2/train_diag_ubm.sh: starting from 256 Gaussians, reaching 512;
steps/online/nnet2/train_diag_ubm.sh: for 20 iterations, using at most 700000 frames of data
Getting Gaussian-selection info
steps/online/nnet2/train_diag_ubm.sh: will train for 4 iterations, in parallel over
steps/online/nnet2/train_diag_ubm.sh: 8 machines, parallelized with 'run.pl --mem 2G'
steps/online/nnet2/train_diag_ubm.sh: Training pass 0
steps/online/nnet2/train_diag_ubm.sh: Training pass 1
steps/online/nnet2/train_diag_ubm.sh: Training pass 2
steps/online/nnet2/train_diag_ubm.sh: Training pass 3
[96m[2021-10-23 07:53:32] run_ivector_common.sh: training the iVector extractor[0m
steps/online/nnet2/train_ivector_extractor.sh --cmd run.pl --mem 2G --nj 4 --num-processes 2 --num-threads 2 data/train_sp_hires exp/nnet3/diag_ubm exp/nnet3/extractor
steps/online/nnet2/train_ivector_extractor.sh: doing Gaussian selection and posterior computation
Accumulating stats (pass 0)
Summing accs (pass 0)
Updating model (pass 0)
Accumulating stats (pass 1)
Summing accs (pass 1)
Updating model (pass 1)
Accumulating stats (pass 2)
Summing accs (pass 2)
Updating model (pass 2)
Accumulating stats (pass 3)
Summing accs (pass 3)
Updating model (pass 3)
Accumulating stats (pass 4)
Summing accs (pass 4)
Updating model (pass 4)
Accumulating stats (pass 5)
Summing accs (pass 5)
Updating model (pass 5)
Accumulating stats (pass 6)
Summing accs (pass 6)
Updating model (pass 6)
Accumulating stats (pass 7)
Summing accs (pass 7)
Updating model (pass 7)
Accumulating stats (pass 8)
Summing accs (pass 8)
Updating model (pass 8)
Accumulating stats (pass 9)
Summing accs (pass 9)
Updating model (pass 9)
utils/data/modify_speaker_info.sh: copied data from data/train_sp_hires to exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2, number of speakers changed from 105 to 969
utils/validate_data_dir.sh: text contains 1608 lines with non-printable characters
fbutils/data/modify_speaker_info.sh: copied data from data/train_sp_hires to exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2, number of speakers changed from 105 to 969
utils/validate_data_dir.sh: Successfully validated data-directory exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2
[95m[2021-10-23 11:51:11] run_ivector_common.sh: extracting iVectors from training data[0m
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --mem 2G --nj 8 exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2 exp/nnet3/extractor exp/nnet3/ivectors_train_sp_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3/ivectors_train_sp_hires using the extractor in exp/nnet3/extractor.
[91m[2021-10-23 11:51:14] run_ivector_common.sh: extracting iVectors from test data[0m
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --mem 2G --nj 8 data/test_hires exp/nnet3/extractor exp/nnet3/ivectors_test_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3/ivectors_test_hires using the extractor in exp/nnet3/extractor.
[92m[2021-10-23 11:51:15] run_ivector_common.sh: feature extraction successfully executed![0m
run_tdnn_mono_chain_lda_ivector_fs3.sh --fb-num-epochs 10 --decode false
run_tdnn_mono_chain_lda_ivector_fs3.sh: creating lang directory with one state per phone.
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/mono exp/chain/mono_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/mono/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
22 warnings in exp/chain/mono_train_sp_lats/log/align_pass1.*.log
8 warnings in exp/chain/mono_train_sp_lats/log/generate_lattices.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/mono_ali_train_sp exp/chain/tree_sp_mono_chain_lda_ivector_fs3
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/mono_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/mono_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_mono_chain_lda_ivector_fs3.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_mono_chain_lda_ivector_fs3/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs/network.xconfig --config-dir exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs/
nnet3-init exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs//init.config exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs//init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs//init.raw
nnet3-info exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs//init.raw 
nnet3-init exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs//ref.config exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs//ref.config exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/configs//ref.raw 
2021-10-23 11:51:39,011 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 11:51:39,027 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/mono_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_mono_chain_lda_ivector_fs3',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 11:51:39,044 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 11:51:39,300 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_mono_chain_lda_ivector_fs3/final.mdl exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 11:51:39,513 [steps/nnet3/chain/train.py:350 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 11:51:39,544 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp exp/chain/mono_train_sp_lats exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/tree 
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (14,14)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 11:51:52,395 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/egs to exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp
2021-10-23 11:51:52,396 [steps/nnet3/chain/train.py:442 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 11:51:53,219 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 11:51:53,493 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 30 iterations
2021-10-23 11:51:53,493 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/29   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 11:52:03,812 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/29   Jobs: 1   Epoch: 0.33/10.0 (3.3% complete)   lr: 0.000139   
2021-10-23 11:52:13,059 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/29   Jobs: 1   Epoch: 0.67/10.0 (6.7% complete)   lr: 0.000129   
2021-10-23 11:52:22,300 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/29   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 11:52:31,549 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/29   Jobs: 1   Epoch: 1.33/10.0 (13.3% complete)   lr: 0.000110   
2021-10-23 11:52:40,820 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/29   Jobs: 1   Epoch: 1.67/10.0 (16.7% complete)   lr: 0.000102   
2021-10-23 11:52:50,105 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/29   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 11:52:59,386 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/29   Jobs: 1   Epoch: 2.33/10.0 (23.3% complete)   lr: 0.000088   
2021-10-23 11:53:08,890 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/29   Jobs: 1   Epoch: 2.67/10.0 (26.7% complete)   lr: 0.000081   
2021-10-23 11:53:18,246 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/29   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 11:53:27,792 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 10/29   Jobs: 1   Epoch: 3.33/10.0 (33.3% complete)   lr: 0.000070   
2021-10-23 11:53:37,162 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 11/29   Jobs: 1   Epoch: 3.67/10.0 (36.7% complete)   lr: 0.000064   
2021-10-23 11:53:46,697 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 12/29   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 11:53:56,056 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 13/29   Jobs: 1   Epoch: 4.33/10.0 (43.3% complete)   lr: 0.000055   
2021-10-23 11:54:05,604 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 14/29   Jobs: 1   Epoch: 4.67/10.0 (46.7% complete)   lr: 0.000051   
2021-10-23 11:54:14,952 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 15/29   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 11:54:24,477 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 16/29   Jobs: 1   Epoch: 5.33/10.0 (53.3% complete)   lr: 0.000044   
2021-10-23 11:54:33,817 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 17/29   Jobs: 1   Epoch: 5.67/10.0 (56.7% complete)   lr: 0.000041   
2021-10-23 11:54:43,353 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 18/29   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 11:54:52,690 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 19/29   Jobs: 1   Epoch: 6.33/10.0 (63.3% complete)   lr: 0.000035   
2021-10-23 11:55:02,230 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 20/29   Jobs: 1   Epoch: 6.67/10.0 (66.7% complete)   lr: 0.000032   
2021-10-23 11:55:12,541 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 21/29   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 11:55:22,034 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 22/29   Jobs: 1   Epoch: 7.33/10.0 (73.3% complete)   lr: 0.000028   
2021-10-23 11:55:31,585 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 23/29   Jobs: 1   Epoch: 7.67/10.0 (76.7% complete)   lr: 0.000026   
2021-10-23 11:55:40,937 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 24/29   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 11:55:50,497 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 25/29   Jobs: 1   Epoch: 8.33/10.0 (83.3% complete)   lr: 0.000022   
2021-10-23 11:55:59,850 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 26/29   Jobs: 1   Epoch: 8.67/10.0 (86.7% complete)   lr: 0.000020   
2021-10-23 11:56:09,400 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 27/29   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000019   
2021-10-23 11:56:18,756 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 28/29   Jobs: 1   Epoch: 9.33/10.0 (93.3% complete)   lr: 0.000017   
2021-10-23 11:56:28,311 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 29/29   Jobs: 1   Epoch: 9.67/10.0 (96.7% complete)   lr: 0.000015   
2021-10-23 11:56:37,653 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 11:56:37,653 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) models.
2021-10-23 11:56:46,546 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/egs
exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp: num-iters=30 nj=1..1 num-params=8.9M dim=40+100->408 combine=-0.028->-0.028 (over 1) xent:train/valid[19,29]=(-1.25,-1.08/-1.60,-1.57) logprob:train/valid[19,29]=(-0.038,-0.029/-0.103,-0.103)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_mono_chain_lda_ivector_fs3 --lat-dir exp/chain/mono_train_sp_lats --dir exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_mono_chain_lda_ivector_fs3', '--lat-dir', 'exp/chain/mono_train_sp_lats', '--dir', 'exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp']
run_tdnn_mono_chain_lda_ivector_fs3.sh: success!
[2021-10-23 11:56:53] run_propor.sh: ok
run_tdnn_mono_chain_lda_noivector_fs3.sh --fb-num-epochs 10 --decode false
run_tdnn_mono_chain_lda_noivector_fs3.sh: creating lang directory with one state per phone.
run_tdnn_mono_chain_lda_noivector_fs3.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/mono exp/chain/mono_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/mono/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/mono_train_sp_lats/log/generate_lattices.*.log
22 warnings in exp/chain/mono_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/mono_ali_train_sp exp/chain/tree_sp_mono_chain_lda_noivector_fs3
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/mono_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/mono_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_mono_chain_lda_noivector_fs3.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_mono_chain_lda_noivector_fs3/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs/network.xconfig --config-dir exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs/
nnet3-init exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs//init.config exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs//init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs//init.raw
nnet3-info exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs//init.raw 
nnet3-init exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs//ref.config exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs//ref.config exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/configs//ref.raw 
2021-10-23 11:57:17,495 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 11:57:17,511 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/mono_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_mono_chain_lda_noivector_fs3',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 11:57:17,520 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 11:57:17,616 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_mono_chain_lda_noivector_fs3/final.mdl exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 11:57:17,784 [steps/nnet3/chain/train.py:350 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 11:57:17,814 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp exp/chain/mono_train_sp_lats exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/tree 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (14,14)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 11:57:29,984 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/egs to exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp
2021-10-23 11:57:29,984 [steps/nnet3/chain/train.py:442 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 11:57:30,506 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 11:57:30,773 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 30 iterations
2021-10-23 11:57:30,774 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/29   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 11:57:41,076 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/29   Jobs: 1   Epoch: 0.33/10.0 (3.3% complete)   lr: 0.000139   
2021-10-23 11:57:50,323 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/29   Jobs: 1   Epoch: 0.67/10.0 (6.7% complete)   lr: 0.000129   
2021-10-23 11:57:59,605 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/29   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 11:58:08,870 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/29   Jobs: 1   Epoch: 1.33/10.0 (13.3% complete)   lr: 0.000110   
2021-10-23 11:58:18,134 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/29   Jobs: 1   Epoch: 1.67/10.0 (16.7% complete)   lr: 0.000102   
2021-10-23 11:58:27,431 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/29   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 11:58:36,691 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/29   Jobs: 1   Epoch: 2.33/10.0 (23.3% complete)   lr: 0.000088   
2021-10-23 11:58:46,185 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/29   Jobs: 1   Epoch: 2.67/10.0 (26.7% complete)   lr: 0.000081   
2021-10-23 11:58:55,568 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/29   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 11:59:05,066 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 10/29   Jobs: 1   Epoch: 3.33/10.0 (33.3% complete)   lr: 0.000070   
2021-10-23 11:59:14,381 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 11/29   Jobs: 1   Epoch: 3.67/10.0 (36.7% complete)   lr: 0.000064   
2021-10-23 11:59:23,884 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 12/29   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 11:59:33,209 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 13/29   Jobs: 1   Epoch: 4.33/10.0 (43.3% complete)   lr: 0.000055   
2021-10-23 11:59:42,704 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 14/29   Jobs: 1   Epoch: 4.67/10.0 (46.7% complete)   lr: 0.000051   
2021-10-23 11:59:52,018 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 15/29   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 12:00:01,522 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 16/29   Jobs: 1   Epoch: 5.33/10.0 (53.3% complete)   lr: 0.000044   
2021-10-23 12:00:10,860 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 17/29   Jobs: 1   Epoch: 5.67/10.0 (56.7% complete)   lr: 0.000041   
2021-10-23 12:00:20,389 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 18/29   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 12:00:29,728 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 19/29   Jobs: 1   Epoch: 6.33/10.0 (63.3% complete)   lr: 0.000035   
2021-10-23 12:00:39,212 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 20/29   Jobs: 1   Epoch: 6.67/10.0 (66.7% complete)   lr: 0.000032   
2021-10-23 12:00:49,461 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 21/29   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 12:00:58,924 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 22/29   Jobs: 1   Epoch: 7.33/10.0 (73.3% complete)   lr: 0.000028   
2021-10-23 12:01:08,392 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 23/29   Jobs: 1   Epoch: 7.67/10.0 (76.7% complete)   lr: 0.000026   
2021-10-23 12:01:17,701 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 24/29   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 12:01:27,183 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 25/29   Jobs: 1   Epoch: 8.33/10.0 (83.3% complete)   lr: 0.000022   
2021-10-23 12:01:36,521 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 26/29   Jobs: 1   Epoch: 8.67/10.0 (86.7% complete)   lr: 0.000020   
2021-10-23 12:01:46,025 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 27/29   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000019   
2021-10-23 12:01:55,367 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 28/29   Jobs: 1   Epoch: 9.33/10.0 (93.3% complete)   lr: 0.000017   
2021-10-23 12:02:04,889 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 29/29   Jobs: 1   Epoch: 9.67/10.0 (96.7% complete)   lr: 0.000015   
2021-10-23 12:02:14,206 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 12:02:14,206 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) models.
2021-10-23 12:02:23,055 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp/egs
exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp: num-iters=30 nj=1..1 num-params=8.8M dim=40->408 combine=-0.029->-0.029 (over 1) xent:train/valid[19,29]=(-1.30,-1.15/-1.59,-1.54) logprob:train/valid[19,29]=(-0.038,-0.030/-0.098,-0.094)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_mono_chain_lda_noivector_fs3 --lat-dir exp/chain/mono_train_sp_lats --dir exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_mono_chain_lda_noivector_fs3', '--lat-dir', 'exp/chain/mono_train_sp_lats', '--dir', 'exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp']
run_tdnn_mono_chain_lda_noivector_fs3.sh: success!
[2021-10-23 12:02:30] run_propor.sh: ok
run_tdnn_mono_chain_lda_ivector_nofs.sh --fb-num-epochs 10 --decode false
run_tdnn_mono_chain_lda_ivector_nofs.sh: creating lang directory with one state per phone.
run_tdnn_mono_chain_lda_ivector_nofs.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/mono exp/chain/mono_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/mono/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/mono_train_sp_lats/log/generate_lattices.*.log
22 warnings in exp/chain/mono_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 1 --alignment-subsampling-factor 1 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/mono_ali_train_sp exp/chain/tree_sp_mono_chain_lda_ivector_nofs
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/mono_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/mono_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_mono_chain_lda_ivector_nofs.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_mono_chain_lda_ivector_nofs/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs/network.xconfig --config-dir exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs/
nnet3-init exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs//init.config exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs//init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs//init.raw
nnet3-info exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs//init.raw 
nnet3-init exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs//ref.config exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs//ref.config exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/configs//ref.raw 
2021-10-23 12:02:54,523 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 12:02:54,539 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 1,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 1,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/mono_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_mono_chain_lda_ivector_nofs',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 12:02:54,556 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 12:02:54,694 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_mono_chain_lda_ivector_nofs/final.mdl exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 12:02:54,887 [steps/nnet3/chain/train.py:350 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 12:02:54,933 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 13 --right-context 13 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 1 --alignment-subsampling-factor 1 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp exp/chain/mono_train_sp_lats exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/tree 
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (13,13)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 12:03:07,941 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/egs to exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp
2021-10-23 12:03:07,942 [steps/nnet3/chain/train.py:442 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 12:03:09,372 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 12:03:09,645 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 10 iterations
2021-10-23 12:03:09,646 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/9   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 12:03:25,030 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/9   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 12:03:39,244 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/9   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 12:03:53,683 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/9   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 12:04:08,477 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/9   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 12:04:23,174 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/9   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 12:04:37,839 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/9   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 12:04:52,524 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/9   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 12:05:07,149 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/9   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 12:05:21,810 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/9   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000015   
2021-10-23 12:05:36,501 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 12:05:36,501 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([8, 9, 10, 6, 7]) models.
2021-10-23 12:05:42,992 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/egs
exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp: num-iters=10 nj=1..1 num-params=9.4M dim=40+100->1248 combine=-0.017->-0.017 (over 1) xent:train/valid[5,9]=(-2.03,-1.81/-2.50,-2.33) logprob:train/valid[5,9]=(-0.021,-0.018/-0.089,-0.083)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --chain.frame-subsampling-factor 1 --chain.alignment-subsampling-factor 1 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_mono_chain_lda_ivector_nofs --lat-dir exp/chain/mono_train_sp_lats --dir exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--chain.frame-subsampling-factor', '1', '--chain.alignment-subsampling-factor', '1', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_mono_chain_lda_ivector_nofs', '--lat-dir', 'exp/chain/mono_train_sp_lats', '--dir', 'exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp']
run_tdnn_mono_chain_lda_ivector_nofs.sh: success!
[2021-10-23 12:05:58] run_propor.sh: ok
run_tdnn_mono_chain_lda_noivector_nofs.sh --fb-num-epochs 10 --decode false
run_tdnn_mono_chain_lda_noivector_nofs.sh: creating lang directory with one state per phone.
run_tdnn_mono_chain_lda_noivector_nofs.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/mono exp/chain/mono_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/mono/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
22 warnings in exp/chain/mono_train_sp_lats/log/align_pass1.*.log
8 warnings in exp/chain/mono_train_sp_lats/log/generate_lattices.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 1 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/mono_ali_train_sp exp/chain/tree_sp_mono_chain_lda_noivector_nofs
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/mono_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/mono_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_mono_chain_lda_noivector_nofs.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_mono_chain_lda_noivector_nofs/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs/network.xconfig --config-dir exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs/
nnet3-init exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs//init.config exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs//init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs//init.raw
nnet3-info exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs//init.raw 
nnet3-init exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs//ref.config exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs//ref.config exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/configs//ref.raw 
2021-10-23 12:06:22,675 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 12:06:22,691 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 1,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 1,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/mono_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_mono_chain_lda_noivector_nofs',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 12:06:22,700 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 12:06:22,823 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_mono_chain_lda_noivector_nofs/final.mdl exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 12:06:23,025 [steps/nnet3/chain/train.py:350 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 12:06:23,069 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 13 --right-context 13 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 1 --alignment-subsampling-factor 1 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp exp/chain/mono_train_sp_lats exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/tree 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (13,13)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 12:06:36,109 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/egs to exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp
2021-10-23 12:06:36,110 [steps/nnet3/chain/train.py:442 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 12:06:36,879 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 12:06:37,178 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 10 iterations
2021-10-23 12:06:37,178 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/9   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 12:06:52,488 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/9   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 12:07:06,670 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/9   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 12:07:21,003 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/9   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 12:07:35,659 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/9   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 12:07:50,280 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/9   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 12:08:04,912 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/9   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 12:08:19,536 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/9   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 12:08:34,157 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/9   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 12:08:48,774 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/9   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000015   
2021-10-23 12:09:03,378 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 12:09:03,379 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([8, 9, 10, 6, 7]) models.
2021-10-23 12:09:09,976 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp/egs
exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp: num-iters=10 nj=1..1 num-params=9.2M dim=40->1248 combine=-0.017->-0.017 (over 1) xent:train/valid[5,9]=(-2.05,-1.86/-2.40,-2.26) logprob:train/valid[5,9]=(-0.022,-0.018/-0.077,-0.071)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --chain.frame-subsampling-factor 1 --chain.alignment-subsampling-factor 1 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_mono_chain_lda_noivector_nofs --lat-dir exp/chain/mono_train_sp_lats --dir exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--chain.frame-subsampling-factor', '1', '--chain.alignment-subsampling-factor', '1', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_mono_chain_lda_noivector_nofs', '--lat-dir', 'exp/chain/mono_train_sp_lats', '--dir', 'exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp']
run_tdnn_mono_chain_lda_noivector_nofs.sh: success!
[2021-10-23 12:09:25] run_propor.sh: ok
run_tdnn_mono_nochain_lda_ivector.sh: creating neural net configs
tree-info exp/mono_ali_train_sp/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs/network.xconfig --config-dir exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs
nnet3-init exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs/init.config exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs/init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs/init.raw
nnet3-info exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs/init.raw 
nnet3-init exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs/ref.config exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs/ref.raw 
nnet3-init exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs/ref.config exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/configs/ref.raw 
2021-10-23 12:09:25,816 [steps/nnet3/train_dnn.py:36 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir  --cleanup.remove-egs true --cleanup.preserve-model-interval 100 --feat-dir=data/train_sp_hires --ali-dir exp/mono_ali_train_sp --lang data/lang --reporting.email= --dir=exp/nnet3/tdnn_mono_nochain_lda_ivector_sp
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', '', '--cleanup.remove-egs', 'true', '--cleanup.preserve-model-interval', '100', '--feat-dir=data/train_sp_hires', '--ali-dir', 'exp/mono_ali_train_sp', '--lang', 'data/lang', '--reporting.email=', '--dir=exp/nnet3/tdnn_mono_nochain_lda_ivector_sp']
2021-10-23 12:09:25,832 [steps/nnet3/train_dnn.py:178 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/mono_ali_train_sp',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_mono_nochain_lda_ivector_sp',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': None,
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'input_model': None,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 10.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': [],
 'use_gpu': 'yes'}
2021-10-23 12:09:25,849 [steps/nnet3/train_dnn.py:228 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 12:09:25,902 [steps/nnet3/train_dnn.py:238 - train - INFO ] Generating egs
steps/nnet3/get_egs.sh --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 8 --srand 0 data/train_sp_hires exp/mono_ali_train_sp exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/egs
File data/train_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
*** steps/nnet3/get_egs.sh: warning: the --frames-per-eg is too large to generate one archive with
*** as many as --samples-per-iter egs in it.  Consider reducing --frames-per-eg.
steps/nnet3/get_egs.sh: creating 1 archives, each with 110347 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (14,14)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/egs/ali.ark,exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/egs/ali.scp 
LOG (copy-int-vector[5.5.0~1-5caf]:main():copy-int-vector.cc:83) Copied 1890 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
2021-10-23 12:09:37,388 [steps/nnet3/train_dnn.py:276 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 12:09:39,861 [steps/nnet3/train_dnn.py:287 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2021-10-23 12:09:39,974 [steps/nnet3/train_dnn.py:294 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 12:09:40,281 [steps/nnet3/train_dnn.py:319 - train - INFO ] Training will run for 10.0 epochs = 80 iterations
2021-10-23 12:09:40,281 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 0/79   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.001700   
2021-10-23 12:09:52,033 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 1/79   Jobs: 1   Epoch: 0.12/10.0 (1.2% complete)   lr: 0.001652   
2021-10-23 12:10:02,633 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 2/79   Jobs: 1   Epoch: 0.25/10.0 (2.5% complete)   lr: 0.001605   
2021-10-23 12:10:13,287 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 3/79   Jobs: 1   Epoch: 0.38/10.0 (3.8% complete)   lr: 0.001559   
2021-10-23 12:10:23,935 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 4/79   Jobs: 1   Epoch: 0.50/10.0 (5.0% complete)   lr: 0.001515   
2021-10-23 12:10:34,653 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 5/79   Jobs: 1   Epoch: 0.62/10.0 (6.2% complete)   lr: 0.001472   
2021-10-23 12:10:45,374 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 6/79   Jobs: 1   Epoch: 0.75/10.0 (7.5% complete)   lr: 0.001430   
2021-10-23 12:10:55,967 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 7/79   Jobs: 1   Epoch: 0.88/10.0 (8.8% complete)   lr: 0.001390   
2021-10-23 12:11:06,598 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 8/79   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.001350   
2021-10-23 12:11:17,208 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 9/79   Jobs: 1   Epoch: 1.12/10.0 (11.2% complete)   lr: 0.001312   
2021-10-23 12:11:27,843 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 10/79   Jobs: 1   Epoch: 1.25/10.0 (12.5% complete)   lr: 0.001275   
2021-10-23 12:11:38,484 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 11/79   Jobs: 1   Epoch: 1.38/10.0 (13.8% complete)   lr: 0.001239   
2021-10-23 12:11:49,089 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 12/79   Jobs: 1   Epoch: 1.50/10.0 (15.0% complete)   lr: 0.001204   
2021-10-23 12:11:59,711 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 13/79   Jobs: 1   Epoch: 1.62/10.0 (16.2% complete)   lr: 0.001169   
2021-10-23 12:12:10,335 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 14/79   Jobs: 1   Epoch: 1.75/10.0 (17.5% complete)   lr: 0.001136   
2021-10-23 12:12:20,935 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 15/79   Jobs: 1   Epoch: 1.88/10.0 (18.8% complete)   lr: 0.001104   
2021-10-23 12:12:31,544 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 16/79   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.001073   
2021-10-23 12:12:42,170 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 17/79   Jobs: 1   Epoch: 2.12/10.0 (21.2% complete)   lr: 0.001042   
2021-10-23 12:12:52,794 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 18/79   Jobs: 1   Epoch: 2.25/10.0 (22.5% complete)   lr: 0.001013   
2021-10-23 12:13:03,399 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 19/79   Jobs: 1   Epoch: 2.38/10.0 (23.8% complete)   lr: 0.000984   
2021-10-23 12:13:14,010 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 20/79   Jobs: 1   Epoch: 2.50/10.0 (25.0% complete)   lr: 0.000956   
2021-10-23 12:13:25,492 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 21/79   Jobs: 1   Epoch: 2.62/10.0 (26.2% complete)   lr: 0.000929   
2021-10-23 12:13:36,351 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 22/79   Jobs: 1   Epoch: 2.75/10.0 (27.5% complete)   lr: 0.000903   
2021-10-23 12:13:47,095 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 23/79   Jobs: 1   Epoch: 2.88/10.0 (28.8% complete)   lr: 0.000877   
2021-10-23 12:13:57,693 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 24/79   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000852   
2021-10-23 12:14:08,289 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 25/79   Jobs: 1   Epoch: 3.12/10.0 (31.2% complete)   lr: 0.000828   
2021-10-23 12:14:18,867 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 26/79   Jobs: 1   Epoch: 3.25/10.0 (32.5% complete)   lr: 0.000804   
2021-10-23 12:14:29,547 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 27/79   Jobs: 1   Epoch: 3.38/10.0 (33.8% complete)   lr: 0.000782   
2021-10-23 12:14:40,135 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 28/79   Jobs: 1   Epoch: 3.50/10.0 (35.0% complete)   lr: 0.000759   
2021-10-23 12:14:50,765 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 29/79   Jobs: 1   Epoch: 3.62/10.0 (36.2% complete)   lr: 0.000738   
2021-10-23 12:15:01,366 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 30/79   Jobs: 1   Epoch: 3.75/10.0 (37.5% complete)   lr: 0.000717   
2021-10-23 12:15:11,988 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 31/79   Jobs: 1   Epoch: 3.88/10.0 (38.8% complete)   lr: 0.000697   
2021-10-23 12:15:22,578 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 32/79   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000677   
2021-10-23 12:15:33,212 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 33/79   Jobs: 1   Epoch: 4.12/10.0 (41.2% complete)   lr: 0.000658   
2021-10-23 12:15:43,801 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 34/79   Jobs: 1   Epoch: 4.25/10.0 (42.5% complete)   lr: 0.000639   
2021-10-23 12:15:54,430 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 35/79   Jobs: 1   Epoch: 4.38/10.0 (43.8% complete)   lr: 0.000621   
2021-10-23 12:16:05,051 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 36/79   Jobs: 1   Epoch: 4.50/10.0 (45.0% complete)   lr: 0.000603   
2021-10-23 12:16:15,692 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 37/79   Jobs: 1   Epoch: 4.62/10.0 (46.2% complete)   lr: 0.000586   
2021-10-23 12:16:26,298 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 38/79   Jobs: 1   Epoch: 4.75/10.0 (47.5% complete)   lr: 0.000569   
2021-10-23 12:16:36,902 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 39/79   Jobs: 1   Epoch: 4.88/10.0 (48.8% complete)   lr: 0.000553   
2021-10-23 12:16:47,499 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 40/79   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000538   
2021-10-23 12:16:58,967 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 41/79   Jobs: 1   Epoch: 5.12/10.0 (51.2% complete)   lr: 0.000522   
2021-10-23 12:17:09,744 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 42/79   Jobs: 1   Epoch: 5.25/10.0 (52.5% complete)   lr: 0.000508   
2021-10-23 12:17:20,547 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 43/79   Jobs: 1   Epoch: 5.38/10.0 (53.8% complete)   lr: 0.000493   
2021-10-23 12:17:31,164 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 44/79   Jobs: 1   Epoch: 5.50/10.0 (55.0% complete)   lr: 0.000479   
2021-10-23 12:17:41,783 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 45/79   Jobs: 1   Epoch: 5.62/10.0 (56.2% complete)   lr: 0.000466   
2021-10-23 12:17:52,407 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 46/79   Jobs: 1   Epoch: 5.75/10.0 (57.5% complete)   lr: 0.000452   
2021-10-23 12:18:03,008 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 47/79   Jobs: 1   Epoch: 5.88/10.0 (58.8% complete)   lr: 0.000439   
2021-10-23 12:18:13,624 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 48/79   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000427   
2021-10-23 12:18:24,225 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 49/79   Jobs: 1   Epoch: 6.12/10.0 (61.2% complete)   lr: 0.000415   
2021-10-23 12:18:34,858 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 50/79   Jobs: 1   Epoch: 6.25/10.0 (62.5% complete)   lr: 0.000403   
2021-10-23 12:18:45,492 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 51/79   Jobs: 1   Epoch: 6.38/10.0 (63.8% complete)   lr: 0.000392   
2021-10-23 12:18:56,107 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 52/79   Jobs: 1   Epoch: 6.50/10.0 (65.0% complete)   lr: 0.000381   
2021-10-23 12:19:06,725 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 53/79   Jobs: 1   Epoch: 6.62/10.0 (66.2% complete)   lr: 0.000370   
2021-10-23 12:19:17,351 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 54/79   Jobs: 1   Epoch: 6.75/10.0 (67.5% complete)   lr: 0.000359   
2021-10-23 12:19:27,992 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 55/79   Jobs: 1   Epoch: 6.88/10.0 (68.8% complete)   lr: 0.000349   
2021-10-23 12:19:38,614 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 56/79   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000339   
2021-10-23 12:19:49,234 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 57/79   Jobs: 1   Epoch: 7.12/10.0 (71.2% complete)   lr: 0.000330   
2021-10-23 12:19:59,871 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 58/79   Jobs: 1   Epoch: 7.25/10.0 (72.5% complete)   lr: 0.000320   
2021-10-23 12:20:10,492 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 59/79   Jobs: 1   Epoch: 7.38/10.0 (73.8% complete)   lr: 0.000311   
2021-10-23 12:20:21,109 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 60/79   Jobs: 1   Epoch: 7.50/10.0 (75.0% complete)   lr: 0.000302   
2021-10-23 12:20:32,558 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 61/79   Jobs: 1   Epoch: 7.62/10.0 (76.2% complete)   lr: 0.000294   
2021-10-23 12:20:43,333 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 62/79   Jobs: 1   Epoch: 7.75/10.0 (77.5% complete)   lr: 0.000285   
2021-10-23 12:20:54,092 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 63/79   Jobs: 1   Epoch: 7.88/10.0 (78.8% complete)   lr: 0.000277   
2021-10-23 12:21:04,698 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 64/79   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000269   
2021-10-23 12:21:15,281 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 65/79   Jobs: 1   Epoch: 8.12/10.0 (81.2% complete)   lr: 0.000262   
2021-10-23 12:21:25,903 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 66/79   Jobs: 1   Epoch: 8.25/10.0 (82.5% complete)   lr: 0.000254   
2021-10-23 12:21:36,556 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 67/79   Jobs: 1   Epoch: 8.38/10.0 (83.8% complete)   lr: 0.000247   
2021-10-23 12:21:47,165 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 68/79   Jobs: 1   Epoch: 8.50/10.0 (85.0% complete)   lr: 0.000240   
2021-10-23 12:21:57,806 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 69/79   Jobs: 1   Epoch: 8.62/10.0 (86.2% complete)   lr: 0.000233   
2021-10-23 12:22:08,406 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 70/79   Jobs: 1   Epoch: 8.75/10.0 (87.5% complete)   lr: 0.000227   
2021-10-23 12:22:19,098 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 71/79   Jobs: 1   Epoch: 8.88/10.0 (88.8% complete)   lr: 0.000220   
2021-10-23 12:22:29,707 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 72/79   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000214   
2021-10-23 12:22:40,299 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 73/79   Jobs: 1   Epoch: 9.12/10.0 (91.2% complete)   lr: 0.000208   
2021-10-23 12:22:50,922 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 74/79   Jobs: 1   Epoch: 9.25/10.0 (92.5% complete)   lr: 0.000202   
2021-10-23 12:23:01,528 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 75/79   Jobs: 1   Epoch: 9.38/10.0 (93.8% complete)   lr: 0.000196   
2021-10-23 12:23:12,167 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 76/79   Jobs: 1   Epoch: 9.50/10.0 (95.0% complete)   lr: 0.000191   
2021-10-23 12:23:22,765 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 77/79   Jobs: 1   Epoch: 9.62/10.0 (96.2% complete)   lr: 0.000185   
2021-10-23 12:23:33,386 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 78/79   Jobs: 1   Epoch: 9.75/10.0 (97.5% complete)   lr: 0.000180   
2021-10-23 12:23:43,976 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 79/79   Jobs: 1   Epoch: 9.88/10.0 (98.8% complete)   lr: 0.000170   
2021-10-23 12:23:54,624 [steps/nnet3/train_dnn.py:401 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 12:23:54,624 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 61, 62, 63]) models.
2021-10-23 12:24:06,397 [steps/nnet3/train_dnn.py:410 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2021-10-23 12:24:43,417 [steps/nnet3/train_dnn.py:421 - train - INFO ] Re-adjusting priors based on computed posteriors
2021-10-23 12:24:43,511 [steps/nnet3/train_dnn.py:431 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_mono_nochain_lda_ivector_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/nnet3/tdnn_mono_nochain_lda_ivector_sp/egs
exp/nnet3/tdnn_mono_nochain_lda_ivector_sp: num-iters=80 nj=1..1 num-params=8.1M dim=40+100->124 combine=-0.05->-0.03 (over 9) loglike:train/valid[52,79,combined]=(-0.089,-0.034,-0.027/-1.69,-1.84,-1.83) accuracy:train/valid[52,79,combined]=(0.9731,0.9924,0.9946/0.69,0.69,0.69)
[2021-10-23 12:24:43] run_propor.sh: ok
run_tdnn_mono_nochain_lda_noivector.sh: creating neural net configs
tree-info exp/mono_ali_train_sp/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs/network.xconfig --config-dir exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs
nnet3-init exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs/init.config exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs/init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs/init.raw
nnet3-info exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs/init.raw 
nnet3-init exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs/ref.config exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs/ref.raw 
nnet3-init exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs/ref.config exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/configs/ref.raw 
2021-10-23 12:24:44,277 [steps/nnet3/train_dnn.py:36 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir  --cleanup.remove-egs true --cleanup.preserve-model-interval 100 --feat-dir=data/train_sp_hires --ali-dir exp/mono_ali_train_sp --lang data/lang --reporting.email= --dir=exp/nnet3/tdnn_mono_nochain_lda_noivector_sp
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', '', '--cleanup.remove-egs', 'true', '--cleanup.preserve-model-interval', '100', '--feat-dir=data/train_sp_hires', '--ali-dir', 'exp/mono_ali_train_sp', '--lang', 'data/lang', '--reporting.email=', '--dir=exp/nnet3/tdnn_mono_nochain_lda_noivector_sp']
2021-10-23 12:24:44,293 [steps/nnet3/train_dnn.py:178 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/mono_ali_train_sp',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_mono_nochain_lda_noivector_sp',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': None,
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'input_model': None,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 10.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': [],
 'use_gpu': 'yes'}
2021-10-23 12:24:44,302 [steps/nnet3/train_dnn.py:228 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 12:24:44,349 [steps/nnet3/train_dnn.py:238 - train - INFO ] Generating egs
steps/nnet3/get_egs.sh --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 13 --right-context 13 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 8 --srand 0 data/train_sp_hires exp/mono_ali_train_sp exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/egs
File data/train_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
*** steps/nnet3/get_egs.sh: warning: the --frames-per-eg is too large to generate one archive with
*** as many as --samples-per-iter egs in it.  Consider reducing --frames-per-eg.
steps/nnet3/get_egs.sh: creating 1 archives, each with 110347 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (13,13)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/egs/ali.ark,exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/egs/ali.scp 
LOG (copy-int-vector[5.5.0~1-5caf]:main():copy-int-vector.cc:83) Copied 1890 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
2021-10-23 12:24:55,465 [steps/nnet3/train_dnn.py:276 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 12:24:56,684 [steps/nnet3/train_dnn.py:287 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2021-10-23 12:24:56,801 [steps/nnet3/train_dnn.py:294 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 12:24:57,079 [steps/nnet3/train_dnn.py:319 - train - INFO ] Training will run for 10.0 epochs = 80 iterations
2021-10-23 12:24:57,079 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 0/79   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.001700   
2021-10-23 12:25:08,170 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 1/79   Jobs: 1   Epoch: 0.12/10.0 (1.2% complete)   lr: 0.001652   
2021-10-23 12:25:18,635 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 2/79   Jobs: 1   Epoch: 0.25/10.0 (2.5% complete)   lr: 0.001605   
2021-10-23 12:25:29,125 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 3/79   Jobs: 1   Epoch: 0.38/10.0 (3.8% complete)   lr: 0.001559   
2021-10-23 12:25:39,616 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 4/79   Jobs: 1   Epoch: 0.50/10.0 (5.0% complete)   lr: 0.001515   
2021-10-23 12:25:50,127 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 5/79   Jobs: 1   Epoch: 0.62/10.0 (6.2% complete)   lr: 0.001472   
2021-10-23 12:26:00,686 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 6/79   Jobs: 1   Epoch: 0.75/10.0 (7.5% complete)   lr: 0.001430   
2021-10-23 12:26:11,243 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 7/79   Jobs: 1   Epoch: 0.88/10.0 (8.8% complete)   lr: 0.001390   
2021-10-23 12:26:21,840 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 8/79   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.001350   
2021-10-23 12:26:32,424 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 9/79   Jobs: 1   Epoch: 1.12/10.0 (11.2% complete)   lr: 0.001312   
2021-10-23 12:26:43,027 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 10/79   Jobs: 1   Epoch: 1.25/10.0 (12.5% complete)   lr: 0.001275   
2021-10-23 12:26:53,654 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 11/79   Jobs: 1   Epoch: 1.38/10.0 (13.8% complete)   lr: 0.001239   
2021-10-23 12:27:04,248 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 12/79   Jobs: 1   Epoch: 1.50/10.0 (15.0% complete)   lr: 0.001204   
2021-10-23 12:27:14,841 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 13/79   Jobs: 1   Epoch: 1.62/10.0 (16.2% complete)   lr: 0.001169   
2021-10-23 12:27:25,434 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 14/79   Jobs: 1   Epoch: 1.75/10.0 (17.5% complete)   lr: 0.001136   
2021-10-23 12:27:36,040 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 15/79   Jobs: 1   Epoch: 1.88/10.0 (18.8% complete)   lr: 0.001104   
2021-10-23 12:27:46,624 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 16/79   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.001073   
2021-10-23 12:27:57,210 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 17/79   Jobs: 1   Epoch: 2.12/10.0 (21.2% complete)   lr: 0.001042   
2021-10-23 12:28:07,784 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 18/79   Jobs: 1   Epoch: 2.25/10.0 (22.5% complete)   lr: 0.001013   
2021-10-23 12:28:18,350 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 19/79   Jobs: 1   Epoch: 2.38/10.0 (23.8% complete)   lr: 0.000984   
2021-10-23 12:28:28,931 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 20/79   Jobs: 1   Epoch: 2.50/10.0 (25.0% complete)   lr: 0.000956   
2021-10-23 12:28:40,348 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 21/79   Jobs: 1   Epoch: 2.62/10.0 (26.2% complete)   lr: 0.000929   
2021-10-23 12:28:50,768 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 22/79   Jobs: 1   Epoch: 2.75/10.0 (27.5% complete)   lr: 0.000903   
2021-10-23 12:29:01,381 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 23/79   Jobs: 1   Epoch: 2.88/10.0 (28.8% complete)   lr: 0.000877   
2021-10-23 12:29:11,948 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 24/79   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000852   
2021-10-23 12:29:22,501 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 25/79   Jobs: 1   Epoch: 3.12/10.0 (31.2% complete)   lr: 0.000828   
2021-10-23 12:29:33,057 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 26/79   Jobs: 1   Epoch: 3.25/10.0 (32.5% complete)   lr: 0.000804   
2021-10-23 12:29:43,639 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 27/79   Jobs: 1   Epoch: 3.38/10.0 (33.8% complete)   lr: 0.000782   
2021-10-23 12:29:54,193 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 28/79   Jobs: 1   Epoch: 3.50/10.0 (35.0% complete)   lr: 0.000759   
2021-10-23 12:30:04,764 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 29/79   Jobs: 1   Epoch: 3.62/10.0 (36.2% complete)   lr: 0.000738   
2021-10-23 12:30:15,317 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 30/79   Jobs: 1   Epoch: 3.75/10.0 (37.5% complete)   lr: 0.000717   
2021-10-23 12:30:25,914 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 31/79   Jobs: 1   Epoch: 3.88/10.0 (38.8% complete)   lr: 0.000697   
2021-10-23 12:30:36,537 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 32/79   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000677   
2021-10-23 12:30:47,064 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 33/79   Jobs: 1   Epoch: 4.12/10.0 (41.2% complete)   lr: 0.000658   
2021-10-23 12:30:57,658 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 34/79   Jobs: 1   Epoch: 4.25/10.0 (42.5% complete)   lr: 0.000639   
2021-10-23 12:31:08,221 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 35/79   Jobs: 1   Epoch: 4.38/10.0 (43.8% complete)   lr: 0.000621   
2021-10-23 12:31:18,783 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 36/79   Jobs: 1   Epoch: 4.50/10.0 (45.0% complete)   lr: 0.000603   
2021-10-23 12:31:29,333 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 37/79   Jobs: 1   Epoch: 4.62/10.0 (46.2% complete)   lr: 0.000586   
2021-10-23 12:31:39,930 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 38/79   Jobs: 1   Epoch: 4.75/10.0 (47.5% complete)   lr: 0.000569   
2021-10-23 12:31:50,523 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 39/79   Jobs: 1   Epoch: 4.88/10.0 (48.8% complete)   lr: 0.000553   
2021-10-23 12:32:01,084 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 40/79   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000538   
2021-10-23 12:32:12,534 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 41/79   Jobs: 1   Epoch: 5.12/10.0 (51.2% complete)   lr: 0.000522   
2021-10-23 12:32:23,114 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 42/79   Jobs: 1   Epoch: 5.25/10.0 (52.5% complete)   lr: 0.000508   
2021-10-23 12:32:33,744 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 43/79   Jobs: 1   Epoch: 5.38/10.0 (53.8% complete)   lr: 0.000493   
2021-10-23 12:32:44,355 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 44/79   Jobs: 1   Epoch: 5.50/10.0 (55.0% complete)   lr: 0.000479   
2021-10-23 12:32:54,961 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 45/79   Jobs: 1   Epoch: 5.62/10.0 (56.2% complete)   lr: 0.000466   
2021-10-23 12:33:05,548 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 46/79   Jobs: 1   Epoch: 5.75/10.0 (57.5% complete)   lr: 0.000452   
2021-10-23 12:33:16,134 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 47/79   Jobs: 1   Epoch: 5.88/10.0 (58.8% complete)   lr: 0.000439   
2021-10-23 12:33:26,743 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 48/79   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000427   
2021-10-23 12:33:37,319 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 49/79   Jobs: 1   Epoch: 6.12/10.0 (61.2% complete)   lr: 0.000415   
2021-10-23 12:33:47,894 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 50/79   Jobs: 1   Epoch: 6.25/10.0 (62.5% complete)   lr: 0.000403   
2021-10-23 12:33:58,523 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 51/79   Jobs: 1   Epoch: 6.38/10.0 (63.8% complete)   lr: 0.000392   
2021-10-23 12:34:09,113 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 52/79   Jobs: 1   Epoch: 6.50/10.0 (65.0% complete)   lr: 0.000381   
2021-10-23 12:34:19,711 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 53/79   Jobs: 1   Epoch: 6.62/10.0 (66.2% complete)   lr: 0.000370   
2021-10-23 12:34:30,307 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 54/79   Jobs: 1   Epoch: 6.75/10.0 (67.5% complete)   lr: 0.000359   
2021-10-23 12:34:40,914 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 55/79   Jobs: 1   Epoch: 6.88/10.0 (68.8% complete)   lr: 0.000349   
2021-10-23 12:34:51,528 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 56/79   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000339   
2021-10-23 12:35:02,107 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 57/79   Jobs: 1   Epoch: 7.12/10.0 (71.2% complete)   lr: 0.000330   
2021-10-23 12:35:12,711 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 58/79   Jobs: 1   Epoch: 7.25/10.0 (72.5% complete)   lr: 0.000320   
2021-10-23 12:35:23,343 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 59/79   Jobs: 1   Epoch: 7.38/10.0 (73.8% complete)   lr: 0.000311   
2021-10-23 12:35:33,933 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 60/79   Jobs: 1   Epoch: 7.50/10.0 (75.0% complete)   lr: 0.000302   
2021-10-23 12:35:45,336 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 61/79   Jobs: 1   Epoch: 7.62/10.0 (76.2% complete)   lr: 0.000294   
2021-10-23 12:35:55,770 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 62/79   Jobs: 1   Epoch: 7.75/10.0 (77.5% complete)   lr: 0.000285   
2021-10-23 12:36:06,347 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 63/79   Jobs: 1   Epoch: 7.88/10.0 (78.8% complete)   lr: 0.000277   
2021-10-23 12:36:16,896 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 64/79   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000269   
2021-10-23 12:36:27,472 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 65/79   Jobs: 1   Epoch: 8.12/10.0 (81.2% complete)   lr: 0.000262   
2021-10-23 12:36:38,055 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 66/79   Jobs: 1   Epoch: 8.25/10.0 (82.5% complete)   lr: 0.000254   
2021-10-23 12:36:48,638 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 67/79   Jobs: 1   Epoch: 8.38/10.0 (83.8% complete)   lr: 0.000247   
2021-10-23 12:36:59,207 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 68/79   Jobs: 1   Epoch: 8.50/10.0 (85.0% complete)   lr: 0.000240   
2021-10-23 12:37:09,782 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 69/79   Jobs: 1   Epoch: 8.62/10.0 (86.2% complete)   lr: 0.000233   
2021-10-23 12:37:20,338 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 70/79   Jobs: 1   Epoch: 8.75/10.0 (87.5% complete)   lr: 0.000227   
2021-10-23 12:37:30,957 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 71/79   Jobs: 1   Epoch: 8.88/10.0 (88.8% complete)   lr: 0.000220   
2021-10-23 12:37:41,530 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 72/79   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000214   
2021-10-23 12:37:52,096 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 73/79   Jobs: 1   Epoch: 9.12/10.0 (91.2% complete)   lr: 0.000208   
2021-10-23 12:38:02,627 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 74/79   Jobs: 1   Epoch: 9.25/10.0 (92.5% complete)   lr: 0.000202   
2021-10-23 12:38:13,179 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 75/79   Jobs: 1   Epoch: 9.38/10.0 (93.8% complete)   lr: 0.000196   
2021-10-23 12:38:23,739 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 76/79   Jobs: 1   Epoch: 9.50/10.0 (95.0% complete)   lr: 0.000191   
2021-10-23 12:38:34,302 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 77/79   Jobs: 1   Epoch: 9.62/10.0 (96.2% complete)   lr: 0.000185   
2021-10-23 12:38:44,835 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 78/79   Jobs: 1   Epoch: 9.75/10.0 (97.5% complete)   lr: 0.000180   
2021-10-23 12:38:55,400 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 79/79   Jobs: 1   Epoch: 9.88/10.0 (98.8% complete)   lr: 0.000170   
2021-10-23 12:39:05,991 [steps/nnet3/train_dnn.py:401 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 12:39:05,991 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 61, 62, 63]) models.
2021-10-23 12:39:17,575 [steps/nnet3/train_dnn.py:410 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2021-10-23 12:39:53,975 [steps/nnet3/train_dnn.py:421 - train - INFO ] Re-adjusting priors based on computed posteriors
2021-10-23 12:39:54,059 [steps/nnet3/train_dnn.py:431 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_mono_nochain_lda_noivector_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/nnet3/tdnn_mono_nochain_lda_noivector_sp/egs
exp/nnet3/tdnn_mono_nochain_lda_noivector_sp: num-iters=80 nj=1..1 num-params=7.8M dim=40->124 combine=-0.04->-0.02 (over 9) loglike:train/valid[52,79,combined]=(-0.094,-0.029,-0.024/-1.79,-1.95,-1.95) accuracy:train/valid[52,79,combined]=(0.970,0.9935,0.9964/0.68,0.69,0.69)
[2021-10-23 12:39:54] run_propor.sh: ok
run_tdnn_mono_chain_delta_ivector_fs3.sh --fb-num-epochs 10 --decode false
run_tdnn_mono_chain_delta_ivector_fs3.sh: creating lang directory with one state per phone.
run_tdnn_mono_chain_delta_ivector_fs3.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/mono exp/chain/mono_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/mono/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/mono_train_sp_lats/log/generate_lattices.*.log
22 warnings in exp/chain/mono_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/mono_ali_train_sp exp/chain/tree_sp_mono_chain_delta_ivector_fs3
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/mono_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/mono_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_mono_chain_delta_ivector_fs3.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_mono_chain_delta_ivector_fs3/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/configs/network.xconfig --config-dir exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/configs/
nnet3-init exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/configs//ref.config exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/configs//ref.config exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/configs//ref.raw 
2021-10-23 12:40:18,019 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 12:40:18,035 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/mono_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_mono_chain_delta_ivector_fs3',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 12:40:18,052 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 12:40:18,142 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_mono_chain_delta_ivector_fs3/final.mdl exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 12:40:18,312 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 15 --right-context 15 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp exp/chain/mono_train_sp_lats exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/tree 
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (15,15)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 12:40:30,459 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/egs to exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp
2021-10-23 12:40:30,459 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 12:40:30,754 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 30 iterations
2021-10-23 12:40:30,754 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/29   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 12:40:41,148 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/29   Jobs: 1   Epoch: 0.33/10.0 (3.3% complete)   lr: 0.000139   
2021-10-23 12:40:50,476 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/29   Jobs: 1   Epoch: 0.67/10.0 (6.7% complete)   lr: 0.000129   
2021-10-23 12:40:59,908 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/29   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 12:41:09,172 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/29   Jobs: 1   Epoch: 1.33/10.0 (13.3% complete)   lr: 0.000110   
2021-10-23 12:41:18,568 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/29   Jobs: 1   Epoch: 1.67/10.0 (16.7% complete)   lr: 0.000102   
2021-10-23 12:41:27,791 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/29   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 12:41:37,191 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/29   Jobs: 1   Epoch: 2.33/10.0 (23.3% complete)   lr: 0.000088   
2021-10-23 12:41:46,856 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/29   Jobs: 1   Epoch: 2.67/10.0 (26.7% complete)   lr: 0.000081   
2021-10-23 12:41:56,283 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/29   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 12:42:05,911 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 10/29   Jobs: 1   Epoch: 3.33/10.0 (33.3% complete)   lr: 0.000070   
2021-10-23 12:42:15,495 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 11/29   Jobs: 1   Epoch: 3.67/10.0 (36.7% complete)   lr: 0.000064   
2021-10-23 12:42:24,914 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 12/29   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 12:42:34,530 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 13/29   Jobs: 1   Epoch: 4.33/10.0 (43.3% complete)   lr: 0.000055   
2021-10-23 12:42:44,099 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 14/29   Jobs: 1   Epoch: 4.67/10.0 (46.7% complete)   lr: 0.000051   
2021-10-23 12:42:53,520 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 15/29   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 12:43:03,126 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 16/29   Jobs: 1   Epoch: 5.33/10.0 (53.3% complete)   lr: 0.000044   
2021-10-23 12:43:12,512 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 17/29   Jobs: 1   Epoch: 5.67/10.0 (56.7% complete)   lr: 0.000041   
2021-10-23 12:43:22,180 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 18/29   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 12:43:31,405 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 19/29   Jobs: 1   Epoch: 6.33/10.0 (63.3% complete)   lr: 0.000035   
2021-10-23 12:43:41,035 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 20/29   Jobs: 1   Epoch: 6.67/10.0 (66.7% complete)   lr: 0.000032   
2021-10-23 12:43:51,431 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 21/29   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 12:44:01,024 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 22/29   Jobs: 1   Epoch: 7.33/10.0 (73.3% complete)   lr: 0.000028   
2021-10-23 12:44:10,626 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 23/29   Jobs: 1   Epoch: 7.67/10.0 (76.7% complete)   lr: 0.000026   
2021-10-23 12:44:20,048 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 24/29   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 12:44:29,639 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 25/29   Jobs: 1   Epoch: 8.33/10.0 (83.3% complete)   lr: 0.000022   
2021-10-23 12:44:39,065 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 26/29   Jobs: 1   Epoch: 8.67/10.0 (86.7% complete)   lr: 0.000020   
2021-10-23 12:44:48,652 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 27/29   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000019   
2021-10-23 12:44:58,051 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 28/29   Jobs: 1   Epoch: 9.33/10.0 (93.3% complete)   lr: 0.000017   
2021-10-23 12:45:07,675 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 29/29   Jobs: 1   Epoch: 9.67/10.0 (96.7% complete)   lr: 0.000015   
2021-10-23 12:45:17,051 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 12:45:17,051 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) models.
2021-10-23 12:45:26,299 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/egs
exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp: num-iters=30 nj=1..1 num-params=8.9M dim=40+100->408 combine=-0.051->-0.051 (over 1) xent:train/valid[19,29]=(-1.58,-1.46/-1.72,-1.65) logprob:train/valid[19,29]=(-0.060,-0.048/-0.100,-0.091)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_mono_chain_delta_ivector_fs3 --lat-dir exp/chain/mono_train_sp_lats --dir exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_mono_chain_delta_ivector_fs3', '--lat-dir', 'exp/chain/mono_train_sp_lats', '--dir', 'exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp']
run_tdnn_mono_chain_delta_ivector_fs3.sh: success!
[2021-10-23 12:45:33] run_propor.sh: ok
run_tdnn_mono_chain_delta_noivector_fs3.sh --fb-num-epochs 10 --decode false
run_tdnn_mono_chain_delta_noivector_fs3.sh: creating lang directory with one state per phone.
run_tdnn_mono_chain_delta_noivector_fs3.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/mono exp/chain/mono_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/mono/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/mono_train_sp_lats/log/generate_lattices.*.log
22 warnings in exp/chain/mono_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/mono_ali_train_sp exp/chain/tree_sp_mono_chain_delta_noivector_fs3
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/mono_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/mono_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_mono_chain_delta_noivector_fs3.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_mono_chain_delta_noivector_fs3/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/configs/network.xconfig --config-dir exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/configs/
nnet3-init exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/configs//ref.config exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/configs//ref.config exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/configs//ref.raw 
2021-10-23 12:45:57,396 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 12:45:57,412 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/mono_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_mono_chain_delta_noivector_fs3',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 12:45:57,421 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 12:45:57,510 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_mono_chain_delta_noivector_fs3/final.mdl exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 12:45:57,700 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 15 --right-context 15 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp exp/chain/mono_train_sp_lats exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/tree 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (15,15)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 12:46:09,868 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/egs to exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp
2021-10-23 12:46:09,868 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 12:46:10,165 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 30 iterations
2021-10-23 12:46:10,165 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/29   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 12:46:20,518 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/29   Jobs: 1   Epoch: 0.33/10.0 (3.3% complete)   lr: 0.000139   
2021-10-23 12:46:29,798 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/29   Jobs: 1   Epoch: 0.67/10.0 (6.7% complete)   lr: 0.000129   
2021-10-23 12:46:39,101 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/29   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 12:46:48,382 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/29   Jobs: 1   Epoch: 1.33/10.0 (13.3% complete)   lr: 0.000110   
2021-10-23 12:46:57,685 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/29   Jobs: 1   Epoch: 1.67/10.0 (16.7% complete)   lr: 0.000102   
2021-10-23 12:47:07,015 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/29   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 12:47:16,322 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/29   Jobs: 1   Epoch: 2.33/10.0 (23.3% complete)   lr: 0.000088   
2021-10-23 12:47:25,812 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/29   Jobs: 1   Epoch: 2.67/10.0 (26.7% complete)   lr: 0.000081   
2021-10-23 12:47:35,270 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/29   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 12:47:44,600 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 10/29   Jobs: 1   Epoch: 3.33/10.0 (33.3% complete)   lr: 0.000070   
2021-10-23 12:47:54,059 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 11/29   Jobs: 1   Epoch: 3.67/10.0 (36.7% complete)   lr: 0.000064   
2021-10-23 12:48:03,418 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 12/29   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 12:48:12,793 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 13/29   Jobs: 1   Epoch: 4.33/10.0 (43.3% complete)   lr: 0.000055   
2021-10-23 12:48:22,183 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 14/29   Jobs: 1   Epoch: 4.67/10.0 (46.7% complete)   lr: 0.000051   
2021-10-23 12:48:31,560 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 15/29   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 12:48:40,939 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 16/29   Jobs: 1   Epoch: 5.33/10.0 (53.3% complete)   lr: 0.000044   
2021-10-23 12:48:50,320 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 17/29   Jobs: 1   Epoch: 5.67/10.0 (56.7% complete)   lr: 0.000041   
2021-10-23 12:48:59,683 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 18/29   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 12:49:09,083 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 19/29   Jobs: 1   Epoch: 6.33/10.0 (63.3% complete)   lr: 0.000035   
2021-10-23 12:49:18,454 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 20/29   Jobs: 1   Epoch: 6.67/10.0 (66.7% complete)   lr: 0.000032   
2021-10-23 12:49:28,802 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 21/29   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 12:49:38,321 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 22/29   Jobs: 1   Epoch: 7.33/10.0 (73.3% complete)   lr: 0.000028   
2021-10-23 12:49:47,663 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 23/29   Jobs: 1   Epoch: 7.67/10.0 (76.7% complete)   lr: 0.000026   
2021-10-23 12:49:57,068 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 24/29   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 12:50:06,437 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 25/29   Jobs: 1   Epoch: 8.33/10.0 (83.3% complete)   lr: 0.000022   
2021-10-23 12:50:15,795 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 26/29   Jobs: 1   Epoch: 8.67/10.0 (86.7% complete)   lr: 0.000020   
2021-10-23 12:50:25,158 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 27/29   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000019   
2021-10-23 12:50:34,586 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 28/29   Jobs: 1   Epoch: 9.33/10.0 (93.3% complete)   lr: 0.000017   
2021-10-23 12:50:43,953 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 29/29   Jobs: 1   Epoch: 9.67/10.0 (96.7% complete)   lr: 0.000015   
2021-10-23 12:50:53,299 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 12:50:53,299 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) models.
2021-10-23 12:51:02,357 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp/egs
exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp: num-iters=30 nj=1..1 num-params=8.8M dim=40->408 combine=-0.057->-0.057 (over 1) xent:train/valid[19,29]=(-1.63,-1.51/-1.72,-1.64) logprob:train/valid[19,29]=(-0.065,-0.053/-0.095,-0.086)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_mono_chain_delta_noivector_fs3 --lat-dir exp/chain/mono_train_sp_lats --dir exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_mono_chain_delta_noivector_fs3', '--lat-dir', 'exp/chain/mono_train_sp_lats', '--dir', 'exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp']
run_tdnn_mono_chain_delta_noivector_fs3.sh: success!
[2021-10-23 12:51:09] run_propor.sh: ok
run_tdnn_mono_chain_delta_ivector_nofs.sh --fb-num-epochs 10 --decode false
run_tdnn_mono_chain_delta_ivector_nofs.sh: creating lang directory with one state per phone.
run_tdnn_mono_chain_delta_ivector_nofs.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/mono exp/chain/mono_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/mono/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
22 warnings in exp/chain/mono_train_sp_lats/log/align_pass1.*.log
8 warnings in exp/chain/mono_train_sp_lats/log/generate_lattices.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 1 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/mono_ali_train_sp exp/chain/tree_sp_mono_chain_delta_ivector_nofs
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/mono_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/mono_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_mono_chain_delta_ivector_nofs.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_mono_chain_delta_ivector_nofs/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/configs/network.xconfig --config-dir exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/configs/
nnet3-init exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/configs//ref.config exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/configs//ref.config exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/configs//ref.raw 
2021-10-23 12:51:34,349 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 12:51:34,365 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 1,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 1,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/mono_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_mono_chain_delta_ivector_nofs',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 12:51:34,381 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 12:51:34,503 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_mono_chain_delta_ivector_nofs/final.mdl exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 12:51:34,709 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 1 --alignment-subsampling-factor 1 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp exp/chain/mono_train_sp_lats exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/tree 
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (14,14)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 12:51:47,818 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/egs to exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp
2021-10-23 12:51:47,818 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 12:51:48,116 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 10 iterations
2021-10-23 12:51:48,116 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/9   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 12:52:03,354 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/9   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 12:52:17,498 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/9   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 12:52:31,942 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/9   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 12:52:46,725 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/9   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 12:53:01,424 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/9   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 12:53:16,145 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/9   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 12:53:30,884 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/9   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 12:53:45,611 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/9   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 12:54:00,309 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/9   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000015   
2021-10-23 12:54:15,053 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 12:54:15,054 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([8, 9, 10, 6, 7]) models.
2021-10-23 12:54:21,799 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/egs
exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp: num-iters=10 nj=1..1 num-params=9.4M dim=40+100->1248 combine=-0.046->-0.046 (over 1) xent:train/valid[5,9]=(-2.98,-2.70/-3.02,-2.79) logprob:train/valid[5,9]=(-0.072,-0.046/-0.112,-0.087)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --chain.frame-subsampling-factor 1 --chain.alignment-subsampling-factor 1 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_mono_chain_delta_ivector_nofs --lat-dir exp/chain/mono_train_sp_lats --dir exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--chain.frame-subsampling-factor', '1', '--chain.alignment-subsampling-factor', '1', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_mono_chain_delta_ivector_nofs', '--lat-dir', 'exp/chain/mono_train_sp_lats', '--dir', 'exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp']
run_tdnn_mono_chain_delta_ivector_nofs.sh: success!
[2021-10-23 12:54:36] run_propor.sh: ok
run_tdnn_mono_chain_delta_noivector_nofs.sh --fb-num-epochs 10 --decode false
run_tdnn_mono_chain_delta_noivector_nofs.sh: creating lang directory with one state per phone.
run_tdnn_mono_chain_delta_noivector_nofs.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/mono exp/chain/mono_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/mono/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/mono_train_sp_lats/log/generate_lattices.*.log
22 warnings in exp/chain/mono_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 1 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/mono_ali_train_sp exp/chain/tree_sp_mono_chain_delta_noivector_nofs
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/mono_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/mono_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_mono_chain_delta_noivector_nofs.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_mono_chain_delta_noivector_nofs/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/configs/network.xconfig --config-dir exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/configs/
nnet3-init exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/configs//ref.config exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/configs//ref.config exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/configs//ref.raw 
2021-10-23 12:55:01,464 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 12:55:01,480 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 1,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 1,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/mono_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_mono_chain_delta_noivector_nofs',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 12:55:01,490 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 12:55:01,614 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_mono_chain_delta_noivector_nofs/final.mdl exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 12:55:01,805 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 1 --alignment-subsampling-factor 1 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp exp/chain/mono_train_sp_lats exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/tree 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (14,14)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 12:55:14,779 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/egs to exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp
2021-10-23 12:55:14,779 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 12:55:15,082 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 10 iterations
2021-10-23 12:55:15,082 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/9   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 12:55:30,524 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/9   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 12:55:44,667 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/9   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 12:55:59,018 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/9   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 12:56:13,735 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/9   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 12:56:28,359 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/9   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 12:56:42,993 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/9   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 12:56:57,633 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/9   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 12:57:12,277 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/9   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 12:57:26,941 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/9   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000015   
2021-10-23 12:57:41,584 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 12:57:41,584 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([8, 9, 10, 6, 7]) models.
2021-10-23 12:57:48,262 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp/egs
exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp: num-iters=10 nj=1..1 num-params=9.2M dim=40->1248 combine=-0.043->-0.043 (over 1) xent:train/valid[5,9]=(-2.88,-2.61/-2.92,-2.70) logprob:train/valid[5,9]=(-0.064,-0.045/-0.097,-0.077)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --chain.frame-subsampling-factor 1 --chain.alignment-subsampling-factor 1 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_mono_chain_delta_noivector_nofs --lat-dir exp/chain/mono_train_sp_lats --dir exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--chain.frame-subsampling-factor', '1', '--chain.alignment-subsampling-factor', '1', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_mono_chain_delta_noivector_nofs', '--lat-dir', 'exp/chain/mono_train_sp_lats', '--dir', 'exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp']
run_tdnn_mono_chain_delta_noivector_nofs.sh: success!
[2021-10-23 12:58:03] run_propor.sh: ok
run_tdnn_mono_nochain_delta_ivector.sh: creating neural net configs
tree-info exp/mono_ali_train_sp/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/configs/network.xconfig --config-dir exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/configs
nnet3-init exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/configs/ref.config exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/configs/ref.raw 
nnet3-init exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/configs/ref.config exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/configs/ref.raw 
2021-10-23 12:58:04,338 [steps/nnet3/train_dnn.py:36 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir  --cleanup.remove-egs true --cleanup.preserve-model-interval 100 --feat-dir=data/train_sp_hires --ali-dir exp/mono_ali_train_sp --lang data/lang --reporting.email= --dir=exp/nnet3/tdnn_mono_nochain_delta_ivector_sp
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', '', '--cleanup.remove-egs', 'true', '--cleanup.preserve-model-interval', '100', '--feat-dir=data/train_sp_hires', '--ali-dir', 'exp/mono_ali_train_sp', '--lang', 'data/lang', '--reporting.email=', '--dir=exp/nnet3/tdnn_mono_nochain_delta_ivector_sp']
2021-10-23 12:58:04,354 [steps/nnet3/train_dnn.py:178 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/mono_ali_train_sp',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_mono_nochain_delta_ivector_sp',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': None,
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'input_model': None,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 10.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': [],
 'use_gpu': 'yes'}
2021-10-23 12:58:04,370 [steps/nnet3/train_dnn.py:238 - train - INFO ] Generating egs
steps/nnet3/get_egs.sh --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 8 --srand 0 data/train_sp_hires exp/mono_ali_train_sp exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/egs
File data/train_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
*** steps/nnet3/get_egs.sh: warning: the --frames-per-eg is too large to generate one archive with
*** as many as --samples-per-iter egs in it.  Consider reducing --frames-per-eg.
steps/nnet3/get_egs.sh: creating 1 archives, each with 110347 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (14,14)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/egs/ali.ark,exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/egs/ali.scp 
LOG (copy-int-vector[5.5.0~1-5caf]:main():copy-int-vector.cc:83) Copied 1890 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
2021-10-23 12:58:15,897 [steps/nnet3/train_dnn.py:287 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2021-10-23 12:58:16,011 [steps/nnet3/train_dnn.py:294 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 12:58:16,294 [steps/nnet3/train_dnn.py:319 - train - INFO ] Training will run for 10.0 epochs = 80 iterations
2021-10-23 12:58:16,294 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 0/79   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.001700   
2021-10-23 12:58:27,997 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 1/79   Jobs: 1   Epoch: 0.12/10.0 (1.2% complete)   lr: 0.001652   
2021-10-23 12:58:38,683 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 2/79   Jobs: 1   Epoch: 0.25/10.0 (2.5% complete)   lr: 0.001605   
2021-10-23 12:58:49,304 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 3/79   Jobs: 1   Epoch: 0.38/10.0 (3.8% complete)   lr: 0.001559   
2021-10-23 12:58:59,987 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 4/79   Jobs: 1   Epoch: 0.50/10.0 (5.0% complete)   lr: 0.001515   
2021-10-23 12:59:10,656 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 5/79   Jobs: 1   Epoch: 0.62/10.0 (6.2% complete)   lr: 0.001472   
2021-10-23 12:59:21,322 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 6/79   Jobs: 1   Epoch: 0.75/10.0 (7.5% complete)   lr: 0.001430   
2021-10-23 12:59:32,020 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 7/79   Jobs: 1   Epoch: 0.88/10.0 (8.8% complete)   lr: 0.001390   
2021-10-23 12:59:42,737 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 8/79   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.001350   
2021-10-23 12:59:53,461 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 9/79   Jobs: 1   Epoch: 1.12/10.0 (11.2% complete)   lr: 0.001312   
2021-10-23 13:00:04,101 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 10/79   Jobs: 1   Epoch: 1.25/10.0 (12.5% complete)   lr: 0.001275   
2021-10-23 13:00:14,722 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 11/79   Jobs: 1   Epoch: 1.38/10.0 (13.8% complete)   lr: 0.001239   
2021-10-23 13:00:25,340 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 12/79   Jobs: 1   Epoch: 1.50/10.0 (15.0% complete)   lr: 0.001204   
2021-10-23 13:00:35,963 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 13/79   Jobs: 1   Epoch: 1.62/10.0 (16.2% complete)   lr: 0.001169   
2021-10-23 13:00:46,554 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 14/79   Jobs: 1   Epoch: 1.75/10.0 (17.5% complete)   lr: 0.001136   
2021-10-23 13:00:57,177 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 15/79   Jobs: 1   Epoch: 1.88/10.0 (18.8% complete)   lr: 0.001104   
2021-10-23 13:01:07,872 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 16/79   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.001073   
2021-10-23 13:01:18,451 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 17/79   Jobs: 1   Epoch: 2.12/10.0 (21.2% complete)   lr: 0.001042   
2021-10-23 13:01:29,061 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 18/79   Jobs: 1   Epoch: 2.25/10.0 (22.5% complete)   lr: 0.001013   
2021-10-23 13:01:39,674 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 19/79   Jobs: 1   Epoch: 2.38/10.0 (23.8% complete)   lr: 0.000984   
2021-10-23 13:01:50,418 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 20/79   Jobs: 1   Epoch: 2.50/10.0 (25.0% complete)   lr: 0.000956   
2021-10-23 13:02:01,817 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 21/79   Jobs: 1   Epoch: 2.62/10.0 (26.2% complete)   lr: 0.000929   
2021-10-23 13:02:12,587 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 22/79   Jobs: 1   Epoch: 2.75/10.0 (27.5% complete)   lr: 0.000903   
2021-10-23 13:02:23,299 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 23/79   Jobs: 1   Epoch: 2.88/10.0 (28.8% complete)   lr: 0.000877   
2021-10-23 13:02:33,941 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 24/79   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000852   
2021-10-23 13:02:44,561 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 25/79   Jobs: 1   Epoch: 3.12/10.0 (31.2% complete)   lr: 0.000828   
2021-10-23 13:02:55,191 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 26/79   Jobs: 1   Epoch: 3.25/10.0 (32.5% complete)   lr: 0.000804   
2021-10-23 13:03:05,801 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 27/79   Jobs: 1   Epoch: 3.38/10.0 (33.8% complete)   lr: 0.000782   
2021-10-23 13:03:16,457 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 28/79   Jobs: 1   Epoch: 3.50/10.0 (35.0% complete)   lr: 0.000759   
2021-10-23 13:03:27,041 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 29/79   Jobs: 1   Epoch: 3.62/10.0 (36.2% complete)   lr: 0.000738   
2021-10-23 13:03:37,650 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 30/79   Jobs: 1   Epoch: 3.75/10.0 (37.5% complete)   lr: 0.000717   
2021-10-23 13:03:48,385 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 31/79   Jobs: 1   Epoch: 3.88/10.0 (38.8% complete)   lr: 0.000697   
2021-10-23 13:03:58,975 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 32/79   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000677   
2021-10-23 13:04:09,604 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 33/79   Jobs: 1   Epoch: 4.12/10.0 (41.2% complete)   lr: 0.000658   
2021-10-23 13:04:20,207 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 34/79   Jobs: 1   Epoch: 4.25/10.0 (42.5% complete)   lr: 0.000639   
2021-10-23 13:04:30,820 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 35/79   Jobs: 1   Epoch: 4.38/10.0 (43.8% complete)   lr: 0.000621   
2021-10-23 13:04:41,468 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 36/79   Jobs: 1   Epoch: 4.50/10.0 (45.0% complete)   lr: 0.000603   
2021-10-23 13:04:52,115 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 37/79   Jobs: 1   Epoch: 4.62/10.0 (46.2% complete)   lr: 0.000586   
2021-10-23 13:05:02,712 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 38/79   Jobs: 1   Epoch: 4.75/10.0 (47.5% complete)   lr: 0.000569   
2021-10-23 13:05:13,303 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 39/79   Jobs: 1   Epoch: 4.88/10.0 (48.8% complete)   lr: 0.000553   
2021-10-23 13:05:23,934 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 40/79   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000538   
2021-10-23 13:05:35,434 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 41/79   Jobs: 1   Epoch: 5.12/10.0 (51.2% complete)   lr: 0.000522   
2021-10-23 13:05:46,193 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 42/79   Jobs: 1   Epoch: 5.25/10.0 (52.5% complete)   lr: 0.000508   
2021-10-23 13:05:56,928 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 43/79   Jobs: 1   Epoch: 5.38/10.0 (53.8% complete)   lr: 0.000493   
2021-10-23 13:06:07,517 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 44/79   Jobs: 1   Epoch: 5.50/10.0 (55.0% complete)   lr: 0.000479   
2021-10-23 13:06:18,195 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 45/79   Jobs: 1   Epoch: 5.62/10.0 (56.2% complete)   lr: 0.000466   
2021-10-23 13:06:28,790 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 46/79   Jobs: 1   Epoch: 5.75/10.0 (57.5% complete)   lr: 0.000452   
2021-10-23 13:06:39,400 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 47/79   Jobs: 1   Epoch: 5.88/10.0 (58.8% complete)   lr: 0.000439   
2021-10-23 13:06:50,042 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 48/79   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000427   
2021-10-23 13:07:00,654 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 49/79   Jobs: 1   Epoch: 6.12/10.0 (61.2% complete)   lr: 0.000415   
2021-10-23 13:07:11,291 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 50/79   Jobs: 1   Epoch: 6.25/10.0 (62.5% complete)   lr: 0.000403   
2021-10-23 13:07:21,929 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 51/79   Jobs: 1   Epoch: 6.38/10.0 (63.8% complete)   lr: 0.000392   
2021-10-23 13:07:32,507 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 52/79   Jobs: 1   Epoch: 6.50/10.0 (65.0% complete)   lr: 0.000381   
2021-10-23 13:07:43,107 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 53/79   Jobs: 1   Epoch: 6.62/10.0 (66.2% complete)   lr: 0.000370   
2021-10-23 13:07:53,799 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 54/79   Jobs: 1   Epoch: 6.75/10.0 (67.5% complete)   lr: 0.000359   
2021-10-23 13:08:04,395 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 55/79   Jobs: 1   Epoch: 6.88/10.0 (68.8% complete)   lr: 0.000349   
2021-10-23 13:08:15,024 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 56/79   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000339   
2021-10-23 13:08:25,677 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 57/79   Jobs: 1   Epoch: 7.12/10.0 (71.2% complete)   lr: 0.000330   
2021-10-23 13:08:36,241 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 58/79   Jobs: 1   Epoch: 7.25/10.0 (72.5% complete)   lr: 0.000320   
2021-10-23 13:08:46,954 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 59/79   Jobs: 1   Epoch: 7.38/10.0 (73.8% complete)   lr: 0.000311   
2021-10-23 13:08:57,560 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 60/79   Jobs: 1   Epoch: 7.50/10.0 (75.0% complete)   lr: 0.000302   
2021-10-23 13:09:09,095 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 61/79   Jobs: 1   Epoch: 7.62/10.0 (76.2% complete)   lr: 0.000294   
2021-10-23 13:09:19,913 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 62/79   Jobs: 1   Epoch: 7.75/10.0 (77.5% complete)   lr: 0.000285   
2021-10-23 13:09:30,640 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 63/79   Jobs: 1   Epoch: 7.88/10.0 (78.8% complete)   lr: 0.000277   
2021-10-23 13:09:41,244 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 64/79   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000269   
2021-10-23 13:09:51,878 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 65/79   Jobs: 1   Epoch: 8.12/10.0 (81.2% complete)   lr: 0.000262   
2021-10-23 13:10:02,524 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 66/79   Jobs: 1   Epoch: 8.25/10.0 (82.5% complete)   lr: 0.000254   
2021-10-23 13:10:13,231 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 67/79   Jobs: 1   Epoch: 8.38/10.0 (83.8% complete)   lr: 0.000247   
2021-10-23 13:10:23,801 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 68/79   Jobs: 1   Epoch: 8.50/10.0 (85.0% complete)   lr: 0.000240   
2021-10-23 13:10:34,411 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 69/79   Jobs: 1   Epoch: 8.62/10.0 (86.2% complete)   lr: 0.000233   
2021-10-23 13:10:45,078 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 70/79   Jobs: 1   Epoch: 8.75/10.0 (87.5% complete)   lr: 0.000227   
2021-10-23 13:10:55,691 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 71/79   Jobs: 1   Epoch: 8.88/10.0 (88.8% complete)   lr: 0.000220   
2021-10-23 13:11:06,354 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 72/79   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000214   
2021-10-23 13:11:16,992 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 73/79   Jobs: 1   Epoch: 9.12/10.0 (91.2% complete)   lr: 0.000208   
2021-10-23 13:11:27,598 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 74/79   Jobs: 1   Epoch: 9.25/10.0 (92.5% complete)   lr: 0.000202   
2021-10-23 13:11:38,224 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 75/79   Jobs: 1   Epoch: 9.38/10.0 (93.8% complete)   lr: 0.000196   
2021-10-23 13:11:48,828 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 76/79   Jobs: 1   Epoch: 9.50/10.0 (95.0% complete)   lr: 0.000191   
2021-10-23 13:11:59,452 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 77/79   Jobs: 1   Epoch: 9.62/10.0 (96.2% complete)   lr: 0.000185   
2021-10-23 13:12:10,054 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 78/79   Jobs: 1   Epoch: 9.75/10.0 (97.5% complete)   lr: 0.000180   
2021-10-23 13:12:20,661 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 79/79   Jobs: 1   Epoch: 9.88/10.0 (98.8% complete)   lr: 0.000170   
2021-10-23 13:12:31,307 [steps/nnet3/train_dnn.py:401 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 13:12:31,307 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 61, 62, 63]) models.
2021-10-23 13:12:43,235 [steps/nnet3/train_dnn.py:410 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2021-10-23 13:13:20,294 [steps/nnet3/train_dnn.py:421 - train - INFO ] Re-adjusting priors based on computed posteriors
2021-10-23 13:13:20,376 [steps/nnet3/train_dnn.py:431 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_mono_nochain_delta_ivector_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/nnet3/tdnn_mono_nochain_delta_ivector_sp/egs
exp/nnet3/tdnn_mono_nochain_delta_ivector_sp: num-iters=80 nj=1..1 num-params=8.0M dim=40+100->124 combine=-0.36->-0.35 (over 5) loglike:train/valid[52,79,combined]=(-0.39,-0.29,-0.28/-1.08,-1.13,-1.12) accuracy:train/valid[52,79,combined]=(0.861,0.896,0.899/0.69,0.70,0.70)
[2021-10-23 13:13:20] run_propor.sh: ok
run_tdnn_mono_nochain_delta_noivector.sh: creating neural net configs
tree-info exp/mono_ali_train_sp/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/configs/network.xconfig --config-dir exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/configs
nnet3-init exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/configs/ref.config exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/configs/ref.raw 
nnet3-init exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/configs/ref.config exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/configs/ref.raw 
2021-10-23 13:13:21,087 [steps/nnet3/train_dnn.py:36 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir  --cleanup.remove-egs true --cleanup.preserve-model-interval 100 --feat-dir=data/train_sp_hires --ali-dir exp/mono_ali_train_sp --lang data/lang --reporting.email= --dir=exp/nnet3/tdnn_mono_nochain_delta_noivector_sp
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', '', '--cleanup.remove-egs', 'true', '--cleanup.preserve-model-interval', '100', '--feat-dir=data/train_sp_hires', '--ali-dir', 'exp/mono_ali_train_sp', '--lang', 'data/lang', '--reporting.email=', '--dir=exp/nnet3/tdnn_mono_nochain_delta_noivector_sp']
2021-10-23 13:13:21,101 [steps/nnet3/train_dnn.py:178 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/mono_ali_train_sp',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_mono_nochain_delta_noivector_sp',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': None,
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'input_model': None,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 10.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': [],
 'use_gpu': 'yes'}
2021-10-23 13:13:21,111 [steps/nnet3/train_dnn.py:238 - train - INFO ] Generating egs
steps/nnet3/get_egs.sh --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 8 --srand 0 data/train_sp_hires exp/mono_ali_train_sp exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/egs
File data/train_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
*** steps/nnet3/get_egs.sh: warning: the --frames-per-eg is too large to generate one archive with
*** as many as --samples-per-iter egs in it.  Consider reducing --frames-per-eg.
steps/nnet3/get_egs.sh: creating 1 archives, each with 110347 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (14,14)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/egs/ali.ark,exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/egs/ali.scp 
LOG (copy-int-vector[5.5.0~1-5caf]:main():copy-int-vector.cc:83) Copied 1890 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
2021-10-23 13:13:32,293 [steps/nnet3/train_dnn.py:287 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2021-10-23 13:13:32,407 [steps/nnet3/train_dnn.py:294 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 13:13:32,689 [steps/nnet3/train_dnn.py:319 - train - INFO ] Training will run for 10.0 epochs = 80 iterations
2021-10-23 13:13:32,690 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 0/79   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.001700   
2021-10-23 13:13:44,354 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 1/79   Jobs: 1   Epoch: 0.12/10.0 (1.2% complete)   lr: 0.001652   
2021-10-23 13:13:54,855 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 2/79   Jobs: 1   Epoch: 0.25/10.0 (2.5% complete)   lr: 0.001605   
2021-10-23 13:14:05,385 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 3/79   Jobs: 1   Epoch: 0.38/10.0 (3.8% complete)   lr: 0.001559   
2021-10-23 13:14:15,947 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 4/79   Jobs: 1   Epoch: 0.50/10.0 (5.0% complete)   lr: 0.001515   
2021-10-23 13:14:26,534 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 5/79   Jobs: 1   Epoch: 0.62/10.0 (6.2% complete)   lr: 0.001472   
2021-10-23 13:14:37,152 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 6/79   Jobs: 1   Epoch: 0.75/10.0 (7.5% complete)   lr: 0.001430   
2021-10-23 13:14:47,777 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 7/79   Jobs: 1   Epoch: 0.88/10.0 (8.8% complete)   lr: 0.001390   
2021-10-23 13:14:58,407 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 8/79   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.001350   
2021-10-23 13:15:09,055 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 9/79   Jobs: 1   Epoch: 1.12/10.0 (11.2% complete)   lr: 0.001312   
2021-10-23 13:15:19,696 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 10/79   Jobs: 1   Epoch: 1.25/10.0 (12.5% complete)   lr: 0.001275   
2021-10-23 13:15:30,358 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 11/79   Jobs: 1   Epoch: 1.38/10.0 (13.8% complete)   lr: 0.001239   
2021-10-23 13:15:40,996 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 12/79   Jobs: 1   Epoch: 1.50/10.0 (15.0% complete)   lr: 0.001204   
2021-10-23 13:15:51,604 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 13/79   Jobs: 1   Epoch: 1.62/10.0 (16.2% complete)   lr: 0.001169   
2021-10-23 13:16:02,259 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 14/79   Jobs: 1   Epoch: 1.75/10.0 (17.5% complete)   lr: 0.001136   
2021-10-23 13:16:12,918 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 15/79   Jobs: 1   Epoch: 1.88/10.0 (18.8% complete)   lr: 0.001104   
2021-10-23 13:16:23,551 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 16/79   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.001073   
2021-10-23 13:16:34,185 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 17/79   Jobs: 1   Epoch: 2.12/10.0 (21.2% complete)   lr: 0.001042   
2021-10-23 13:16:44,836 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 18/79   Jobs: 1   Epoch: 2.25/10.0 (22.5% complete)   lr: 0.001013   
2021-10-23 13:16:55,444 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 19/79   Jobs: 1   Epoch: 2.38/10.0 (23.8% complete)   lr: 0.000984   
2021-10-23 13:17:06,089 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 20/79   Jobs: 1   Epoch: 2.50/10.0 (25.0% complete)   lr: 0.000956   
2021-10-23 13:17:17,619 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 21/79   Jobs: 1   Epoch: 2.62/10.0 (26.2% complete)   lr: 0.000929   
2021-10-23 13:17:28,058 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 22/79   Jobs: 1   Epoch: 2.75/10.0 (27.5% complete)   lr: 0.000903   
2021-10-23 13:17:38,634 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 23/79   Jobs: 1   Epoch: 2.88/10.0 (28.8% complete)   lr: 0.000877   
2021-10-23 13:17:49,245 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 24/79   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000852   
2021-10-23 13:17:59,865 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 25/79   Jobs: 1   Epoch: 3.12/10.0 (31.2% complete)   lr: 0.000828   
2021-10-23 13:18:10,448 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 26/79   Jobs: 1   Epoch: 3.25/10.0 (32.5% complete)   lr: 0.000804   
2021-10-23 13:18:21,068 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 27/79   Jobs: 1   Epoch: 3.38/10.0 (33.8% complete)   lr: 0.000782   
2021-10-23 13:18:31,672 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 28/79   Jobs: 1   Epoch: 3.50/10.0 (35.0% complete)   lr: 0.000759   
2021-10-23 13:18:42,265 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 29/79   Jobs: 1   Epoch: 3.62/10.0 (36.2% complete)   lr: 0.000738   
2021-10-23 13:18:52,898 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 30/79   Jobs: 1   Epoch: 3.75/10.0 (37.5% complete)   lr: 0.000717   
2021-10-23 13:19:03,533 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 31/79   Jobs: 1   Epoch: 3.88/10.0 (38.8% complete)   lr: 0.000697   
2021-10-23 13:19:14,132 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 32/79   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000677   
2021-10-23 13:19:24,746 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 33/79   Jobs: 1   Epoch: 4.12/10.0 (41.2% complete)   lr: 0.000658   
2021-10-23 13:19:35,351 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 34/79   Jobs: 1   Epoch: 4.25/10.0 (42.5% complete)   lr: 0.000639   
2021-10-23 13:19:45,975 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 35/79   Jobs: 1   Epoch: 4.38/10.0 (43.8% complete)   lr: 0.000621   
2021-10-23 13:19:56,582 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 36/79   Jobs: 1   Epoch: 4.50/10.0 (45.0% complete)   lr: 0.000603   
2021-10-23 13:20:07,179 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 37/79   Jobs: 1   Epoch: 4.62/10.0 (46.2% complete)   lr: 0.000586   
2021-10-23 13:20:17,815 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 38/79   Jobs: 1   Epoch: 4.75/10.0 (47.5% complete)   lr: 0.000569   
2021-10-23 13:20:28,403 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 39/79   Jobs: 1   Epoch: 4.88/10.0 (48.8% complete)   lr: 0.000553   
2021-10-23 13:20:39,004 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 40/79   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000538   
2021-10-23 13:20:50,542 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 41/79   Jobs: 1   Epoch: 5.12/10.0 (51.2% complete)   lr: 0.000522   
2021-10-23 13:21:01,175 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 42/79   Jobs: 1   Epoch: 5.25/10.0 (52.5% complete)   lr: 0.000508   
2021-10-23 13:21:11,828 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 43/79   Jobs: 1   Epoch: 5.38/10.0 (53.8% complete)   lr: 0.000493   
2021-10-23 13:21:22,478 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 44/79   Jobs: 1   Epoch: 5.50/10.0 (55.0% complete)   lr: 0.000479   
2021-10-23 13:21:33,101 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 45/79   Jobs: 1   Epoch: 5.62/10.0 (56.2% complete)   lr: 0.000466   
2021-10-23 13:21:43,748 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 46/79   Jobs: 1   Epoch: 5.75/10.0 (57.5% complete)   lr: 0.000452   
2021-10-23 13:21:54,375 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 47/79   Jobs: 1   Epoch: 5.88/10.0 (58.8% complete)   lr: 0.000439   
2021-10-23 13:22:05,023 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 48/79   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000427   
2021-10-23 13:22:15,651 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 49/79   Jobs: 1   Epoch: 6.12/10.0 (61.2% complete)   lr: 0.000415   
2021-10-23 13:22:26,315 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 50/79   Jobs: 1   Epoch: 6.25/10.0 (62.5% complete)   lr: 0.000403   
2021-10-23 13:22:36,958 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 51/79   Jobs: 1   Epoch: 6.38/10.0 (63.8% complete)   lr: 0.000392   
2021-10-23 13:22:47,592 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 52/79   Jobs: 1   Epoch: 6.50/10.0 (65.0% complete)   lr: 0.000381   
2021-10-23 13:22:58,239 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 53/79   Jobs: 1   Epoch: 6.62/10.0 (66.2% complete)   lr: 0.000370   
2021-10-23 13:23:08,862 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 54/79   Jobs: 1   Epoch: 6.75/10.0 (67.5% complete)   lr: 0.000359   
2021-10-23 13:23:19,511 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 55/79   Jobs: 1   Epoch: 6.88/10.0 (68.8% complete)   lr: 0.000349   
2021-10-23 13:23:30,138 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 56/79   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000339   
2021-10-23 13:23:40,747 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 57/79   Jobs: 1   Epoch: 7.12/10.0 (71.2% complete)   lr: 0.000330   
2021-10-23 13:23:51,408 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 58/79   Jobs: 1   Epoch: 7.25/10.0 (72.5% complete)   lr: 0.000320   
2021-10-23 13:24:02,047 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 59/79   Jobs: 1   Epoch: 7.38/10.0 (73.8% complete)   lr: 0.000311   
2021-10-23 13:24:12,695 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 60/79   Jobs: 1   Epoch: 7.50/10.0 (75.0% complete)   lr: 0.000302   
2021-10-23 13:24:24,202 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 61/79   Jobs: 1   Epoch: 7.62/10.0 (76.2% complete)   lr: 0.000294   
2021-10-23 13:24:34,642 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 62/79   Jobs: 1   Epoch: 7.75/10.0 (77.5% complete)   lr: 0.000285   
2021-10-23 13:24:45,285 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 63/79   Jobs: 1   Epoch: 7.88/10.0 (78.8% complete)   lr: 0.000277   
2021-10-23 13:24:55,866 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 64/79   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000269   
2021-10-23 13:25:06,513 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 65/79   Jobs: 1   Epoch: 8.12/10.0 (81.2% complete)   lr: 0.000262   
2021-10-23 13:25:17,121 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 66/79   Jobs: 1   Epoch: 8.25/10.0 (82.5% complete)   lr: 0.000254   
2021-10-23 13:25:27,712 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 67/79   Jobs: 1   Epoch: 8.38/10.0 (83.8% complete)   lr: 0.000247   
2021-10-23 13:25:38,307 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 68/79   Jobs: 1   Epoch: 8.50/10.0 (85.0% complete)   lr: 0.000240   
2021-10-23 13:25:48,910 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 69/79   Jobs: 1   Epoch: 8.62/10.0 (86.2% complete)   lr: 0.000233   
2021-10-23 13:25:59,492 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 70/79   Jobs: 1   Epoch: 8.75/10.0 (87.5% complete)   lr: 0.000227   
2021-10-23 13:26:10,119 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 71/79   Jobs: 1   Epoch: 8.88/10.0 (88.8% complete)   lr: 0.000220   
2021-10-23 13:26:20,722 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 72/79   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000214   
2021-10-23 13:26:31,322 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 73/79   Jobs: 1   Epoch: 9.12/10.0 (91.2% complete)   lr: 0.000208   
2021-10-23 13:26:41,926 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 74/79   Jobs: 1   Epoch: 9.25/10.0 (92.5% complete)   lr: 0.000202   
2021-10-23 13:26:52,518 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 75/79   Jobs: 1   Epoch: 9.38/10.0 (93.8% complete)   lr: 0.000196   
2021-10-23 13:27:03,120 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 76/79   Jobs: 1   Epoch: 9.50/10.0 (95.0% complete)   lr: 0.000191   
2021-10-23 13:27:13,751 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 77/79   Jobs: 1   Epoch: 9.62/10.0 (96.2% complete)   lr: 0.000185   
2021-10-23 13:27:24,346 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 78/79   Jobs: 1   Epoch: 9.75/10.0 (97.5% complete)   lr: 0.000180   
2021-10-23 13:27:34,938 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 79/79   Jobs: 1   Epoch: 9.88/10.0 (98.8% complete)   lr: 0.000170   
2021-10-23 13:27:45,543 [steps/nnet3/train_dnn.py:401 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 13:27:45,543 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 61, 62, 63]) models.
2021-10-23 13:27:57,475 [steps/nnet3/train_dnn.py:410 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2021-10-23 13:28:34,466 [steps/nnet3/train_dnn.py:421 - train - INFO ] Re-adjusting priors based on computed posteriors
2021-10-23 13:28:34,544 [steps/nnet3/train_dnn.py:431 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_mono_nochain_delta_noivector_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/nnet3/tdnn_mono_nochain_delta_noivector_sp/egs
exp/nnet3/tdnn_mono_nochain_delta_noivector_sp: num-iters=80 nj=1..1 num-params=7.8M dim=40->124 combine=-0.45->-0.43 (over 5) loglike:train/valid[52,79,combined]=(-0.49,-0.36,-0.36/-1.08,-1.11,-1.08) accuracy:train/valid[52,79,combined]=(0.828,0.871,0.874/0.68,0.69,0.69)
[2021-10-23 13:28:34] run_propor.sh: ok
run_tdnn_trideltas_chain_lda_ivector_fs3.sh --fb-num-epochs 10 --decode false
run_tdnn_trideltas_chain_lda_ivector_fs3.sh: creating lang directory with one state per phone.
run_tdnn_trideltas_chain_lda_ivector_fs3.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri1 exp/chain/tri1_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri1/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
10 warnings in exp/chain/tri1_train_sp_lats/log/align_pass1.*.log
8 warnings in exp/chain/tri1_train_sp_lats/log/generate_lattices.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri1_ali_train_sp exp/chain/tree_sp_trideltas_chain_lda_ivector_fs3
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri1_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri1_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trideltas_chain_lda_ivector_fs3.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trideltas_chain_lda_ivector_fs3/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs/
nnet3-init exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs//init.config exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs//init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs//init.raw
nnet3-info exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs//init.raw 
nnet3-init exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/configs//ref.raw 
2021-10-23 13:29:01,815 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 13:29:01,831 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri1_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trideltas_chain_lda_ivector_fs3',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 13:29:01,847 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 13:29:01,935 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trideltas_chain_lda_ivector_fs3/final.mdl exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 13:29:02,120 [steps/nnet3/chain/train.py:350 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 13:29:02,151 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp exp/chain/tri1_train_sp_lats exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/tree 
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (14,14)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 13:29:14,049 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/egs to exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp
2021-10-23 13:29:14,049 [steps/nnet3/chain/train.py:442 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 13:29:14,841 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 13:29:15,104 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 30 iterations
2021-10-23 13:29:15,104 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/29   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 13:29:25,460 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/29   Jobs: 1   Epoch: 0.33/10.0 (3.3% complete)   lr: 0.000139   
2021-10-23 13:29:34,724 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/29   Jobs: 1   Epoch: 0.67/10.0 (6.7% complete)   lr: 0.000129   
2021-10-23 13:29:44,037 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/29   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 13:29:53,374 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/29   Jobs: 1   Epoch: 1.33/10.0 (13.3% complete)   lr: 0.000110   
2021-10-23 13:30:02,678 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/29   Jobs: 1   Epoch: 1.67/10.0 (16.7% complete)   lr: 0.000102   
2021-10-23 13:30:12,022 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/29   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 13:30:21,331 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/29   Jobs: 1   Epoch: 2.33/10.0 (23.3% complete)   lr: 0.000088   
2021-10-23 13:30:30,842 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/29   Jobs: 1   Epoch: 2.67/10.0 (26.7% complete)   lr: 0.000081   
2021-10-23 13:30:40,201 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/29   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 13:30:49,756 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 10/29   Jobs: 1   Epoch: 3.33/10.0 (33.3% complete)   lr: 0.000070   
2021-10-23 13:30:59,108 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 11/29   Jobs: 1   Epoch: 3.67/10.0 (36.7% complete)   lr: 0.000064   
2021-10-23 13:31:08,670 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 12/29   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 13:31:18,024 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 13/29   Jobs: 1   Epoch: 4.33/10.0 (43.3% complete)   lr: 0.000055   
2021-10-23 13:31:27,563 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 14/29   Jobs: 1   Epoch: 4.67/10.0 (46.7% complete)   lr: 0.000051   
2021-10-23 13:31:36,882 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 15/29   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 13:31:46,445 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 16/29   Jobs: 1   Epoch: 5.33/10.0 (53.3% complete)   lr: 0.000044   
2021-10-23 13:31:55,809 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 17/29   Jobs: 1   Epoch: 5.67/10.0 (56.7% complete)   lr: 0.000041   
2021-10-23 13:32:05,376 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 18/29   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 13:32:14,718 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 19/29   Jobs: 1   Epoch: 6.33/10.0 (63.3% complete)   lr: 0.000035   
2021-10-23 13:32:24,276 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 20/29   Jobs: 1   Epoch: 6.67/10.0 (66.7% complete)   lr: 0.000032   
2021-10-23 13:32:34,589 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 21/29   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 13:32:44,078 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 22/29   Jobs: 1   Epoch: 7.33/10.0 (73.3% complete)   lr: 0.000028   
2021-10-23 13:32:53,602 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 23/29   Jobs: 1   Epoch: 7.67/10.0 (76.7% complete)   lr: 0.000026   
2021-10-23 13:33:02,938 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 24/29   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 13:33:12,495 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 25/29   Jobs: 1   Epoch: 8.33/10.0 (83.3% complete)   lr: 0.000022   
2021-10-23 13:33:21,852 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 26/29   Jobs: 1   Epoch: 8.67/10.0 (86.7% complete)   lr: 0.000020   
2021-10-23 13:33:31,395 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 27/29   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000019   
2021-10-23 13:33:40,778 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 28/29   Jobs: 1   Epoch: 9.33/10.0 (93.3% complete)   lr: 0.000017   
2021-10-23 13:33:50,336 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 29/29   Jobs: 1   Epoch: 9.67/10.0 (96.7% complete)   lr: 0.000015   
2021-10-23 13:33:59,679 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 13:33:59,679 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) models.
2021-10-23 13:34:08,511 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp/egs
exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp: num-iters=30 nj=1..1 num-params=8.9M dim=40+100->440 combine=-0.029->-0.029 (over 1) xent:train/valid[19,29]=(-1.30,-1.12/-1.67,-1.64) logprob:train/valid[19,29]=(-0.040,-0.031/-0.107,-0.107)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --egs.dir  --egs.stage -10 --egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trideltas_chain_lda_ivector_fs3 --lat-dir exp/chain/tri1_train_sp_lats --dir exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trideltas_chain_lda_ivector_fs3', '--lat-dir', 'exp/chain/tri1_train_sp_lats', '--dir', 'exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp']
run_tdnn_trideltas_chain_lda_ivector_fs3.sh: success
[2021-10-23 13:34:15] run_propor.sh: ok
run_tdnn_trideltas_chain_lda_noivector_fs3.sh --fb-num-epochs 10 --decode false
run_tdnn_trideltas_chain_lda_noivector_fs3.sh: creating lang directory with one state per phone.
run_tdnn_trideltas_chain_lda_noivector_fs3.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri1 exp/chain/tri1_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri1/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
10 warnings in exp/chain/tri1_train_sp_lats/log/align_pass1.*.log
8 warnings in exp/chain/tri1_train_sp_lats/log/generate_lattices.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri1_ali_train_sp exp/chain/tree_sp_trideltas_chain_lda_noivector_fs3
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri1_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri1_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trideltas_chain_lda_noivector_fs3.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trideltas_chain_lda_noivector_fs3/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs/
nnet3-init exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs//init.config exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs//init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs//init.raw
nnet3-info exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs//init.raw 
nnet3-init exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/configs//ref.raw 
2021-10-23 13:34:43,201 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 13:34:43,216 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri1_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trideltas_chain_lda_noivector_fs3',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 13:34:43,226 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 13:34:43,315 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trideltas_chain_lda_noivector_fs3/final.mdl exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 13:34:43,497 [steps/nnet3/chain/train.py:350 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 13:34:43,542 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp exp/chain/tri1_train_sp_lats exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/tree 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (14,14)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 13:34:55,369 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/egs to exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp
2021-10-23 13:34:55,369 [steps/nnet3/chain/train.py:442 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 13:34:55,909 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 13:34:56,172 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 30 iterations
2021-10-23 13:34:56,172 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/29   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 13:35:06,095 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/29   Jobs: 1   Epoch: 0.33/10.0 (3.3% complete)   lr: 0.000139   
2021-10-23 13:35:15,289 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/29   Jobs: 1   Epoch: 0.67/10.0 (6.7% complete)   lr: 0.000129   
2021-10-23 13:35:24,582 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/29   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 13:35:33,813 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/29   Jobs: 1   Epoch: 1.33/10.0 (13.3% complete)   lr: 0.000110   
2021-10-23 13:35:43,099 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/29   Jobs: 1   Epoch: 1.67/10.0 (16.7% complete)   lr: 0.000102   
2021-10-23 13:35:52,354 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/29   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 13:36:01,646 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/29   Jobs: 1   Epoch: 2.33/10.0 (23.3% complete)   lr: 0.000088   
2021-10-23 13:36:11,092 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/29   Jobs: 1   Epoch: 2.67/10.0 (26.7% complete)   lr: 0.000081   
2021-10-23 13:36:20,567 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/29   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 13:36:29,853 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 10/29   Jobs: 1   Epoch: 3.33/10.0 (33.3% complete)   lr: 0.000070   
2021-10-23 13:36:39,357 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 11/29   Jobs: 1   Epoch: 3.67/10.0 (36.7% complete)   lr: 0.000064   
2021-10-23 13:36:48,653 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 12/29   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 13:36:58,134 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 13/29   Jobs: 1   Epoch: 4.33/10.0 (43.3% complete)   lr: 0.000055   
2021-10-23 13:37:07,426 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 14/29   Jobs: 1   Epoch: 4.67/10.0 (46.7% complete)   lr: 0.000051   
2021-10-23 13:37:16,913 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 15/29   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 13:37:26,223 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 16/29   Jobs: 1   Epoch: 5.33/10.0 (53.3% complete)   lr: 0.000044   
2021-10-23 13:37:35,723 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 17/29   Jobs: 1   Epoch: 5.67/10.0 (56.7% complete)   lr: 0.000041   
2021-10-23 13:37:45,040 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 18/29   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 13:37:54,516 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 19/29   Jobs: 1   Epoch: 6.33/10.0 (63.3% complete)   lr: 0.000035   
2021-10-23 13:38:03,814 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 20/29   Jobs: 1   Epoch: 6.67/10.0 (66.7% complete)   lr: 0.000032   
2021-10-23 13:38:14,229 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 21/29   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 13:38:23,704 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 22/29   Jobs: 1   Epoch: 7.33/10.0 (73.3% complete)   lr: 0.000028   
2021-10-23 13:38:32,978 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 23/29   Jobs: 1   Epoch: 7.67/10.0 (76.7% complete)   lr: 0.000026   
2021-10-23 13:38:42,454 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 24/29   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 13:38:51,744 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 25/29   Jobs: 1   Epoch: 8.33/10.0 (83.3% complete)   lr: 0.000022   
2021-10-23 13:39:01,234 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 26/29   Jobs: 1   Epoch: 8.67/10.0 (86.7% complete)   lr: 0.000020   
2021-10-23 13:39:10,509 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 27/29   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000019   
2021-10-23 13:39:20,008 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 28/29   Jobs: 1   Epoch: 9.33/10.0 (93.3% complete)   lr: 0.000017   
2021-10-23 13:39:29,259 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 29/29   Jobs: 1   Epoch: 9.67/10.0 (96.7% complete)   lr: 0.000015   
2021-10-23 13:39:38,734 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 13:39:38,734 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) models.
2021-10-23 13:39:47,319 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp/egs
exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp: num-iters=30 nj=1..1 num-params=8.8M dim=40->440 combine=-0.030->-0.030 (over 1) xent:train/valid[19,29]=(-1.35,-1.19/-1.65,-1.60) logprob:train/valid[19,29]=(-0.040,-0.031/-0.103,-0.099)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trideltas_chain_lda_noivector_fs3 --lat-dir exp/chain/tri1_train_sp_lats --dir exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trideltas_chain_lda_noivector_fs3', '--lat-dir', 'exp/chain/tri1_train_sp_lats', '--dir', 'exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp']
run_tdnn_trideltas_chain_lda_noivector_fs3.sh: success
[2021-10-23 13:39:54] run_propor.sh: ok
run_tdnn_trideltas_chain_lda_ivector_nofs.sh --fb-num-epochs 10 --decode false
run_tdnn_trideltas_chain_lda_ivector_nofs.sh: creating lang directory with one state per phone.
run_tdnn_trideltas_chain_lda_ivector_nofs.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri1 exp/chain/tri1_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri1/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
10 warnings in exp/chain/tri1_train_sp_lats/log/align_pass1.*.log
8 warnings in exp/chain/tri1_train_sp_lats/log/generate_lattices.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 1 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri1_ali_train_sp exp/chain/tree_sp_trideltas_chain_lda_ivector_nofs
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri1_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri1_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trideltas_chain_lda_ivector_nofs.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trideltas_chain_lda_ivector_nofs/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs/
nnet3-init exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs//init.config exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs//init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs//init.raw
nnet3-info exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs//init.raw 
nnet3-init exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/configs//ref.raw 
2021-10-23 13:40:22,379 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 13:40:22,395 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 1,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 1,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri1_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trideltas_chain_lda_ivector_nofs',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 13:40:22,411 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 13:40:22,533 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trideltas_chain_lda_ivector_nofs/final.mdl exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 13:40:22,729 [steps/nnet3/chain/train.py:350 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 13:40:22,775 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 13 --right-context 13 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 1 --alignment-subsampling-factor 1 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp exp/chain/tri1_train_sp_lats exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/tree 
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (13,13)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 13:40:35,284 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/egs to exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp
2021-10-23 13:40:35,284 [steps/nnet3/chain/train.py:442 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 13:40:36,717 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 13:40:37,010 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 10 iterations
2021-10-23 13:40:37,010 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/9   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 13:40:52,254 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/9   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 13:41:06,508 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/9   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 13:41:21,042 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/9   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 13:41:35,843 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/9   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 13:41:50,561 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/9   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 13:42:05,347 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/9   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 13:42:20,164 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/9   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 13:42:34,961 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/9   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 13:42:49,620 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/9   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000015   
2021-10-23 13:43:04,317 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 13:43:04,317 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([8, 9, 10, 6, 7]) models.
2021-10-23 13:43:10,814 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp/egs
exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp: num-iters=10 nj=1..1 num-params=9.4M dim=40+100->1336 combine=-0.017->-0.017 (over 1) xent:train/valid[5,9]=(-2.07,-1.84/-2.53,-2.37) logprob:train/valid[5,9]=(-0.022,-0.018/-0.088,-0.082)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --chain.frame-subsampling-factor 1 --chain.alignment-subsampling-factor 1 --egs.dir  --egs.stage -10 --egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trideltas_chain_lda_ivector_nofs --lat-dir exp/chain/tri1_train_sp_lats --dir exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--chain.frame-subsampling-factor', '1', '--chain.alignment-subsampling-factor', '1', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trideltas_chain_lda_ivector_nofs', '--lat-dir', 'exp/chain/tri1_train_sp_lats', '--dir', 'exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp']
run_tdnn_trideltas_chain_lda_ivector_nofs.sh: success
[2021-10-23 13:43:26] run_propor.sh: ok
run_tdnn_trideltas_chain_lda_noivector_nofs.sh --fb-num-epochs 10 --decode false
run_tdnn_trideltas_chain_lda_noivector_nofs.sh: creating lang directory with one state per phone.
run_tdnn_trideltas_chain_lda_noivector_nofs.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri1 exp/chain/tri1_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri1/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/tri1_train_sp_lats/log/generate_lattices.*.log
10 warnings in exp/chain/tri1_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 1 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri1_ali_train_sp exp/chain/tree_sp_trideltas_chain_lda_noivector_nofs
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri1_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri1_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trideltas_chain_lda_noivector_nofs.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trideltas_chain_lda_noivector_nofs/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs/
nnet3-init exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs//init.config exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs//init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs//init.raw
nnet3-info exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs//init.raw 
nnet3-init exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/configs//ref.raw 
2021-10-23 13:43:54,177 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 13:43:54,192 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 1,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 1,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri1_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trideltas_chain_lda_noivector_nofs',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 13:43:54,202 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 13:43:54,324 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trideltas_chain_lda_noivector_nofs/final.mdl exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 13:43:54,516 [steps/nnet3/chain/train.py:350 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 13:43:54,546 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 13 --right-context 13 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 1 --alignment-subsampling-factor 1 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp exp/chain/tri1_train_sp_lats exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/tree 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (13,13)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 13:44:07,113 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/egs to exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp
2021-10-23 13:44:07,113 [steps/nnet3/chain/train.py:442 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 13:44:07,894 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 13:44:08,151 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 10 iterations
2021-10-23 13:44:08,151 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/9   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 13:44:23,406 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/9   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 13:44:37,591 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/9   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 13:44:52,018 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/9   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 13:45:06,763 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/9   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 13:45:21,391 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/9   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 13:45:36,063 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/9   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 13:45:50,735 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/9   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 13:46:05,370 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/9   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 13:46:20,067 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/9   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000015   
2021-10-23 13:46:34,728 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 13:46:34,728 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([8, 9, 10, 6, 7]) models.
2021-10-23 13:46:41,309 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp/egs
exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp: num-iters=10 nj=1..1 num-params=9.2M dim=40->1336 combine=-0.017->-0.017 (over 1) xent:train/valid[5,9]=(-2.09,-1.90/-2.44,-2.29) logprob:train/valid[5,9]=(-0.022,-0.018/-0.082,-0.076)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --chain.frame-subsampling-factor 1 --chain.alignment-subsampling-factor 1 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trideltas_chain_lda_noivector_nofs --lat-dir exp/chain/tri1_train_sp_lats --dir exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--chain.frame-subsampling-factor', '1', '--chain.alignment-subsampling-factor', '1', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trideltas_chain_lda_noivector_nofs', '--lat-dir', 'exp/chain/tri1_train_sp_lats', '--dir', 'exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp']
run_tdnn_trideltas_chain_lda_noivector_nofs.sh: success
[2021-10-23 13:46:56] run_propor.sh: ok
run_tdnn_trideltas_nochain_lda_ivector.sh: creating neural net configs
tree-info exp/tri1_ali_train_sp/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs/network.xconfig --config-dir exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs
nnet3-init exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs/init.config exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs/init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs/init.raw
nnet3-info exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs/init.raw 
nnet3-init exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs/ref.config exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs/ref.raw 
nnet3-init exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs/ref.config exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/configs/ref.raw 
2021-10-23 13:46:57,182 [steps/nnet3/train_dnn.py:36 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir  --cleanup.remove-egs true --cleanup.preserve-model-interval 100 --feat-dir=data/train_sp_hires --ali-dir exp/tri1_ali_train_sp --lang data/lang --reporting.email= --dir=exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', '', '--cleanup.remove-egs', 'true', '--cleanup.preserve-model-interval', '100', '--feat-dir=data/train_sp_hires', '--ali-dir', 'exp/tri1_ali_train_sp', '--lang', 'data/lang', '--reporting.email=', '--dir=exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp']
2021-10-23 13:46:57,197 [steps/nnet3/train_dnn.py:178 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/tri1_ali_train_sp',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': None,
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'input_model': None,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 10.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': [],
 'use_gpu': 'yes'}
2021-10-23 13:46:57,214 [steps/nnet3/train_dnn.py:228 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 13:46:57,269 [steps/nnet3/train_dnn.py:238 - train - INFO ] Generating egs
steps/nnet3/get_egs.sh --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 8 --srand 0 data/train_sp_hires exp/tri1_ali_train_sp exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/egs
File data/train_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
*** steps/nnet3/get_egs.sh: warning: the --frames-per-eg is too large to generate one archive with
*** as many as --samples-per-iter egs in it.  Consider reducing --frames-per-eg.
steps/nnet3/get_egs.sh: creating 1 archives, each with 110347 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (14,14)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/egs/ali.ark,exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/egs/ali.scp 
LOG (copy-int-vector[5.5.0~1-5caf]:main():copy-int-vector.cc:83) Copied 1890 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
2021-10-23 13:47:08,902 [steps/nnet3/train_dnn.py:276 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 13:47:11,429 [steps/nnet3/train_dnn.py:287 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2021-10-23 13:47:11,530 [steps/nnet3/train_dnn.py:294 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 13:47:11,805 [steps/nnet3/train_dnn.py:319 - train - INFO ] Training will run for 10.0 epochs = 80 iterations
2021-10-23 13:47:11,805 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 0/79   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.001700   
2021-10-23 13:47:23,584 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 1/79   Jobs: 1   Epoch: 0.12/10.0 (1.2% complete)   lr: 0.001652   
2021-10-23 13:47:34,251 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 2/79   Jobs: 1   Epoch: 0.25/10.0 (2.5% complete)   lr: 0.001605   
2021-10-23 13:47:44,931 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 3/79   Jobs: 1   Epoch: 0.38/10.0 (3.8% complete)   lr: 0.001559   
2021-10-23 13:47:55,613 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 4/79   Jobs: 1   Epoch: 0.50/10.0 (5.0% complete)   lr: 0.001515   
2021-10-23 13:48:06,340 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 5/79   Jobs: 1   Epoch: 0.62/10.0 (6.2% complete)   lr: 0.001472   
2021-10-23 13:48:17,063 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 6/79   Jobs: 1   Epoch: 0.75/10.0 (7.5% complete)   lr: 0.001430   
2021-10-23 13:48:27,684 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 7/79   Jobs: 1   Epoch: 0.88/10.0 (8.8% complete)   lr: 0.001390   
2021-10-23 13:48:38,344 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 8/79   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.001350   
2021-10-23 13:48:48,972 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 9/79   Jobs: 1   Epoch: 1.12/10.0 (11.2% complete)   lr: 0.001312   
2021-10-23 13:48:59,600 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 10/79   Jobs: 1   Epoch: 1.25/10.0 (12.5% complete)   lr: 0.001275   
2021-10-23 13:49:10,244 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 11/79   Jobs: 1   Epoch: 1.38/10.0 (13.8% complete)   lr: 0.001239   
2021-10-23 13:49:20,862 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 12/79   Jobs: 1   Epoch: 1.50/10.0 (15.0% complete)   lr: 0.001204   
2021-10-23 13:49:31,482 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 13/79   Jobs: 1   Epoch: 1.62/10.0 (16.2% complete)   lr: 0.001169   
2021-10-23 13:49:42,102 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 14/79   Jobs: 1   Epoch: 1.75/10.0 (17.5% complete)   lr: 0.001136   
2021-10-23 13:49:52,761 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 15/79   Jobs: 1   Epoch: 1.88/10.0 (18.8% complete)   lr: 0.001104   
2021-10-23 13:50:03,389 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 16/79   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.001073   
2021-10-23 13:50:14,011 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 17/79   Jobs: 1   Epoch: 2.12/10.0 (21.2% complete)   lr: 0.001042   
2021-10-23 13:50:24,613 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 18/79   Jobs: 1   Epoch: 2.25/10.0 (22.5% complete)   lr: 0.001013   
2021-10-23 13:50:35,238 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 19/79   Jobs: 1   Epoch: 2.38/10.0 (23.8% complete)   lr: 0.000984   
2021-10-23 13:50:45,865 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 20/79   Jobs: 1   Epoch: 2.50/10.0 (25.0% complete)   lr: 0.000956   
2021-10-23 13:50:57,349 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 21/79   Jobs: 1   Epoch: 2.62/10.0 (26.2% complete)   lr: 0.000929   
2021-10-23 13:51:08,180 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 22/79   Jobs: 1   Epoch: 2.75/10.0 (27.5% complete)   lr: 0.000903   
2021-10-23 13:51:18,958 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 23/79   Jobs: 1   Epoch: 2.88/10.0 (28.8% complete)   lr: 0.000877   
2021-10-23 13:51:29,599 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 24/79   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000852   
2021-10-23 13:51:40,225 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 25/79   Jobs: 1   Epoch: 3.12/10.0 (31.2% complete)   lr: 0.000828   
2021-10-23 13:51:50,834 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 26/79   Jobs: 1   Epoch: 3.25/10.0 (32.5% complete)   lr: 0.000804   
2021-10-23 13:52:01,462 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 27/79   Jobs: 1   Epoch: 3.38/10.0 (33.8% complete)   lr: 0.000782   
2021-10-23 13:52:12,069 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 28/79   Jobs: 1   Epoch: 3.50/10.0 (35.0% complete)   lr: 0.000759   
2021-10-23 13:52:22,724 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 29/79   Jobs: 1   Epoch: 3.62/10.0 (36.2% complete)   lr: 0.000738   
2021-10-23 13:52:33,363 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 30/79   Jobs: 1   Epoch: 3.75/10.0 (37.5% complete)   lr: 0.000717   
2021-10-23 13:52:44,022 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 31/79   Jobs: 1   Epoch: 3.88/10.0 (38.8% complete)   lr: 0.000697   
2021-10-23 13:52:54,686 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 32/79   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000677   
2021-10-23 13:53:05,330 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 33/79   Jobs: 1   Epoch: 4.12/10.0 (41.2% complete)   lr: 0.000658   
2021-10-23 13:53:15,938 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 34/79   Jobs: 1   Epoch: 4.25/10.0 (42.5% complete)   lr: 0.000639   
2021-10-23 13:53:26,569 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 35/79   Jobs: 1   Epoch: 4.38/10.0 (43.8% complete)   lr: 0.000621   
2021-10-23 13:53:37,191 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 36/79   Jobs: 1   Epoch: 4.50/10.0 (45.0% complete)   lr: 0.000603   
2021-10-23 13:53:47,801 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 37/79   Jobs: 1   Epoch: 4.62/10.0 (46.2% complete)   lr: 0.000586   
2021-10-23 13:53:58,479 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 38/79   Jobs: 1   Epoch: 4.75/10.0 (47.5% complete)   lr: 0.000569   
2021-10-23 13:54:09,129 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 39/79   Jobs: 1   Epoch: 4.88/10.0 (48.8% complete)   lr: 0.000553   
2021-10-23 13:54:19,768 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 40/79   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000538   
2021-10-23 13:54:31,271 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 41/79   Jobs: 1   Epoch: 5.12/10.0 (51.2% complete)   lr: 0.000522   
2021-10-23 13:54:42,077 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 42/79   Jobs: 1   Epoch: 5.25/10.0 (52.5% complete)   lr: 0.000508   
2021-10-23 13:54:52,862 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 43/79   Jobs: 1   Epoch: 5.38/10.0 (53.8% complete)   lr: 0.000493   
2021-10-23 13:55:03,525 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 44/79   Jobs: 1   Epoch: 5.50/10.0 (55.0% complete)   lr: 0.000479   
2021-10-23 13:55:14,172 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 45/79   Jobs: 1   Epoch: 5.62/10.0 (56.2% complete)   lr: 0.000466   
2021-10-23 13:55:24,791 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 46/79   Jobs: 1   Epoch: 5.75/10.0 (57.5% complete)   lr: 0.000452   
2021-10-23 13:55:35,431 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 47/79   Jobs: 1   Epoch: 5.88/10.0 (58.8% complete)   lr: 0.000439   
2021-10-23 13:55:46,092 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 48/79   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000427   
2021-10-23 13:55:56,695 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 49/79   Jobs: 1   Epoch: 6.12/10.0 (61.2% complete)   lr: 0.000415   
2021-10-23 13:56:07,342 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 50/79   Jobs: 1   Epoch: 6.25/10.0 (62.5% complete)   lr: 0.000403   
2021-10-23 13:56:17,983 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 51/79   Jobs: 1   Epoch: 6.38/10.0 (63.8% complete)   lr: 0.000392   
2021-10-23 13:56:28,625 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 52/79   Jobs: 1   Epoch: 6.50/10.0 (65.0% complete)   lr: 0.000381   
2021-10-23 13:56:39,264 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 53/79   Jobs: 1   Epoch: 6.62/10.0 (66.2% complete)   lr: 0.000370   
2021-10-23 13:56:49,898 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 54/79   Jobs: 1   Epoch: 6.75/10.0 (67.5% complete)   lr: 0.000359   
2021-10-23 13:57:00,585 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 55/79   Jobs: 1   Epoch: 6.88/10.0 (68.8% complete)   lr: 0.000349   
2021-10-23 13:57:11,222 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 56/79   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000339   
2021-10-23 13:57:21,858 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 57/79   Jobs: 1   Epoch: 7.12/10.0 (71.2% complete)   lr: 0.000330   
2021-10-23 13:57:32,518 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 58/79   Jobs: 1   Epoch: 7.25/10.0 (72.5% complete)   lr: 0.000320   
2021-10-23 13:57:43,162 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 59/79   Jobs: 1   Epoch: 7.38/10.0 (73.8% complete)   lr: 0.000311   
2021-10-23 13:57:53,827 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 60/79   Jobs: 1   Epoch: 7.50/10.0 (75.0% complete)   lr: 0.000302   
2021-10-23 13:58:05,313 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 61/79   Jobs: 1   Epoch: 7.62/10.0 (76.2% complete)   lr: 0.000294   
2021-10-23 13:58:16,120 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 62/79   Jobs: 1   Epoch: 7.75/10.0 (77.5% complete)   lr: 0.000285   
2021-10-23 13:58:26,899 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 63/79   Jobs: 1   Epoch: 7.88/10.0 (78.8% complete)   lr: 0.000277   
2021-10-23 13:58:37,512 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 64/79   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000269   
2021-10-23 13:58:48,156 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 65/79   Jobs: 1   Epoch: 8.12/10.0 (81.2% complete)   lr: 0.000262   
2021-10-23 13:58:58,775 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 66/79   Jobs: 1   Epoch: 8.25/10.0 (82.5% complete)   lr: 0.000254   
2021-10-23 13:59:09,429 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 67/79   Jobs: 1   Epoch: 8.38/10.0 (83.8% complete)   lr: 0.000247   
2021-10-23 13:59:20,093 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 68/79   Jobs: 1   Epoch: 8.50/10.0 (85.0% complete)   lr: 0.000240   
2021-10-23 13:59:30,736 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 69/79   Jobs: 1   Epoch: 8.62/10.0 (86.2% complete)   lr: 0.000233   
2021-10-23 13:59:41,392 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 70/79   Jobs: 1   Epoch: 8.75/10.0 (87.5% complete)   lr: 0.000227   
2021-10-23 13:59:52,072 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 71/79   Jobs: 1   Epoch: 8.88/10.0 (88.8% complete)   lr: 0.000220   
2021-10-23 14:00:02,724 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 72/79   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000214   
2021-10-23 14:00:13,344 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 73/79   Jobs: 1   Epoch: 9.12/10.0 (91.2% complete)   lr: 0.000208   
2021-10-23 14:00:23,980 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 74/79   Jobs: 1   Epoch: 9.25/10.0 (92.5% complete)   lr: 0.000202   
2021-10-23 14:00:34,608 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 75/79   Jobs: 1   Epoch: 9.38/10.0 (93.8% complete)   lr: 0.000196   
2021-10-23 14:00:45,249 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 76/79   Jobs: 1   Epoch: 9.50/10.0 (95.0% complete)   lr: 0.000191   
2021-10-23 14:00:55,869 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 77/79   Jobs: 1   Epoch: 9.62/10.0 (96.2% complete)   lr: 0.000185   
2021-10-23 14:01:06,502 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 78/79   Jobs: 1   Epoch: 9.75/10.0 (97.5% complete)   lr: 0.000180   
2021-10-23 14:01:17,148 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 79/79   Jobs: 1   Epoch: 9.88/10.0 (98.8% complete)   lr: 0.000170   
2021-10-23 14:01:27,809 [steps/nnet3/train_dnn.py:401 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 14:01:27,809 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 61, 62, 63]) models.
2021-10-23 14:01:39,597 [steps/nnet3/train_dnn.py:410 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2021-10-23 14:02:20,101 [steps/nnet3/train_dnn.py:421 - train - INFO ] Re-adjusting priors based on computed posteriors
2021-10-23 14:02:20,185 [steps/nnet3/train_dnn.py:431 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp/egs
exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp: num-iters=80 nj=1..1 num-params=8.2M dim=40+100->640 combine=-0.05->-0.04 (over 9) loglike:train/valid[52,79,combined]=(-0.066,-0.035,-0.029/-1.96,-2.03,-2.00) accuracy:train/valid[52,79,combined]=(0.9851,0.9941,0.9969/0.61,0.61,0.61)
run_tdnn_trideltas_nochain_lda_ivector.sh: success
[2021-10-23 14:02:20] run_propor.sh: ok
run_tdnn_trideltas_nochain_lda_noivector.sh: creating neural net configs
tree-info exp/tri1_ali_train_sp/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs/network.xconfig --config-dir exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs
nnet3-init exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs/init.config exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs/init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs/init.raw
nnet3-info exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs/init.raw 
nnet3-init exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs/ref.config exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs/ref.raw 
nnet3-init exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs/ref.config exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/configs/ref.raw 
2021-10-23 14:02:20,983 [steps/nnet3/train_dnn.py:36 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir  --cleanup.remove-egs true --cleanup.preserve-model-interval 100 --feat-dir=data/train_sp_hires --ali-dir exp/tri1_ali_train_sp --lang data/lang --reporting.email= --dir=exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', '', '--cleanup.remove-egs', 'true', '--cleanup.preserve-model-interval', '100', '--feat-dir=data/train_sp_hires', '--ali-dir', 'exp/tri1_ali_train_sp', '--lang', 'data/lang', '--reporting.email=', '--dir=exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp']
2021-10-23 14:02:20,998 [steps/nnet3/train_dnn.py:178 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/tri1_ali_train_sp',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': None,
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'input_model': None,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 10.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': [],
 'use_gpu': 'yes'}
2021-10-23 14:02:21,007 [steps/nnet3/train_dnn.py:228 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 14:02:21,074 [steps/nnet3/train_dnn.py:238 - train - INFO ] Generating egs
steps/nnet3/get_egs.sh --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 13 --right-context 13 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 8 --srand 0 data/train_sp_hires exp/tri1_ali_train_sp exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/egs
File data/train_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
*** steps/nnet3/get_egs.sh: warning: the --frames-per-eg is too large to generate one archive with
*** as many as --samples-per-iter egs in it.  Consider reducing --frames-per-eg.
steps/nnet3/get_egs.sh: creating 1 archives, each with 110347 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (13,13)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/egs/ali.ark,exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/egs/ali.scp 
LOG (copy-int-vector[5.5.0~1-5caf]:main():copy-int-vector.cc:83) Copied 1890 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
2021-10-23 14:02:32,336 [steps/nnet3/train_dnn.py:276 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 14:02:33,592 [steps/nnet3/train_dnn.py:287 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2021-10-23 14:02:33,713 [steps/nnet3/train_dnn.py:294 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 14:02:34,021 [steps/nnet3/train_dnn.py:319 - train - INFO ] Training will run for 10.0 epochs = 80 iterations
2021-10-23 14:02:34,021 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 0/79   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.001700   
2021-10-23 14:02:45,605 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 1/79   Jobs: 1   Epoch: 0.12/10.0 (1.2% complete)   lr: 0.001652   
2021-10-23 14:02:56,098 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 2/79   Jobs: 1   Epoch: 0.25/10.0 (2.5% complete)   lr: 0.001605   
2021-10-23 14:03:06,625 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 3/79   Jobs: 1   Epoch: 0.38/10.0 (3.8% complete)   lr: 0.001559   
2021-10-23 14:03:17,160 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 4/79   Jobs: 1   Epoch: 0.50/10.0 (5.0% complete)   lr: 0.001515   
2021-10-23 14:03:27,717 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 5/79   Jobs: 1   Epoch: 0.62/10.0 (6.2% complete)   lr: 0.001472   
2021-10-23 14:03:38,276 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 6/79   Jobs: 1   Epoch: 0.75/10.0 (7.5% complete)   lr: 0.001430   
2021-10-23 14:03:48,850 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 7/79   Jobs: 1   Epoch: 0.88/10.0 (8.8% complete)   lr: 0.001390   
2021-10-23 14:04:03,465 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 8/79   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.001350   
2021-10-23 14:04:13,864 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 9/79   Jobs: 1   Epoch: 1.12/10.0 (11.2% complete)   lr: 0.001312   
2021-10-23 14:04:24,447 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 10/79   Jobs: 1   Epoch: 1.25/10.0 (12.5% complete)   lr: 0.001275   
2021-10-23 14:04:35,054 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 11/79   Jobs: 1   Epoch: 1.38/10.0 (13.8% complete)   lr: 0.001239   
2021-10-23 14:04:45,611 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 12/79   Jobs: 1   Epoch: 1.50/10.0 (15.0% complete)   lr: 0.001204   
2021-10-23 14:04:56,213 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 13/79   Jobs: 1   Epoch: 1.62/10.0 (16.2% complete)   lr: 0.001169   
2021-10-23 14:05:06,814 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 14/79   Jobs: 1   Epoch: 1.75/10.0 (17.5% complete)   lr: 0.001136   
2021-10-23 14:05:17,390 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 15/79   Jobs: 1   Epoch: 1.88/10.0 (18.8% complete)   lr: 0.001104   
2021-10-23 14:05:27,941 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 16/79   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.001073   
2021-10-23 14:05:38,545 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 17/79   Jobs: 1   Epoch: 2.12/10.0 (21.2% complete)   lr: 0.001042   
2021-10-23 14:05:49,105 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 18/79   Jobs: 1   Epoch: 2.25/10.0 (22.5% complete)   lr: 0.001013   
2021-10-23 14:05:59,658 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 19/79   Jobs: 1   Epoch: 2.38/10.0 (23.8% complete)   lr: 0.000984   
2021-10-23 14:06:10,215 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 20/79   Jobs: 1   Epoch: 2.50/10.0 (25.0% complete)   lr: 0.000956   
2021-10-23 14:06:21,629 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 21/79   Jobs: 1   Epoch: 2.62/10.0 (26.2% complete)   lr: 0.000929   
2021-10-23 14:06:32,234 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 22/79   Jobs: 1   Epoch: 2.75/10.0 (27.5% complete)   lr: 0.000903   
2021-10-23 14:06:42,868 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 23/79   Jobs: 1   Epoch: 2.88/10.0 (28.8% complete)   lr: 0.000877   
2021-10-23 14:06:53,488 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 24/79   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000852   
2021-10-23 14:07:04,090 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 25/79   Jobs: 1   Epoch: 3.12/10.0 (31.2% complete)   lr: 0.000828   
2021-10-23 14:07:14,667 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 26/79   Jobs: 1   Epoch: 3.25/10.0 (32.5% complete)   lr: 0.000804   
2021-10-23 14:07:25,281 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 27/79   Jobs: 1   Epoch: 3.38/10.0 (33.8% complete)   lr: 0.000782   
2021-10-23 14:07:35,866 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 28/79   Jobs: 1   Epoch: 3.50/10.0 (35.0% complete)   lr: 0.000759   
2021-10-23 14:07:46,485 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 29/79   Jobs: 1   Epoch: 3.62/10.0 (36.2% complete)   lr: 0.000738   
2021-10-23 14:07:57,121 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 30/79   Jobs: 1   Epoch: 3.75/10.0 (37.5% complete)   lr: 0.000717   
2021-10-23 14:08:07,737 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 31/79   Jobs: 1   Epoch: 3.88/10.0 (38.8% complete)   lr: 0.000697   
2021-10-23 14:08:18,347 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 32/79   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000677   
2021-10-23 14:08:28,964 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 33/79   Jobs: 1   Epoch: 4.12/10.0 (41.2% complete)   lr: 0.000658   
2021-10-23 14:08:39,568 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 34/79   Jobs: 1   Epoch: 4.25/10.0 (42.5% complete)   lr: 0.000639   
2021-10-23 14:08:50,204 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 35/79   Jobs: 1   Epoch: 4.38/10.0 (43.8% complete)   lr: 0.000621   
2021-10-23 14:09:00,827 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 36/79   Jobs: 1   Epoch: 4.50/10.0 (45.0% complete)   lr: 0.000603   
2021-10-23 14:09:11,427 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 37/79   Jobs: 1   Epoch: 4.62/10.0 (46.2% complete)   lr: 0.000586   
2021-10-23 14:09:22,017 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 38/79   Jobs: 1   Epoch: 4.75/10.0 (47.5% complete)   lr: 0.000569   
2021-10-23 14:09:32,657 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 39/79   Jobs: 1   Epoch: 4.88/10.0 (48.8% complete)   lr: 0.000553   
2021-10-23 14:09:43,267 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 40/79   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000538   
2021-10-23 14:09:54,731 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 41/79   Jobs: 1   Epoch: 5.12/10.0 (51.2% complete)   lr: 0.000522   
2021-10-23 14:10:05,167 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 42/79   Jobs: 1   Epoch: 5.25/10.0 (52.5% complete)   lr: 0.000508   
2021-10-23 14:10:15,784 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 43/79   Jobs: 1   Epoch: 5.38/10.0 (53.8% complete)   lr: 0.000493   
2021-10-23 14:10:26,364 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 44/79   Jobs: 1   Epoch: 5.50/10.0 (55.0% complete)   lr: 0.000479   
2021-10-23 14:10:36,960 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 45/79   Jobs: 1   Epoch: 5.62/10.0 (56.2% complete)   lr: 0.000466   
2021-10-23 14:10:47,545 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 46/79   Jobs: 1   Epoch: 5.75/10.0 (57.5% complete)   lr: 0.000452   
2021-10-23 14:10:58,145 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 47/79   Jobs: 1   Epoch: 5.88/10.0 (58.8% complete)   lr: 0.000439   
2021-10-23 14:11:08,737 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 48/79   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000427   
2021-10-23 14:11:19,335 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 49/79   Jobs: 1   Epoch: 6.12/10.0 (61.2% complete)   lr: 0.000415   
2021-10-23 14:11:29,905 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 50/79   Jobs: 1   Epoch: 6.25/10.0 (62.5% complete)   lr: 0.000403   
2021-10-23 14:11:40,509 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 51/79   Jobs: 1   Epoch: 6.38/10.0 (63.8% complete)   lr: 0.000392   
2021-10-23 14:11:51,108 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 52/79   Jobs: 1   Epoch: 6.50/10.0 (65.0% complete)   lr: 0.000381   
2021-10-23 14:12:01,710 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 53/79   Jobs: 1   Epoch: 6.62/10.0 (66.2% complete)   lr: 0.000370   
2021-10-23 14:12:12,309 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 54/79   Jobs: 1   Epoch: 6.75/10.0 (67.5% complete)   lr: 0.000359   
2021-10-23 14:12:22,881 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 55/79   Jobs: 1   Epoch: 6.88/10.0 (68.8% complete)   lr: 0.000349   
2021-10-23 14:12:33,467 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 56/79   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000339   
2021-10-23 14:12:44,064 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 57/79   Jobs: 1   Epoch: 7.12/10.0 (71.2% complete)   lr: 0.000330   
2021-10-23 14:12:54,637 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 58/79   Jobs: 1   Epoch: 7.25/10.0 (72.5% complete)   lr: 0.000320   
2021-10-23 14:13:05,231 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 59/79   Jobs: 1   Epoch: 7.38/10.0 (73.8% complete)   lr: 0.000311   
2021-10-23 14:13:15,834 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 60/79   Jobs: 1   Epoch: 7.50/10.0 (75.0% complete)   lr: 0.000302   
2021-10-23 14:13:27,264 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 61/79   Jobs: 1   Epoch: 7.62/10.0 (76.2% complete)   lr: 0.000294   
2021-10-23 14:13:37,867 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 62/79   Jobs: 1   Epoch: 7.75/10.0 (77.5% complete)   lr: 0.000285   
2021-10-23 14:13:48,485 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 63/79   Jobs: 1   Epoch: 7.88/10.0 (78.8% complete)   lr: 0.000277   
2021-10-23 14:13:59,101 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 64/79   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000269   
2021-10-23 14:14:09,717 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 65/79   Jobs: 1   Epoch: 8.12/10.0 (81.2% complete)   lr: 0.000262   
2021-10-23 14:14:20,345 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 66/79   Jobs: 1   Epoch: 8.25/10.0 (82.5% complete)   lr: 0.000254   
2021-10-23 14:14:30,951 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 67/79   Jobs: 1   Epoch: 8.38/10.0 (83.8% complete)   lr: 0.000247   
2021-10-23 14:14:41,572 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 68/79   Jobs: 1   Epoch: 8.50/10.0 (85.0% complete)   lr: 0.000240   
2021-10-23 14:14:52,196 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 69/79   Jobs: 1   Epoch: 8.62/10.0 (86.2% complete)   lr: 0.000233   
2021-10-23 14:15:02,825 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 70/79   Jobs: 1   Epoch: 8.75/10.0 (87.5% complete)   lr: 0.000227   
2021-10-23 14:15:13,472 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 71/79   Jobs: 1   Epoch: 8.88/10.0 (88.8% complete)   lr: 0.000220   
2021-10-23 14:15:24,078 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 72/79   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000214   
2021-10-23 14:15:34,705 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 73/79   Jobs: 1   Epoch: 9.12/10.0 (91.2% complete)   lr: 0.000208   
2021-10-23 14:15:45,322 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 74/79   Jobs: 1   Epoch: 9.25/10.0 (92.5% complete)   lr: 0.000202   
2021-10-23 14:15:55,942 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 75/79   Jobs: 1   Epoch: 9.38/10.0 (93.8% complete)   lr: 0.000196   
2021-10-23 14:16:06,578 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 76/79   Jobs: 1   Epoch: 9.50/10.0 (95.0% complete)   lr: 0.000191   
2021-10-23 14:16:17,215 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 77/79   Jobs: 1   Epoch: 9.62/10.0 (96.2% complete)   lr: 0.000185   
2021-10-23 14:16:27,819 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 78/79   Jobs: 1   Epoch: 9.75/10.0 (97.5% complete)   lr: 0.000180   
2021-10-23 14:16:38,422 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 79/79   Jobs: 1   Epoch: 9.88/10.0 (98.8% complete)   lr: 0.000170   
2021-10-23 14:16:49,046 [steps/nnet3/train_dnn.py:401 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 14:16:49,046 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 61, 62, 63]) models.
2021-10-23 14:17:00,727 [steps/nnet3/train_dnn.py:410 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2021-10-23 14:17:40,508 [steps/nnet3/train_dnn.py:421 - train - INFO ] Re-adjusting priors based on computed posteriors
2021-10-23 14:17:40,588 [steps/nnet3/train_dnn.py:431 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp/egs
exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp: num-iters=80 nj=1..1 num-params=7.9M dim=40->640 combine=-0.03->-0.02 (over 3) loglike:train/valid[52,79,combined]=(-0.067,-0.026,-0.022/-2.12,-2.20,-2.19) accuracy:train/valid[52,79,combined]=(0.9841,0.9972,0.9982/0.58,0.58,0.58)
run_tdnn_trideltas_nochain_lda_noivector.sh: success
[2021-10-23 14:17:40] run_propor.sh: ok
run_tdnn_trideltas_chain_delta_ivector_fs3.sh --fb-num-epochs 10 --decode false
run_tdnn_trideltas_chain_delta_ivector_fs3.sh: creating lang directory with one state per phone.
run_tdnn_trideltas_chain_delta_ivector_fs3.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri1 exp/chain/tri1_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri1/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/tri1_train_sp_lats/log/generate_lattices.*.log
10 warnings in exp/chain/tri1_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri1_ali_train_sp exp/chain/tree_sp_trideltas_chain_delta_ivector_fs3
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri1_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri1_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trideltas_chain_delta_ivector_fs3.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trideltas_chain_delta_ivector_fs3/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/configs/
nnet3-init exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/configs//ref.raw 
2021-10-23 14:18:08,256 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 14:18:08,272 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri1_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trideltas_chain_delta_ivector_fs3',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 14:18:08,288 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 14:18:08,374 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trideltas_chain_delta_ivector_fs3/final.mdl exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 14:18:08,555 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 15 --right-context 15 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp exp/chain/tri1_train_sp_lats exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/tree 
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (15,15)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 14:18:20,515 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/egs to exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp
2021-10-23 14:18:20,515 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 14:18:20,801 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 30 iterations
2021-10-23 14:18:20,801 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/29   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 14:18:31,180 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/29   Jobs: 1   Epoch: 0.33/10.0 (3.3% complete)   lr: 0.000139   
2021-10-23 14:18:40,482 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/29   Jobs: 1   Epoch: 0.67/10.0 (6.7% complete)   lr: 0.000129   
2021-10-23 14:18:49,919 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/29   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 14:18:59,232 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/29   Jobs: 1   Epoch: 1.33/10.0 (13.3% complete)   lr: 0.000110   
2021-10-23 14:19:08,602 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/29   Jobs: 1   Epoch: 1.67/10.0 (16.7% complete)   lr: 0.000102   
2021-10-23 14:19:17,903 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/29   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 14:19:27,281 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/29   Jobs: 1   Epoch: 2.33/10.0 (23.3% complete)   lr: 0.000088   
2021-10-23 14:19:36,802 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/29   Jobs: 1   Epoch: 2.67/10.0 (26.7% complete)   lr: 0.000081   
2021-10-23 14:19:46,385 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/29   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 14:19:55,762 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 10/29   Jobs: 1   Epoch: 3.33/10.0 (33.3% complete)   lr: 0.000070   
2021-10-23 14:20:05,343 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 11/29   Jobs: 1   Epoch: 3.67/10.0 (36.7% complete)   lr: 0.000064   
2021-10-23 14:20:14,733 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 12/29   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 14:20:24,311 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 13/29   Jobs: 1   Epoch: 4.33/10.0 (43.3% complete)   lr: 0.000055   
2021-10-23 14:20:33,695 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 14/29   Jobs: 1   Epoch: 4.67/10.0 (46.7% complete)   lr: 0.000051   
2021-10-23 14:20:43,264 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 15/29   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 14:20:52,669 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 16/29   Jobs: 1   Epoch: 5.33/10.0 (53.3% complete)   lr: 0.000044   
2021-10-23 14:21:02,278 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 17/29   Jobs: 1   Epoch: 5.67/10.0 (56.7% complete)   lr: 0.000041   
2021-10-23 14:21:11,653 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 18/29   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 14:21:21,255 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 19/29   Jobs: 1   Epoch: 6.33/10.0 (63.3% complete)   lr: 0.000035   
2021-10-23 14:21:30,660 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 20/29   Jobs: 1   Epoch: 6.67/10.0 (66.7% complete)   lr: 0.000032   
2021-10-23 14:21:41,217 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 21/29   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 14:21:50,794 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 22/29   Jobs: 1   Epoch: 7.33/10.0 (73.3% complete)   lr: 0.000028   
2021-10-23 14:22:00,191 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 23/29   Jobs: 1   Epoch: 7.67/10.0 (76.7% complete)   lr: 0.000026   
2021-10-23 14:22:09,768 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 24/29   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 14:22:19,170 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 25/29   Jobs: 1   Epoch: 8.33/10.0 (83.3% complete)   lr: 0.000022   
2021-10-23 14:22:28,750 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 26/29   Jobs: 1   Epoch: 8.67/10.0 (86.7% complete)   lr: 0.000020   
2021-10-23 14:22:38,130 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 27/29   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000019   
2021-10-23 14:22:47,698 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 28/29   Jobs: 1   Epoch: 9.33/10.0 (93.3% complete)   lr: 0.000017   
2021-10-23 14:22:57,063 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 29/29   Jobs: 1   Epoch: 9.67/10.0 (96.7% complete)   lr: 0.000015   
2021-10-23 14:23:06,650 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 14:23:06,651 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) models.
2021-10-23 14:23:15,618 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp/egs
exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp: num-iters=30 nj=1..1 num-params=8.9M dim=40+100->440 combine=-0.053->-0.053 (over 1) xent:train/valid[19,29]=(-1.63,-1.50/-1.80,-1.72) logprob:train/valid[19,29]=(-0.062,-0.051/-0.103,-0.093)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --egs.dir  --egs.stage -10 --egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trideltas_chain_delta_ivector_fs3 --lat-dir exp/chain/tri1_train_sp_lats --dir exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trideltas_chain_delta_ivector_fs3', '--lat-dir', 'exp/chain/tri1_train_sp_lats', '--dir', 'exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp']
run_tdnn_trideltas_chain_delta_ivector_fs3.sh: success
[2021-10-23 14:23:22] run_propor.sh: ok
run_tdnn_trideltas_chain_delta_noivector_fs3.sh --fb-num-epochs 10 --decode false
run_tdnn_trideltas_chain_delta_noivector_fs3.sh: creating lang directory with one state per phone.
run_tdnn_trideltas_chain_delta_noivector_fs3.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri1 exp/chain/tri1_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri1/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/tri1_train_sp_lats/log/generate_lattices.*.log
10 warnings in exp/chain/tri1_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri1_ali_train_sp exp/chain/tree_sp_trideltas_chain_delta_noivector_fs3
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri1_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri1_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trideltas_chain_delta_noivector_fs3.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trideltas_chain_delta_noivector_fs3/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/configs/
nnet3-init exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/configs//ref.raw 
2021-10-23 14:23:50,343 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 14:23:50,358 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri1_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trideltas_chain_delta_noivector_fs3',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 14:23:50,368 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 14:23:50,467 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trideltas_chain_delta_noivector_fs3/final.mdl exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 14:23:50,659 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 15 --right-context 15 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp exp/chain/tri1_train_sp_lats exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/tree 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (15,15)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 14:24:02,567 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/egs to exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp
2021-10-23 14:24:02,567 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 14:24:02,858 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 30 iterations
2021-10-23 14:24:02,858 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/29   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 14:24:13,200 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/29   Jobs: 1   Epoch: 0.33/10.0 (3.3% complete)   lr: 0.000139   
2021-10-23 14:24:22,512 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/29   Jobs: 1   Epoch: 0.67/10.0 (6.7% complete)   lr: 0.000129   
2021-10-23 14:24:31,768 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/29   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 14:24:41,093 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/29   Jobs: 1   Epoch: 1.33/10.0 (13.3% complete)   lr: 0.000110   
2021-10-23 14:24:50,385 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/29   Jobs: 1   Epoch: 1.67/10.0 (16.7% complete)   lr: 0.000102   
2021-10-23 14:24:59,701 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/29   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 14:25:08,971 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/29   Jobs: 1   Epoch: 2.33/10.0 (23.3% complete)   lr: 0.000088   
2021-10-23 14:25:18,479 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/29   Jobs: 1   Epoch: 2.67/10.0 (26.7% complete)   lr: 0.000081   
2021-10-23 14:25:27,871 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/29   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 14:25:37,385 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 10/29   Jobs: 1   Epoch: 3.33/10.0 (33.3% complete)   lr: 0.000070   
2021-10-23 14:25:46,728 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 11/29   Jobs: 1   Epoch: 3.67/10.0 (36.7% complete)   lr: 0.000064   
2021-10-23 14:25:56,245 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 12/29   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 14:26:05,581 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 13/29   Jobs: 1   Epoch: 4.33/10.0 (43.3% complete)   lr: 0.000055   
2021-10-23 14:26:15,106 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 14/29   Jobs: 1   Epoch: 4.67/10.0 (46.7% complete)   lr: 0.000051   
2021-10-23 14:26:24,424 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 15/29   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 14:26:33,953 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 16/29   Jobs: 1   Epoch: 5.33/10.0 (53.3% complete)   lr: 0.000044   
2021-10-23 14:26:43,287 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 17/29   Jobs: 1   Epoch: 5.67/10.0 (56.7% complete)   lr: 0.000041   
2021-10-23 14:26:52,783 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 18/29   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 14:27:02,105 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 19/29   Jobs: 1   Epoch: 6.33/10.0 (63.3% complete)   lr: 0.000035   
2021-10-23 14:27:11,616 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 20/29   Jobs: 1   Epoch: 6.67/10.0 (66.7% complete)   lr: 0.000032   
2021-10-23 14:27:21,908 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 21/29   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 14:27:31,362 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 22/29   Jobs: 1   Epoch: 7.33/10.0 (73.3% complete)   lr: 0.000028   
2021-10-23 14:27:40,858 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 23/29   Jobs: 1   Epoch: 7.67/10.0 (76.7% complete)   lr: 0.000026   
2021-10-23 14:27:50,194 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 24/29   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 14:27:59,703 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 25/29   Jobs: 1   Epoch: 8.33/10.0 (83.3% complete)   lr: 0.000022   
2021-10-23 14:28:09,022 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 26/29   Jobs: 1   Epoch: 8.67/10.0 (86.7% complete)   lr: 0.000020   
2021-10-23 14:28:18,522 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 27/29   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000019   
2021-10-23 14:28:27,862 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 28/29   Jobs: 1   Epoch: 9.33/10.0 (93.3% complete)   lr: 0.000017   
2021-10-23 14:28:37,400 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 29/29   Jobs: 1   Epoch: 9.67/10.0 (96.7% complete)   lr: 0.000015   
2021-10-23 14:28:46,698 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 14:28:46,698 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) models.
2021-10-23 14:28:55,843 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp/egs
exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp: num-iters=30 nj=1..1 num-params=8.8M dim=40->440 combine=-0.059->-0.059 (over 1) xent:train/valid[19,29]=(-1.69,-1.56/-1.80,-1.71) logprob:train/valid[19,29]=(-0.067,-0.055/-0.099,-0.090)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trideltas_chain_delta_noivector_fs3 --lat-dir exp/chain/tri1_train_sp_lats --dir exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trideltas_chain_delta_noivector_fs3', '--lat-dir', 'exp/chain/tri1_train_sp_lats', '--dir', 'exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp']
run_tdnn_trideltas_chain_delta_noivector_fs3.sh: success
[2021-10-23 14:29:02] run_propor.sh: ok
run_tdnn_trideltas_chain_delta_ivector_nofs.sh --fb-num-epochs 10 --decode false
run_tdnn_trideltas_chain_delta_ivector_nofs.sh: creating lang directory with one state per phone.
run_tdnn_trideltas_chain_delta_ivector_nofs.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri1 exp/chain/tri1_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri1/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/tri1_train_sp_lats/log/generate_lattices.*.log
10 warnings in exp/chain/tri1_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 1 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri1_ali_train_sp exp/chain/tree_sp_trideltas_chain_delta_ivector_nofs
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri1_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri1_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trideltas_chain_delta_ivector_nofs.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trideltas_chain_delta_ivector_nofs/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/configs/
nnet3-init exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/configs//ref.raw 
2021-10-23 14:29:30,951 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 14:29:30,967 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 1,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 1,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri1_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trideltas_chain_delta_ivector_nofs',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 14:29:30,982 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 14:29:31,104 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trideltas_chain_delta_ivector_nofs/final.mdl exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 14:29:31,294 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 1 --alignment-subsampling-factor 1 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp exp/chain/tri1_train_sp_lats exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/tree 
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (14,14)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 14:29:43,850 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/egs to exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp
2021-10-23 14:29:43,850 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 14:29:44,172 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 10 iterations
2021-10-23 14:29:44,172 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/9   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 14:29:59,698 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/9   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 14:30:13,917 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/9   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 14:30:28,478 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/9   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 14:30:43,332 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/9   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 14:30:57,968 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/9   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 14:31:12,672 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/9   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 14:31:27,316 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/9   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 14:31:41,996 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/9   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 14:31:56,716 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/9   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000015   
2021-10-23 14:32:11,347 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 14:32:11,347 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([8, 9, 10, 6, 7]) models.
2021-10-23 14:32:17,862 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp/egs
exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp: num-iters=10 nj=1..1 num-params=9.4M dim=40+100->1336 combine=-0.046->-0.046 (over 1) xent:train/valid[5,9]=(-2.98,-2.71/-3.04,-2.81) logprob:train/valid[5,9]=(-0.070,-0.047/-0.117,-0.090)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --chain.frame-subsampling-factor 1 --chain.alignment-subsampling-factor 1 --egs.dir  --egs.stage -10 --egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trideltas_chain_delta_ivector_nofs --lat-dir exp/chain/tri1_train_sp_lats --dir exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--chain.frame-subsampling-factor', '1', '--chain.alignment-subsampling-factor', '1', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trideltas_chain_delta_ivector_nofs', '--lat-dir', 'exp/chain/tri1_train_sp_lats', '--dir', 'exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp']
run_tdnn_trideltas_chain_delta_ivector_nofs.sh: success
[2021-10-23 14:32:33] run_propor.sh: ok
run_tdnn_trideltas_chain_delta_noivector_nofs.sh --fb-num-epochs 10 --decode false
run_tdnn_trideltas_chain_delta_noivector_nofs.sh: creating lang directory with one state per phone.
run_tdnn_trideltas_chain_delta_noivector_nofs.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri1 exp/chain/tri1_train_sp_lats
steps/align_fmllr_lats.sh: feature type is delta
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri1/final.mdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
10 warnings in exp/chain/tri1_train_sp_lats/log/align_pass1.*.log
8 warnings in exp/chain/tri1_train_sp_lats/log/generate_lattices.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 1 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri1_ali_train_sp exp/chain/tree_sp_trideltas_chain_delta_noivector_nofs
steps/nnet3/chain/build_tree.sh: feature type is delta
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri1_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri1_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trideltas_chain_delta_noivector_nofs.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trideltas_chain_delta_noivector_nofs/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/configs/
nnet3-init exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/configs//ref.config exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/configs//ref.raw 
2021-10-23 14:33:01,341 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 14:33:01,357 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 1,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 1,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri1_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trideltas_chain_delta_noivector_nofs',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 14:33:01,366 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 14:33:01,485 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trideltas_chain_delta_noivector_nofs/final.mdl exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 14:33:01,685 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 1 --alignment-subsampling-factor 1 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp exp/chain/tri1_train_sp_lats exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/tree 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (14,14)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 14:33:14,180 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/egs to exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp
2021-10-23 14:33:14,180 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 14:33:14,473 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 10 iterations
2021-10-23 14:33:14,473 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/9   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 14:33:29,938 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/9   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 14:33:44,131 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/9   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 14:33:58,548 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/9   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 14:34:13,354 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/9   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 14:34:28,001 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/9   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 14:34:42,727 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/9   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 14:34:57,402 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/9   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 14:35:12,094 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/9   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 14:35:26,787 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/9   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000015   
2021-10-23 14:35:41,491 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 14:35:41,491 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([8, 9, 10, 6, 7]) models.
2021-10-23 14:35:48,216 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp/egs
exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp: num-iters=10 nj=1..1 num-params=9.2M dim=40->1336 combine=-0.044->-0.044 (over 1) xent:train/valid[5,9]=(-2.91,-2.64/-2.95,-2.73) logprob:train/valid[5,9]=(-0.065,-0.045/-0.099,-0.080)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --chain.frame-subsampling-factor 1 --chain.alignment-subsampling-factor 1 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trideltas_chain_delta_noivector_nofs --lat-dir exp/chain/tri1_train_sp_lats --dir exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--chain.frame-subsampling-factor', '1', '--chain.alignment-subsampling-factor', '1', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trideltas_chain_delta_noivector_nofs', '--lat-dir', 'exp/chain/tri1_train_sp_lats', '--dir', 'exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp']
run_tdnn_trideltas_chain_delta_noivector_nofs.sh: success
[2021-10-23 14:36:03] run_propor.sh: ok
run_tdnn_trideltas_nochain_delta_ivector.sh: creating neural net configs
tree-info exp/tri1_ali_train_sp/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/configs/network.xconfig --config-dir exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/configs
nnet3-init exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/configs/ref.config exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/configs/ref.raw 
nnet3-init exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/configs/ref.config exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/configs/ref.raw 
2021-10-23 14:36:04,115 [steps/nnet3/train_dnn.py:36 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir  --cleanup.remove-egs true --cleanup.preserve-model-interval 100 --feat-dir=data/train_sp_hires --ali-dir exp/tri1_ali_train_sp --lang data/lang --reporting.email= --dir=exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', '', '--cleanup.remove-egs', 'true', '--cleanup.preserve-model-interval', '100', '--feat-dir=data/train_sp_hires', '--ali-dir', 'exp/tri1_ali_train_sp', '--lang', 'data/lang', '--reporting.email=', '--dir=exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp']
2021-10-23 14:36:04,131 [steps/nnet3/train_dnn.py:178 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/tri1_ali_train_sp',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': None,
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'input_model': None,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 10.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': [],
 'use_gpu': 'yes'}
2021-10-23 14:36:04,147 [steps/nnet3/train_dnn.py:238 - train - INFO ] Generating egs
steps/nnet3/get_egs.sh --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 8 --srand 0 data/train_sp_hires exp/tri1_ali_train_sp exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/egs
File data/train_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
*** steps/nnet3/get_egs.sh: warning: the --frames-per-eg is too large to generate one archive with
*** as many as --samples-per-iter egs in it.  Consider reducing --frames-per-eg.
steps/nnet3/get_egs.sh: creating 1 archives, each with 110347 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (14,14)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/egs/ali.ark,exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/egs/ali.scp 
LOG (copy-int-vector[5.5.0~1-5caf]:main():copy-int-vector.cc:83) Copied 1890 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
2021-10-23 14:36:15,638 [steps/nnet3/train_dnn.py:287 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2021-10-23 14:36:15,752 [steps/nnet3/train_dnn.py:294 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 14:36:16,049 [steps/nnet3/train_dnn.py:319 - train - INFO ] Training will run for 10.0 epochs = 80 iterations
2021-10-23 14:36:16,050 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 0/79   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.001700   
2021-10-23 14:36:27,766 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 1/79   Jobs: 1   Epoch: 0.12/10.0 (1.2% complete)   lr: 0.001652   
2021-10-23 14:36:38,422 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 2/79   Jobs: 1   Epoch: 0.25/10.0 (2.5% complete)   lr: 0.001605   
2021-10-23 14:36:49,096 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 3/79   Jobs: 1   Epoch: 0.38/10.0 (3.8% complete)   lr: 0.001559   
2021-10-23 14:36:59,785 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 4/79   Jobs: 1   Epoch: 0.50/10.0 (5.0% complete)   lr: 0.001515   
2021-10-23 14:37:10,473 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 5/79   Jobs: 1   Epoch: 0.62/10.0 (6.2% complete)   lr: 0.001472   
2021-10-23 14:37:21,162 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 6/79   Jobs: 1   Epoch: 0.75/10.0 (7.5% complete)   lr: 0.001430   
2021-10-23 14:37:31,876 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 7/79   Jobs: 1   Epoch: 0.88/10.0 (8.8% complete)   lr: 0.001390   
2021-10-23 14:37:42,627 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 8/79   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.001350   
2021-10-23 14:37:53,391 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 9/79   Jobs: 1   Epoch: 1.12/10.0 (11.2% complete)   lr: 0.001312   
2021-10-23 14:38:04,087 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 10/79   Jobs: 1   Epoch: 1.25/10.0 (12.5% complete)   lr: 0.001275   
2021-10-23 14:38:14,721 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 11/79   Jobs: 1   Epoch: 1.38/10.0 (13.8% complete)   lr: 0.001239   
2021-10-23 14:38:25,328 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 12/79   Jobs: 1   Epoch: 1.50/10.0 (15.0% complete)   lr: 0.001204   
2021-10-23 14:38:35,937 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 13/79   Jobs: 1   Epoch: 1.62/10.0 (16.2% complete)   lr: 0.001169   
2021-10-23 14:38:46,545 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 14/79   Jobs: 1   Epoch: 1.75/10.0 (17.5% complete)   lr: 0.001136   
2021-10-23 14:38:57,153 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 15/79   Jobs: 1   Epoch: 1.88/10.0 (18.8% complete)   lr: 0.001104   
2021-10-23 14:39:07,817 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 16/79   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.001073   
2021-10-23 14:39:18,481 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 17/79   Jobs: 1   Epoch: 2.12/10.0 (21.2% complete)   lr: 0.001042   
2021-10-23 14:39:29,099 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 18/79   Jobs: 1   Epoch: 2.25/10.0 (22.5% complete)   lr: 0.001013   
2021-10-23 14:39:39,707 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 19/79   Jobs: 1   Epoch: 2.38/10.0 (23.8% complete)   lr: 0.000984   
2021-10-23 14:39:50,317 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 20/79   Jobs: 1   Epoch: 2.50/10.0 (25.0% complete)   lr: 0.000956   
2021-10-23 14:40:01,862 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 21/79   Jobs: 1   Epoch: 2.62/10.0 (26.2% complete)   lr: 0.000929   
2021-10-23 14:40:12,640 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 22/79   Jobs: 1   Epoch: 2.75/10.0 (27.5% complete)   lr: 0.000903   
2021-10-23 14:40:23,417 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 23/79   Jobs: 1   Epoch: 2.88/10.0 (28.8% complete)   lr: 0.000877   
2021-10-23 14:40:34,014 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 24/79   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000852   
2021-10-23 14:40:44,641 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 25/79   Jobs: 1   Epoch: 3.12/10.0 (31.2% complete)   lr: 0.000828   
2021-10-23 14:40:55,331 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 26/79   Jobs: 1   Epoch: 3.25/10.0 (32.5% complete)   lr: 0.000804   
2021-10-23 14:41:05,962 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 27/79   Jobs: 1   Epoch: 3.38/10.0 (33.8% complete)   lr: 0.000782   
2021-10-23 14:41:16,558 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 28/79   Jobs: 1   Epoch: 3.50/10.0 (35.0% complete)   lr: 0.000759   
2021-10-23 14:41:27,178 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 29/79   Jobs: 1   Epoch: 3.62/10.0 (36.2% complete)   lr: 0.000738   
2021-10-23 14:41:37,811 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 30/79   Jobs: 1   Epoch: 3.75/10.0 (37.5% complete)   lr: 0.000717   
2021-10-23 14:41:48,470 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 31/79   Jobs: 1   Epoch: 3.88/10.0 (38.8% complete)   lr: 0.000697   
2021-10-23 14:41:59,075 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 32/79   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000677   
2021-10-23 14:42:09,715 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 33/79   Jobs: 1   Epoch: 4.12/10.0 (41.2% complete)   lr: 0.000658   
2021-10-23 14:42:20,307 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 34/79   Jobs: 1   Epoch: 4.25/10.0 (42.5% complete)   lr: 0.000639   
2021-10-23 14:42:30,959 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 35/79   Jobs: 1   Epoch: 4.38/10.0 (43.8% complete)   lr: 0.000621   
2021-10-23 14:42:41,600 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 36/79   Jobs: 1   Epoch: 4.50/10.0 (45.0% complete)   lr: 0.000603   
2021-10-23 14:42:52,287 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 37/79   Jobs: 1   Epoch: 4.62/10.0 (46.2% complete)   lr: 0.000586   
2021-10-23 14:43:02,907 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 38/79   Jobs: 1   Epoch: 4.75/10.0 (47.5% complete)   lr: 0.000569   
2021-10-23 14:43:13,516 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 39/79   Jobs: 1   Epoch: 4.88/10.0 (48.8% complete)   lr: 0.000553   
2021-10-23 14:43:24,147 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 40/79   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000538   
2021-10-23 14:43:35,619 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 41/79   Jobs: 1   Epoch: 5.12/10.0 (51.2% complete)   lr: 0.000522   
2021-10-23 14:43:46,410 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 42/79   Jobs: 1   Epoch: 5.25/10.0 (52.5% complete)   lr: 0.000508   
2021-10-23 14:43:57,181 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 43/79   Jobs: 1   Epoch: 5.38/10.0 (53.8% complete)   lr: 0.000493   
2021-10-23 14:44:07,782 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 44/79   Jobs: 1   Epoch: 5.50/10.0 (55.0% complete)   lr: 0.000479   
2021-10-23 14:44:18,421 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 45/79   Jobs: 1   Epoch: 5.62/10.0 (56.2% complete)   lr: 0.000466   
2021-10-23 14:44:29,028 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 46/79   Jobs: 1   Epoch: 5.75/10.0 (57.5% complete)   lr: 0.000452   
2021-10-23 14:44:39,622 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 47/79   Jobs: 1   Epoch: 5.88/10.0 (58.8% complete)   lr: 0.000439   
2021-10-23 14:44:50,278 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 48/79   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000427   
2021-10-23 14:45:00,901 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 49/79   Jobs: 1   Epoch: 6.12/10.0 (61.2% complete)   lr: 0.000415   
2021-10-23 14:45:11,528 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 50/79   Jobs: 1   Epoch: 6.25/10.0 (62.5% complete)   lr: 0.000403   
2021-10-23 14:45:22,163 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 51/79   Jobs: 1   Epoch: 6.38/10.0 (63.8% complete)   lr: 0.000392   
2021-10-23 14:45:32,779 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 52/79   Jobs: 1   Epoch: 6.50/10.0 (65.0% complete)   lr: 0.000381   
2021-10-23 14:45:43,400 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 53/79   Jobs: 1   Epoch: 6.62/10.0 (66.2% complete)   lr: 0.000370   
2021-10-23 14:45:54,021 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 54/79   Jobs: 1   Epoch: 6.75/10.0 (67.5% complete)   lr: 0.000359   
2021-10-23 14:46:04,671 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 55/79   Jobs: 1   Epoch: 6.88/10.0 (68.8% complete)   lr: 0.000349   
2021-10-23 14:46:15,283 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 56/79   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000339   
2021-10-23 14:46:25,950 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 57/79   Jobs: 1   Epoch: 7.12/10.0 (71.2% complete)   lr: 0.000330   
2021-10-23 14:46:36,575 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 58/79   Jobs: 1   Epoch: 7.25/10.0 (72.5% complete)   lr: 0.000320   
2021-10-23 14:46:47,221 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 59/79   Jobs: 1   Epoch: 7.38/10.0 (73.8% complete)   lr: 0.000311   
2021-10-23 14:46:57,874 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 60/79   Jobs: 1   Epoch: 7.50/10.0 (75.0% complete)   lr: 0.000302   
2021-10-23 14:47:09,394 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 61/79   Jobs: 1   Epoch: 7.62/10.0 (76.2% complete)   lr: 0.000294   
2021-10-23 14:47:20,189 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 62/79   Jobs: 1   Epoch: 7.75/10.0 (77.5% complete)   lr: 0.000285   
2021-10-23 14:47:30,962 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 63/79   Jobs: 1   Epoch: 7.88/10.0 (78.8% complete)   lr: 0.000277   
2021-10-23 14:47:41,588 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 64/79   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000269   
2021-10-23 14:47:52,206 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 65/79   Jobs: 1   Epoch: 8.12/10.0 (81.2% complete)   lr: 0.000262   
2021-10-23 14:48:02,828 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 66/79   Jobs: 1   Epoch: 8.25/10.0 (82.5% complete)   lr: 0.000254   
2021-10-23 14:48:13,453 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 67/79   Jobs: 1   Epoch: 8.38/10.0 (83.8% complete)   lr: 0.000247   
2021-10-23 14:48:24,065 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 68/79   Jobs: 1   Epoch: 8.50/10.0 (85.0% complete)   lr: 0.000240   
2021-10-23 14:48:34,688 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 69/79   Jobs: 1   Epoch: 8.62/10.0 (86.2% complete)   lr: 0.000233   
2021-10-23 14:48:45,291 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 70/79   Jobs: 1   Epoch: 8.75/10.0 (87.5% complete)   lr: 0.000227   
2021-10-23 14:48:55,965 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 71/79   Jobs: 1   Epoch: 8.88/10.0 (88.8% complete)   lr: 0.000220   
2021-10-23 14:49:06,572 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 72/79   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000214   
2021-10-23 14:49:17,209 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 73/79   Jobs: 1   Epoch: 9.12/10.0 (91.2% complete)   lr: 0.000208   
2021-10-23 14:49:27,826 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 74/79   Jobs: 1   Epoch: 9.25/10.0 (92.5% complete)   lr: 0.000202   
2021-10-23 14:49:38,449 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 75/79   Jobs: 1   Epoch: 9.38/10.0 (93.8% complete)   lr: 0.000196   
2021-10-23 14:49:49,054 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 76/79   Jobs: 1   Epoch: 9.50/10.0 (95.0% complete)   lr: 0.000191   
2021-10-23 14:49:59,756 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 77/79   Jobs: 1   Epoch: 9.62/10.0 (96.2% complete)   lr: 0.000185   
2021-10-23 14:50:10,376 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 78/79   Jobs: 1   Epoch: 9.75/10.0 (97.5% complete)   lr: 0.000180   
2021-10-23 14:50:20,996 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 79/79   Jobs: 1   Epoch: 9.88/10.0 (98.8% complete)   lr: 0.000170   
2021-10-23 14:50:31,604 [steps/nnet3/train_dnn.py:401 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 14:50:31,604 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 61, 62, 63]) models.
2021-10-23 14:50:43,574 [steps/nnet3/train_dnn.py:410 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2021-10-23 14:51:24,359 [steps/nnet3/train_dnn.py:421 - train - INFO ] Re-adjusting priors based on computed posteriors
2021-10-23 14:51:24,441 [steps/nnet3/train_dnn.py:431 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp/egs
exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp: num-iters=80 nj=1..1 num-params=8.1M dim=40+100->640 combine=-0.34->-0.33 (over 7) loglike:train/valid[52,79,combined]=(-0.39,-0.28,-0.27/-1.53,-1.60,-1.58) accuracy:train/valid[52,79,combined]=(0.868,0.902,0.908/0.60,0.59,0.59)
run_tdnn_trideltas_nochain_delta_ivector.sh: success
[2021-10-23 14:51:24] run_propor.sh: ok
run_tdnn_trideltas_nochain_delta_noivector.sh: creating neural net configs
tree-info exp/tri1_ali_train_sp/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/configs/network.xconfig --config-dir exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/configs
nnet3-init exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/configs/ref.config exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/configs/ref.raw 
nnet3-init exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/configs/ref.config exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/configs/ref.raw 
2021-10-23 14:51:25,163 [steps/nnet3/train_dnn.py:36 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir  --cleanup.remove-egs true --cleanup.preserve-model-interval 100 --feat-dir=data/train_sp_hires --ali-dir exp/tri1_ali_train_sp --lang data/lang --reporting.email= --dir=exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', '', '--cleanup.remove-egs', 'true', '--cleanup.preserve-model-interval', '100', '--feat-dir=data/train_sp_hires', '--ali-dir', 'exp/tri1_ali_train_sp', '--lang', 'data/lang', '--reporting.email=', '--dir=exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp']
2021-10-23 14:51:25,179 [steps/nnet3/train_dnn.py:178 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/tri1_ali_train_sp',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': None,
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'input_model': None,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 10.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': [],
 'use_gpu': 'yes'}
2021-10-23 14:51:25,188 [steps/nnet3/train_dnn.py:238 - train - INFO ] Generating egs
steps/nnet3/get_egs.sh --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 8 --srand 0 data/train_sp_hires exp/tri1_ali_train_sp exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/egs
File data/train_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
*** steps/nnet3/get_egs.sh: warning: the --frames-per-eg is too large to generate one archive with
*** as many as --samples-per-iter egs in it.  Consider reducing --frames-per-eg.
steps/nnet3/get_egs.sh: creating 1 archives, each with 110347 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (14,14)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/egs/ali.ark,exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/egs/ali.scp 
LOG (copy-int-vector[5.5.0~1-5caf]:main():copy-int-vector.cc:83) Copied 1890 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
2021-10-23 14:51:36,356 [steps/nnet3/train_dnn.py:287 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2021-10-23 14:51:36,479 [steps/nnet3/train_dnn.py:294 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 14:51:36,764 [steps/nnet3/train_dnn.py:319 - train - INFO ] Training will run for 10.0 epochs = 80 iterations
2021-10-23 14:51:36,764 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 0/79   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.001700   
2021-10-23 14:51:47,947 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 1/79   Jobs: 1   Epoch: 0.12/10.0 (1.2% complete)   lr: 0.001652   
2021-10-23 14:51:58,461 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 2/79   Jobs: 1   Epoch: 0.25/10.0 (2.5% complete)   lr: 0.001605   
2021-10-23 14:52:08,981 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 3/79   Jobs: 1   Epoch: 0.38/10.0 (3.8% complete)   lr: 0.001559   
2021-10-23 14:52:19,545 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 4/79   Jobs: 1   Epoch: 0.50/10.0 (5.0% complete)   lr: 0.001515   
2021-10-23 14:52:30,140 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 5/79   Jobs: 1   Epoch: 0.62/10.0 (6.2% complete)   lr: 0.001472   
2021-10-23 14:52:40,745 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 6/79   Jobs: 1   Epoch: 0.75/10.0 (7.5% complete)   lr: 0.001430   
2021-10-23 14:52:51,344 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 7/79   Jobs: 1   Epoch: 0.88/10.0 (8.8% complete)   lr: 0.001390   
2021-10-23 14:53:01,963 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 8/79   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.001350   
2021-10-23 14:53:12,601 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 9/79   Jobs: 1   Epoch: 1.12/10.0 (11.2% complete)   lr: 0.001312   
2021-10-23 14:53:23,234 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 10/79   Jobs: 1   Epoch: 1.25/10.0 (12.5% complete)   lr: 0.001275   
2021-10-23 14:53:33,890 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 11/79   Jobs: 1   Epoch: 1.38/10.0 (13.8% complete)   lr: 0.001239   
2021-10-23 14:53:44,535 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 12/79   Jobs: 1   Epoch: 1.50/10.0 (15.0% complete)   lr: 0.001204   
2021-10-23 14:53:55,165 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 13/79   Jobs: 1   Epoch: 1.62/10.0 (16.2% complete)   lr: 0.001169   
2021-10-23 14:54:05,797 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 14/79   Jobs: 1   Epoch: 1.75/10.0 (17.5% complete)   lr: 0.001136   
2021-10-23 14:54:16,439 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 15/79   Jobs: 1   Epoch: 1.88/10.0 (18.8% complete)   lr: 0.001104   
2021-10-23 14:54:27,062 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 16/79   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.001073   
2021-10-23 14:54:37,721 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 17/79   Jobs: 1   Epoch: 2.12/10.0 (21.2% complete)   lr: 0.001042   
2021-10-23 14:54:48,377 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 18/79   Jobs: 1   Epoch: 2.25/10.0 (22.5% complete)   lr: 0.001013   
2021-10-23 14:54:59,013 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 19/79   Jobs: 1   Epoch: 2.38/10.0 (23.8% complete)   lr: 0.000984   
2021-10-23 14:55:09,654 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 20/79   Jobs: 1   Epoch: 2.50/10.0 (25.0% complete)   lr: 0.000956   
2021-10-23 14:55:21,193 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 21/79   Jobs: 1   Epoch: 2.62/10.0 (26.2% complete)   lr: 0.000929   
2021-10-23 14:55:31,668 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 22/79   Jobs: 1   Epoch: 2.75/10.0 (27.5% complete)   lr: 0.000903   
2021-10-23 14:55:42,281 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 23/79   Jobs: 1   Epoch: 2.88/10.0 (28.8% complete)   lr: 0.000877   
2021-10-23 14:55:52,908 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 24/79   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000852   
2021-10-23 14:56:03,521 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 25/79   Jobs: 1   Epoch: 3.12/10.0 (31.2% complete)   lr: 0.000828   
2021-10-23 14:56:14,191 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 26/79   Jobs: 1   Epoch: 3.25/10.0 (32.5% complete)   lr: 0.000804   
2021-10-23 14:56:24,848 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 27/79   Jobs: 1   Epoch: 3.38/10.0 (33.8% complete)   lr: 0.000782   
2021-10-23 14:56:35,479 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 28/79   Jobs: 1   Epoch: 3.50/10.0 (35.0% complete)   lr: 0.000759   
2021-10-23 14:56:46,120 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 29/79   Jobs: 1   Epoch: 3.62/10.0 (36.2% complete)   lr: 0.000738   
2021-10-23 14:56:56,765 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 30/79   Jobs: 1   Epoch: 3.75/10.0 (37.5% complete)   lr: 0.000717   
2021-10-23 14:57:07,452 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 31/79   Jobs: 1   Epoch: 3.88/10.0 (38.8% complete)   lr: 0.000697   
2021-10-23 14:57:18,098 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 32/79   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000677   
2021-10-23 14:57:28,742 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 33/79   Jobs: 1   Epoch: 4.12/10.0 (41.2% complete)   lr: 0.000658   
2021-10-23 14:57:39,385 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 34/79   Jobs: 1   Epoch: 4.25/10.0 (42.5% complete)   lr: 0.000639   
2021-10-23 14:57:50,036 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 35/79   Jobs: 1   Epoch: 4.38/10.0 (43.8% complete)   lr: 0.000621   
2021-10-23 14:58:00,676 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 36/79   Jobs: 1   Epoch: 4.50/10.0 (45.0% complete)   lr: 0.000603   
2021-10-23 14:58:11,335 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 37/79   Jobs: 1   Epoch: 4.62/10.0 (46.2% complete)   lr: 0.000586   
2021-10-23 14:58:21,972 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 38/79   Jobs: 1   Epoch: 4.75/10.0 (47.5% complete)   lr: 0.000569   
2021-10-23 14:58:32,616 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 39/79   Jobs: 1   Epoch: 4.88/10.0 (48.8% complete)   lr: 0.000553   
2021-10-23 14:58:43,251 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 40/79   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000538   
2021-10-23 14:58:54,785 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 41/79   Jobs: 1   Epoch: 5.12/10.0 (51.2% complete)   lr: 0.000522   
2021-10-23 14:59:05,258 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 42/79   Jobs: 1   Epoch: 5.25/10.0 (52.5% complete)   lr: 0.000508   
2021-10-23 14:59:15,911 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 43/79   Jobs: 1   Epoch: 5.38/10.0 (53.8% complete)   lr: 0.000493   
2021-10-23 14:59:26,525 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 44/79   Jobs: 1   Epoch: 5.50/10.0 (55.0% complete)   lr: 0.000479   
2021-10-23 14:59:37,177 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 45/79   Jobs: 1   Epoch: 5.62/10.0 (56.2% complete)   lr: 0.000466   
2021-10-23 14:59:47,819 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 46/79   Jobs: 1   Epoch: 5.75/10.0 (57.5% complete)   lr: 0.000452   
2021-10-23 14:59:58,453 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 47/79   Jobs: 1   Epoch: 5.88/10.0 (58.8% complete)   lr: 0.000439   
2021-10-23 15:00:09,096 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 48/79   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000427   
2021-10-23 15:00:19,741 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 49/79   Jobs: 1   Epoch: 6.12/10.0 (61.2% complete)   lr: 0.000415   
2021-10-23 15:00:30,417 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 50/79   Jobs: 1   Epoch: 6.25/10.0 (62.5% complete)   lr: 0.000403   
2021-10-23 15:00:41,088 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 51/79   Jobs: 1   Epoch: 6.38/10.0 (63.8% complete)   lr: 0.000392   
2021-10-23 15:00:51,728 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 52/79   Jobs: 1   Epoch: 6.50/10.0 (65.0% complete)   lr: 0.000381   
2021-10-23 15:01:02,373 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 53/79   Jobs: 1   Epoch: 6.62/10.0 (66.2% complete)   lr: 0.000370   
2021-10-23 15:01:13,004 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 54/79   Jobs: 1   Epoch: 6.75/10.0 (67.5% complete)   lr: 0.000359   
2021-10-23 15:01:23,749 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 55/79   Jobs: 1   Epoch: 6.88/10.0 (68.8% complete)   lr: 0.000349   
2021-10-23 15:01:34,325 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 56/79   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000339   
2021-10-23 15:01:44,963 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 57/79   Jobs: 1   Epoch: 7.12/10.0 (71.2% complete)   lr: 0.000330   
2021-10-23 15:01:55,582 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 58/79   Jobs: 1   Epoch: 7.25/10.0 (72.5% complete)   lr: 0.000320   
2021-10-23 15:02:06,235 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 59/79   Jobs: 1   Epoch: 7.38/10.0 (73.8% complete)   lr: 0.000311   
2021-10-23 15:02:16,877 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 60/79   Jobs: 1   Epoch: 7.50/10.0 (75.0% complete)   lr: 0.000302   
2021-10-23 15:02:28,435 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 61/79   Jobs: 1   Epoch: 7.62/10.0 (76.2% complete)   lr: 0.000294   
2021-10-23 15:02:38,913 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 62/79   Jobs: 1   Epoch: 7.75/10.0 (77.5% complete)   lr: 0.000285   
2021-10-23 15:02:49,551 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 63/79   Jobs: 1   Epoch: 7.88/10.0 (78.8% complete)   lr: 0.000277   
2021-10-23 15:03:00,189 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 64/79   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000269   
2021-10-23 15:03:10,822 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 65/79   Jobs: 1   Epoch: 8.12/10.0 (81.2% complete)   lr: 0.000262   
2021-10-23 15:03:21,486 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 66/79   Jobs: 1   Epoch: 8.25/10.0 (82.5% complete)   lr: 0.000254   
2021-10-23 15:03:32,124 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 67/79   Jobs: 1   Epoch: 8.38/10.0 (83.8% complete)   lr: 0.000247   
2021-10-23 15:03:42,771 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 68/79   Jobs: 1   Epoch: 8.50/10.0 (85.0% complete)   lr: 0.000240   
2021-10-23 15:03:53,409 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 69/79   Jobs: 1   Epoch: 8.62/10.0 (86.2% complete)   lr: 0.000233   
2021-10-23 15:04:04,047 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 70/79   Jobs: 1   Epoch: 8.75/10.0 (87.5% complete)   lr: 0.000227   
2021-10-23 15:04:14,711 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 71/79   Jobs: 1   Epoch: 8.88/10.0 (88.8% complete)   lr: 0.000220   
2021-10-23 15:04:25,360 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 72/79   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000214   
2021-10-23 15:04:36,010 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 73/79   Jobs: 1   Epoch: 9.12/10.0 (91.2% complete)   lr: 0.000208   
2021-10-23 15:04:46,631 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 74/79   Jobs: 1   Epoch: 9.25/10.0 (92.5% complete)   lr: 0.000202   
2021-10-23 15:04:57,310 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 75/79   Jobs: 1   Epoch: 9.38/10.0 (93.8% complete)   lr: 0.000196   
2021-10-23 15:05:07,937 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 76/79   Jobs: 1   Epoch: 9.50/10.0 (95.0% complete)   lr: 0.000191   
2021-10-23 15:05:18,599 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 77/79   Jobs: 1   Epoch: 9.62/10.0 (96.2% complete)   lr: 0.000185   
2021-10-23 15:05:29,219 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 78/79   Jobs: 1   Epoch: 9.75/10.0 (97.5% complete)   lr: 0.000180   
2021-10-23 15:05:39,838 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 79/79   Jobs: 1   Epoch: 9.88/10.0 (98.8% complete)   lr: 0.000170   
2021-10-23 15:05:50,476 [steps/nnet3/train_dnn.py:401 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 15:05:50,476 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 61, 62, 63]) models.
2021-10-23 15:06:02,444 [steps/nnet3/train_dnn.py:410 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2021-10-23 15:06:42,871 [steps/nnet3/train_dnn.py:421 - train - INFO ] Re-adjusting priors based on computed posteriors
2021-10-23 15:06:42,953 [steps/nnet3/train_dnn.py:431 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp/egs
exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp: num-iters=80 nj=1..1 num-params=7.9M dim=40->640 combine=-0.47->-0.45 (over 5) loglike:train/valid[52,79,combined]=(-0.54,-0.39,-0.39/-1.60,-1.61,-1.58) accuracy:train/valid[52,79,combined]=(0.816,0.867,0.867/0.58,0.58,0.59)
run_tdnn_trideltas_nochain_delta_noivector.sh: success
[2021-10-23 15:06:43] run_propor.sh: ok
run_tdnn_trisat_chain_lda_ivector_fs3.sh --fb-num-epochs 10 --decode false
run_tdnn_trisat_chain_lda_ivector_fs3.sh: creating lang directory with one state per phone.
run_tdnn_trisat_chain_lda_ivector_fs3.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri4b exp/chain/tri4b_train_sp_lats
steps/align_fmllr_lats.sh: feature type is lda
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri4b/final.alimdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/tri4b_train_sp_lats/log/generate_lattices.*.log
11 warnings in exp/chain/tri4b_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri4b_ali_train_sp exp/chain/tree_sp_trisat_chain_lda_ivector_fs3
steps/nnet3/chain/build_tree.sh: feature type is lda
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri4b_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri4b_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trisat_chain_lda_ivector_fs3.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trisat_chain_lda_ivector_fs3/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs/
nnet3-init exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs//init.config exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs//init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs//init.raw
nnet3-info exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs//init.raw 
nnet3-init exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs//ref.config exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs//ref.config exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/configs//ref.raw 
2021-10-23 15:07:24,780 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 15:07:24,796 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri4b_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trisat_chain_lda_ivector_fs3',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 15:07:24,812 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 15:07:24,909 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trisat_chain_lda_ivector_fs3/final.mdl exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 15:07:25,090 [steps/nnet3/chain/train.py:350 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 15:07:25,135 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp exp/chain/tri4b_train_sp_lats exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/tree 
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (14,14)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 15:07:36,895 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/egs to exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp
2021-10-23 15:07:36,895 [steps/nnet3/chain/train.py:442 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 15:07:37,682 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 15:07:37,955 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 30 iterations
2021-10-23 15:07:37,955 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/29   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 15:07:48,256 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/29   Jobs: 1   Epoch: 0.33/10.0 (3.3% complete)   lr: 0.000139   
2021-10-23 15:07:57,521 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/29   Jobs: 1   Epoch: 0.67/10.0 (6.7% complete)   lr: 0.000129   
2021-10-23 15:08:06,822 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/29   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 15:08:16,132 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/29   Jobs: 1   Epoch: 1.33/10.0 (13.3% complete)   lr: 0.000110   
2021-10-23 15:08:25,463 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/29   Jobs: 1   Epoch: 1.67/10.0 (16.7% complete)   lr: 0.000102   
2021-10-23 15:08:34,777 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/29   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 15:08:44,064 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/29   Jobs: 1   Epoch: 2.33/10.0 (23.3% complete)   lr: 0.000088   
2021-10-23 15:08:53,585 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/29   Jobs: 1   Epoch: 2.67/10.0 (26.7% complete)   lr: 0.000081   
2021-10-23 15:09:02,959 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/29   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 15:09:12,506 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 10/29   Jobs: 1   Epoch: 3.33/10.0 (33.3% complete)   lr: 0.000070   
2021-10-23 15:09:21,871 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 11/29   Jobs: 1   Epoch: 3.67/10.0 (36.7% complete)   lr: 0.000064   
2021-10-23 15:09:31,418 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 12/29   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 15:09:40,764 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 13/29   Jobs: 1   Epoch: 4.33/10.0 (43.3% complete)   lr: 0.000055   
2021-10-23 15:09:50,288 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 14/29   Jobs: 1   Epoch: 4.67/10.0 (46.7% complete)   lr: 0.000051   
2021-10-23 15:09:59,634 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 15/29   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 15:10:09,182 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 16/29   Jobs: 1   Epoch: 5.33/10.0 (53.3% complete)   lr: 0.000044   
2021-10-23 15:10:18,535 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 17/29   Jobs: 1   Epoch: 5.67/10.0 (56.7% complete)   lr: 0.000041   
2021-10-23 15:10:28,077 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 18/29   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 15:10:37,470 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 19/29   Jobs: 1   Epoch: 6.33/10.0 (63.3% complete)   lr: 0.000035   
2021-10-23 15:10:47,023 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 20/29   Jobs: 1   Epoch: 6.67/10.0 (66.7% complete)   lr: 0.000032   
2021-10-23 15:10:57,344 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 21/29   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 15:11:06,865 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 22/29   Jobs: 1   Epoch: 7.33/10.0 (73.3% complete)   lr: 0.000028   
2021-10-23 15:11:16,417 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 23/29   Jobs: 1   Epoch: 7.67/10.0 (76.7% complete)   lr: 0.000026   
2021-10-23 15:11:25,770 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 24/29   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 15:11:35,339 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 25/29   Jobs: 1   Epoch: 8.33/10.0 (83.3% complete)   lr: 0.000022   
2021-10-23 15:11:44,696 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 26/29   Jobs: 1   Epoch: 8.67/10.0 (86.7% complete)   lr: 0.000020   
2021-10-23 15:11:54,232 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 27/29   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000019   
2021-10-23 15:12:03,664 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 28/29   Jobs: 1   Epoch: 9.33/10.0 (93.3% complete)   lr: 0.000017   
2021-10-23 15:12:13,502 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 29/29   Jobs: 1   Epoch: 9.67/10.0 (96.7% complete)   lr: 0.000015   
2021-10-23 15:12:23,059 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 15:12:23,060 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) models.
2021-10-23 15:12:31,783 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp/egs
exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp: num-iters=30 nj=1..1 num-params=9.0M dim=40+100->608 combine=-0.032->-0.032 (over 1) xent:train/valid[19,29]=(-1.53,-1.35/-1.90,-1.85) logprob:train/valid[19,29]=(-0.041,-0.032/-0.110,-0.110)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --egs.dir  --egs.stage -10 --egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trisat_chain_lda_ivector_fs3 --lat-dir exp/chain/tri4b_train_sp_lats --dir exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trisat_chain_lda_ivector_fs3', '--lat-dir', 'exp/chain/tri4b_train_sp_lats', '--dir', 'exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp']
run_tdnn_trisat_chain_lda_ivector_fs3.sh: success!
[2021-10-23 15:12:39] run_propor.sh: ok
run_tdnn_trisat_chain_lda_noivector_fs3.sh --fb-num-epochs 10 --decode false
run_tdnn_trisat_chain_lda_noivector_fs3.sh: creating lang directory with one state per phone.
run_tdnn_trisat_chain_lda_noivector_fs3.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri4b exp/chain/tri4b_train_sp_lats
steps/align_fmllr_lats.sh: feature type is lda
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri4b/final.alimdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/tri4b_train_sp_lats/log/generate_lattices.*.log
11 warnings in exp/chain/tri4b_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri4b_ali_train_sp exp/chain/tree_sp_trisat_chain_lda_noivector_fs3
steps/nnet3/chain/build_tree.sh: feature type is lda
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri4b_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri4b_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trisat_chain_lda_noivector_fs3.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trisat_chain_lda_noivector_fs3/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs/
nnet3-init exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs//init.config exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs//init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs//init.raw
nnet3-info exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs//init.raw 
nnet3-init exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs//ref.config exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs//ref.config exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/configs//ref.raw 
2021-10-23 15:13:21,476 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 15:13:21,491 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri4b_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trisat_chain_lda_noivector_fs3',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 15:13:21,500 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 15:13:21,590 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trisat_chain_lda_noivector_fs3/final.mdl exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 15:13:21,779 [steps/nnet3/chain/train.py:350 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 15:13:21,825 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp exp/chain/tri4b_train_sp_lats exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/tree 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (14,14)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 15:13:33,551 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/egs to exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp
2021-10-23 15:13:33,551 [steps/nnet3/chain/train.py:442 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 15:13:34,081 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 15:13:34,351 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 30 iterations
2021-10-23 15:13:34,351 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/29   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 15:13:44,586 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/29   Jobs: 1   Epoch: 0.33/10.0 (3.3% complete)   lr: 0.000139   
2021-10-23 15:13:53,778 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/29   Jobs: 1   Epoch: 0.67/10.0 (6.7% complete)   lr: 0.000129   
2021-10-23 15:14:03,086 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/29   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 15:14:12,316 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/29   Jobs: 1   Epoch: 1.33/10.0 (13.3% complete)   lr: 0.000110   
2021-10-23 15:14:21,579 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/29   Jobs: 1   Epoch: 1.67/10.0 (16.7% complete)   lr: 0.000102   
2021-10-23 15:14:30,829 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/29   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 15:14:40,118 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/29   Jobs: 1   Epoch: 2.33/10.0 (23.3% complete)   lr: 0.000088   
2021-10-23 15:14:49,559 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/29   Jobs: 1   Epoch: 2.67/10.0 (26.7% complete)   lr: 0.000081   
2021-10-23 15:14:59,034 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/29   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 15:15:08,308 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 10/29   Jobs: 1   Epoch: 3.33/10.0 (33.3% complete)   lr: 0.000070   
2021-10-23 15:15:17,787 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 11/29   Jobs: 1   Epoch: 3.67/10.0 (36.7% complete)   lr: 0.000064   
2021-10-23 15:15:27,086 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 12/29   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 15:15:36,587 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 13/29   Jobs: 1   Epoch: 4.33/10.0 (43.3% complete)   lr: 0.000055   
2021-10-23 15:15:45,868 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 14/29   Jobs: 1   Epoch: 4.67/10.0 (46.7% complete)   lr: 0.000051   
2021-10-23 15:15:55,375 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 15/29   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 15:16:04,681 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 16/29   Jobs: 1   Epoch: 5.33/10.0 (53.3% complete)   lr: 0.000044   
2021-10-23 15:16:14,181 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 17/29   Jobs: 1   Epoch: 5.67/10.0 (56.7% complete)   lr: 0.000041   
2021-10-23 15:16:23,470 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 18/29   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 15:16:32,971 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 19/29   Jobs: 1   Epoch: 6.33/10.0 (63.3% complete)   lr: 0.000035   
2021-10-23 15:16:42,289 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 20/29   Jobs: 1   Epoch: 6.67/10.0 (66.7% complete)   lr: 0.000032   
2021-10-23 15:16:52,696 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 21/29   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 15:17:02,198 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 22/29   Jobs: 1   Epoch: 7.33/10.0 (73.3% complete)   lr: 0.000028   
2021-10-23 15:17:11,497 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 23/29   Jobs: 1   Epoch: 7.67/10.0 (76.7% complete)   lr: 0.000026   
2021-10-23 15:17:20,955 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 24/29   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 15:17:30,265 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 25/29   Jobs: 1   Epoch: 8.33/10.0 (83.3% complete)   lr: 0.000022   
2021-10-23 15:17:39,742 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 26/29   Jobs: 1   Epoch: 8.67/10.0 (86.7% complete)   lr: 0.000020   
2021-10-23 15:17:49,003 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 27/29   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000019   
2021-10-23 15:17:58,507 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 28/29   Jobs: 1   Epoch: 9.33/10.0 (93.3% complete)   lr: 0.000017   
2021-10-23 15:18:07,820 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 29/29   Jobs: 1   Epoch: 9.67/10.0 (96.7% complete)   lr: 0.000015   
2021-10-23 15:18:17,343 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 15:18:17,343 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) models.
2021-10-23 15:18:25,843 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp/egs
exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp: num-iters=30 nj=1..1 num-params=8.9M dim=40->608 combine=-0.034->-0.034 (over 1) xent:train/valid[19,29]=(-1.58,-1.41/-1.85,-1.78) logprob:train/valid[19,29]=(-0.044,-0.036/-0.102,-0.098)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trisat_chain_lda_noivector_fs3 --lat-dir exp/chain/tri4b_train_sp_lats --dir exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trisat_chain_lda_noivector_fs3', '--lat-dir', 'exp/chain/tri4b_train_sp_lats', '--dir', 'exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp']
run_tdnn_trisat_chain_lda_noivector_fs3.sh: success!
[2021-10-23 15:18:33] run_propor.sh: ok
run_tdnn_trisat_chain_lda_ivector_nofs.sh --fb-num-epochs 10 --decode false
run_tdnn_trisat_chain_lda_ivector_nofs.sh: creating lang directory with one state per phone.
run_tdnn_trisat_chain_lda_ivector_nofs.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri4b exp/chain/tri4b_train_sp_lats
steps/align_fmllr_lats.sh: feature type is lda
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri4b/final.alimdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/tri4b_train_sp_lats/log/generate_lattices.*.log
11 warnings in exp/chain/tri4b_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 1 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri4b_ali_train_sp exp/chain/tree_sp_trisat_chain_lda_ivector_nofs
steps/nnet3/chain/build_tree.sh: feature type is lda
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri4b_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri4b_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trisat_chain_lda_ivector_nofs.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trisat_chain_lda_ivector_nofs/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs/
nnet3-init exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs//init.config exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs//init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs//init.raw
nnet3-info exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs//init.raw 
nnet3-init exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs//ref.config exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs//ref.config exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/configs//ref.raw 
2021-10-23 15:19:16,247 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 15:19:16,263 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 1,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 1,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri4b_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trisat_chain_lda_ivector_nofs',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 15:19:16,279 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 15:19:16,403 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trisat_chain_lda_ivector_nofs/final.mdl exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 15:19:16,595 [steps/nnet3/chain/train.py:350 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 15:19:16,625 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 13 --right-context 13 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 1 --alignment-subsampling-factor 1 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp exp/chain/tri4b_train_sp_lats exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/tree 
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (13,13)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 15:19:28,974 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/egs to exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp
2021-10-23 15:19:28,974 [steps/nnet3/chain/train.py:442 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 15:19:30,406 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 15:19:30,730 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 10 iterations
2021-10-23 15:19:30,730 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/9   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 15:19:46,273 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/9   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 15:20:00,660 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/9   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 15:20:15,373 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/9   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 15:20:30,403 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/9   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 15:20:45,395 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/9   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 15:21:00,230 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/9   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 15:21:15,079 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/9   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 15:21:29,859 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/9   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 15:21:44,683 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/9   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000015   
2021-10-23 15:21:59,519 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 15:21:59,519 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([8, 9, 10, 6, 7]) models.
2021-10-23 15:22:06,097 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp/egs
exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp: num-iters=10 nj=1..1 num-params=9.5M dim=40+100->1608 combine=-0.018->-0.018 (over 1) xent:train/valid[5,9]=(-2.21,-1.97/-2.66,-2.49) logprob:train/valid[5,9]=(-0.024,-0.019/-0.096,-0.088)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --chain.frame-subsampling-factor 1 --chain.alignment-subsampling-factor 1 --egs.dir  --egs.stage -10 --egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trisat_chain_lda_ivector_nofs --lat-dir exp/chain/tri4b_train_sp_lats --dir exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--chain.frame-subsampling-factor', '1', '--chain.alignment-subsampling-factor', '1', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trisat_chain_lda_ivector_nofs', '--lat-dir', 'exp/chain/tri4b_train_sp_lats', '--dir', 'exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp']
run_tdnn_trisat_chain_lda_ivector_nofs.sh: success!
[2021-10-23 15:22:21] run_propor.sh: ok
run_tdnn_trisat_chain_lda_noivector_nofs.sh --fb-num-epochs 10 --decode false
run_tdnn_trisat_chain_lda_noivector_nofs.sh: creating lang directory with one state per phone.
run_tdnn_trisat_chain_lda_noivector_nofs.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri4b exp/chain/tri4b_train_sp_lats
steps/align_fmllr_lats.sh: feature type is lda
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri4b/final.alimdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
11 warnings in exp/chain/tri4b_train_sp_lats/log/align_pass1.*.log
8 warnings in exp/chain/tri4b_train_sp_lats/log/generate_lattices.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 1 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri4b_ali_train_sp exp/chain/tree_sp_trisat_chain_lda_noivector_nofs
steps/nnet3/chain/build_tree.sh: feature type is lda
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri4b_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri4b_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trisat_chain_lda_noivector_nofs.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trisat_chain_lda_noivector_nofs/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs/
nnet3-init exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs//init.config exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs//init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs//init.raw
nnet3-info exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs//init.raw 
nnet3-init exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs//ref.config exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs//ref.config exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/configs//ref.raw 
2021-10-23 15:23:05,175 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 15:23:05,191 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 1,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 1,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri4b_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trisat_chain_lda_noivector_nofs',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 15:23:05,200 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 15:23:05,324 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trisat_chain_lda_noivector_nofs/final.mdl exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 15:23:05,515 [steps/nnet3/chain/train.py:350 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 15:23:05,562 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 13 --right-context 13 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 1 --alignment-subsampling-factor 1 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp exp/chain/tri4b_train_sp_lats exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/tree 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (13,13)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 15:23:17,847 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/egs to exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp
2021-10-23 15:23:17,847 [steps/nnet3/chain/train.py:442 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 15:23:18,684 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 15:23:19,004 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 10 iterations
2021-10-23 15:23:19,004 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/9   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 15:23:34,457 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/9   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 15:23:48,758 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/9   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 15:24:03,383 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/9   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 15:24:18,358 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/9   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 15:24:33,238 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/9   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 15:24:47,989 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/9   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 15:25:02,770 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/9   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 15:25:17,524 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/9   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 15:25:32,267 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/9   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000015   
2021-10-23 15:25:47,029 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 15:25:47,029 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([8, 9, 10, 6, 7]) models.
2021-10-23 15:25:53,558 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp/egs
exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp: num-iters=10 nj=1..1 num-params=9.4M dim=40->1608 combine=-0.018->-0.018 (over 1) xent:train/valid[5,9]=(-2.24,-2.04/-2.56,-2.42) logprob:train/valid[5,9]=(-0.024,-0.020/-0.087,-0.079)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --chain.frame-subsampling-factor 1 --chain.alignment-subsampling-factor 1 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trisat_chain_lda_noivector_nofs --lat-dir exp/chain/tri4b_train_sp_lats --dir exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--chain.frame-subsampling-factor', '1', '--chain.alignment-subsampling-factor', '1', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trisat_chain_lda_noivector_nofs', '--lat-dir', 'exp/chain/tri4b_train_sp_lats', '--dir', 'exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp']
run_tdnn_trisat_chain_lda_noivector_nofs.sh: success!
[2021-10-23 15:26:09] run_propor.sh: ok
run_tdnn_trisat_nochain_lda_ivector.sh: creating neural net configs
tree-info exp/tri4b_ali_train_sp/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs/network.xconfig --config-dir exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs
nnet3-init exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs/init.config exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs/init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs/init.raw
nnet3-info exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs/init.raw 
nnet3-init exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs/ref.config exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs/ref.raw 
nnet3-init exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs/ref.config exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/configs/ref.raw 
2021-10-23 15:26:10,081 [steps/nnet3/train_dnn.py:36 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir  --cleanup.remove-egs true --cleanup.preserve-model-interval 100 --feat-dir=data/train_sp_hires --ali-dir exp/tri4b_ali_train_sp --lang data/lang --reporting.email= --dir=exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', '', '--cleanup.remove-egs', 'true', '--cleanup.preserve-model-interval', '100', '--feat-dir=data/train_sp_hires', '--ali-dir', 'exp/tri4b_ali_train_sp', '--lang', 'data/lang', '--reporting.email=', '--dir=exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp']
2021-10-23 15:26:10,097 [steps/nnet3/train_dnn.py:178 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/tri4b_ali_train_sp',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': None,
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'input_model': None,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 10.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': [],
 'use_gpu': 'yes'}
2021-10-23 15:26:10,113 [steps/nnet3/train_dnn.py:228 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 15:26:10,161 [steps/nnet3/train_dnn.py:238 - train - INFO ] Generating egs
steps/nnet3/get_egs.sh --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 8 --srand 0 data/train_sp_hires exp/tri4b_ali_train_sp exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/egs
File data/train_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
*** steps/nnet3/get_egs.sh: warning: the --frames-per-eg is too large to generate one archive with
*** as many as --samples-per-iter egs in it.  Consider reducing --frames-per-eg.
steps/nnet3/get_egs.sh: creating 1 archives, each with 110347 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (14,14)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/egs/ali.ark,exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/egs/ali.scp 
LOG (copy-int-vector[5.5.0~1-5caf]:main():copy-int-vector.cc:83) Copied 1890 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
2021-10-23 15:26:21,766 [steps/nnet3/train_dnn.py:276 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 15:26:24,292 [steps/nnet3/train_dnn.py:287 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2021-10-23 15:26:24,411 [steps/nnet3/train_dnn.py:294 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 15:26:24,731 [steps/nnet3/train_dnn.py:319 - train - INFO ] Training will run for 10.0 epochs = 80 iterations
2021-10-23 15:26:24,731 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 0/79   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.001700   
2021-10-23 15:26:36,211 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 1/79   Jobs: 1   Epoch: 0.12/10.0 (1.2% complete)   lr: 0.001652   
2021-10-23 15:26:46,944 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 2/79   Jobs: 1   Epoch: 0.25/10.0 (2.5% complete)   lr: 0.001605   
2021-10-23 15:26:57,656 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 3/79   Jobs: 1   Epoch: 0.38/10.0 (3.8% complete)   lr: 0.001559   
2021-10-23 15:27:08,373 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 4/79   Jobs: 1   Epoch: 0.50/10.0 (5.0% complete)   lr: 0.001515   
2021-10-23 15:27:19,148 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 5/79   Jobs: 1   Epoch: 0.62/10.0 (6.2% complete)   lr: 0.001472   
2021-10-23 15:27:29,772 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 6/79   Jobs: 1   Epoch: 0.75/10.0 (7.5% complete)   lr: 0.001430   
2021-10-23 15:27:40,401 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 7/79   Jobs: 1   Epoch: 0.88/10.0 (8.8% complete)   lr: 0.001390   
2021-10-23 15:27:51,106 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 8/79   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.001350   
2021-10-23 15:28:01,787 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 9/79   Jobs: 1   Epoch: 1.12/10.0 (11.2% complete)   lr: 0.001312   
2021-10-23 15:28:12,475 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 10/79   Jobs: 1   Epoch: 1.25/10.0 (12.5% complete)   lr: 0.001275   
2021-10-23 15:28:23,182 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 11/79   Jobs: 1   Epoch: 1.38/10.0 (13.8% complete)   lr: 0.001239   
2021-10-23 15:28:33,863 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 12/79   Jobs: 1   Epoch: 1.50/10.0 (15.0% complete)   lr: 0.001204   
2021-10-23 15:28:44,525 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 13/79   Jobs: 1   Epoch: 1.62/10.0 (16.2% complete)   lr: 0.001169   
2021-10-23 15:28:55,171 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 14/79   Jobs: 1   Epoch: 1.75/10.0 (17.5% complete)   lr: 0.001136   
2021-10-23 15:29:05,854 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 15/79   Jobs: 1   Epoch: 1.88/10.0 (18.8% complete)   lr: 0.001104   
2021-10-23 15:29:16,517 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 16/79   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.001073   
2021-10-23 15:29:27,203 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 17/79   Jobs: 1   Epoch: 2.12/10.0 (21.2% complete)   lr: 0.001042   
2021-10-23 15:29:37,855 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 18/79   Jobs: 1   Epoch: 2.25/10.0 (22.5% complete)   lr: 0.001013   
2021-10-23 15:29:48,560 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 19/79   Jobs: 1   Epoch: 2.38/10.0 (23.8% complete)   lr: 0.000984   
2021-10-23 15:29:59,246 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 20/79   Jobs: 1   Epoch: 2.50/10.0 (25.0% complete)   lr: 0.000956   
2021-10-23 15:30:10,810 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 21/79   Jobs: 1   Epoch: 2.62/10.0 (26.2% complete)   lr: 0.000929   
2021-10-23 15:30:21,657 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 22/79   Jobs: 1   Epoch: 2.75/10.0 (27.5% complete)   lr: 0.000903   
2021-10-23 15:30:32,467 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 23/79   Jobs: 1   Epoch: 2.88/10.0 (28.8% complete)   lr: 0.000877   
2021-10-23 15:30:43,133 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 24/79   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000852   
2021-10-23 15:30:53,815 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 25/79   Jobs: 1   Epoch: 3.12/10.0 (31.2% complete)   lr: 0.000828   
2021-10-23 15:31:04,493 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 26/79   Jobs: 1   Epoch: 3.25/10.0 (32.5% complete)   lr: 0.000804   
2021-10-23 15:31:15,190 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 27/79   Jobs: 1   Epoch: 3.38/10.0 (33.8% complete)   lr: 0.000782   
2021-10-23 15:31:25,872 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 28/79   Jobs: 1   Epoch: 3.50/10.0 (35.0% complete)   lr: 0.000759   
2021-10-23 15:31:36,532 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 29/79   Jobs: 1   Epoch: 3.62/10.0 (36.2% complete)   lr: 0.000738   
2021-10-23 15:31:47,235 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 30/79   Jobs: 1   Epoch: 3.75/10.0 (37.5% complete)   lr: 0.000717   
2021-10-23 15:31:57,966 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 31/79   Jobs: 1   Epoch: 3.88/10.0 (38.8% complete)   lr: 0.000697   
2021-10-23 15:32:08,636 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 32/79   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000677   
2021-10-23 15:32:19,322 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 33/79   Jobs: 1   Epoch: 4.12/10.0 (41.2% complete)   lr: 0.000658   
2021-10-23 15:32:30,012 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 34/79   Jobs: 1   Epoch: 4.25/10.0 (42.5% complete)   lr: 0.000639   
2021-10-23 15:32:40,695 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 35/79   Jobs: 1   Epoch: 4.38/10.0 (43.8% complete)   lr: 0.000621   
2021-10-23 15:32:51,395 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 36/79   Jobs: 1   Epoch: 4.50/10.0 (45.0% complete)   lr: 0.000603   
2021-10-23 15:33:02,093 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 37/79   Jobs: 1   Epoch: 4.62/10.0 (46.2% complete)   lr: 0.000586   
2021-10-23 15:33:12,792 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 38/79   Jobs: 1   Epoch: 4.75/10.0 (47.5% complete)   lr: 0.000569   
2021-10-23 15:33:23,513 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 39/79   Jobs: 1   Epoch: 4.88/10.0 (48.8% complete)   lr: 0.000553   
2021-10-23 15:33:34,197 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 40/79   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000538   
2021-10-23 15:33:45,772 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 41/79   Jobs: 1   Epoch: 5.12/10.0 (51.2% complete)   lr: 0.000522   
2021-10-23 15:33:56,623 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 42/79   Jobs: 1   Epoch: 5.25/10.0 (52.5% complete)   lr: 0.000508   
2021-10-23 15:34:07,455 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 43/79   Jobs: 1   Epoch: 5.38/10.0 (53.8% complete)   lr: 0.000493   
2021-10-23 15:34:18,157 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 44/79   Jobs: 1   Epoch: 5.50/10.0 (55.0% complete)   lr: 0.000479   
2021-10-23 15:34:28,839 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 45/79   Jobs: 1   Epoch: 5.62/10.0 (56.2% complete)   lr: 0.000466   
2021-10-23 15:34:39,542 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 46/79   Jobs: 1   Epoch: 5.75/10.0 (57.5% complete)   lr: 0.000452   
2021-10-23 15:34:50,222 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 47/79   Jobs: 1   Epoch: 5.88/10.0 (58.8% complete)   lr: 0.000439   
2021-10-23 15:35:00,928 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 48/79   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000427   
2021-10-23 15:35:11,596 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 49/79   Jobs: 1   Epoch: 6.12/10.0 (61.2% complete)   lr: 0.000415   
2021-10-23 15:35:22,276 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 50/79   Jobs: 1   Epoch: 6.25/10.0 (62.5% complete)   lr: 0.000403   
2021-10-23 15:35:32,981 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 51/79   Jobs: 1   Epoch: 6.38/10.0 (63.8% complete)   lr: 0.000392   
2021-10-23 15:35:43,660 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 52/79   Jobs: 1   Epoch: 6.50/10.0 (65.0% complete)   lr: 0.000381   
2021-10-23 15:35:54,346 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 53/79   Jobs: 1   Epoch: 6.62/10.0 (66.2% complete)   lr: 0.000370   
2021-10-23 15:36:05,029 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 54/79   Jobs: 1   Epoch: 6.75/10.0 (67.5% complete)   lr: 0.000359   
2021-10-23 15:36:15,712 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 55/79   Jobs: 1   Epoch: 6.88/10.0 (68.8% complete)   lr: 0.000349   
2021-10-23 15:36:26,392 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 56/79   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000339   
2021-10-23 15:36:37,102 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 57/79   Jobs: 1   Epoch: 7.12/10.0 (71.2% complete)   lr: 0.000330   
2021-10-23 15:36:47,779 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 58/79   Jobs: 1   Epoch: 7.25/10.0 (72.5% complete)   lr: 0.000320   
2021-10-23 15:36:58,476 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 59/79   Jobs: 1   Epoch: 7.38/10.0 (73.8% complete)   lr: 0.000311   
2021-10-23 15:37:09,145 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 60/79   Jobs: 1   Epoch: 7.50/10.0 (75.0% complete)   lr: 0.000302   
2021-10-23 15:37:20,711 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 61/79   Jobs: 1   Epoch: 7.62/10.0 (76.2% complete)   lr: 0.000294   
2021-10-23 15:37:31,568 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 62/79   Jobs: 1   Epoch: 7.75/10.0 (77.5% complete)   lr: 0.000285   
2021-10-23 15:37:42,411 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 63/79   Jobs: 1   Epoch: 7.88/10.0 (78.8% complete)   lr: 0.000277   
2021-10-23 15:37:53,085 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 64/79   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000269   
2021-10-23 15:38:03,746 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 65/79   Jobs: 1   Epoch: 8.12/10.0 (81.2% complete)   lr: 0.000262   
2021-10-23 15:38:14,430 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 66/79   Jobs: 1   Epoch: 8.25/10.0 (82.5% complete)   lr: 0.000254   
2021-10-23 15:38:25,151 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 67/79   Jobs: 1   Epoch: 8.38/10.0 (83.8% complete)   lr: 0.000247   
2021-10-23 15:38:35,838 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 68/79   Jobs: 1   Epoch: 8.50/10.0 (85.0% complete)   lr: 0.000240   
2021-10-23 15:38:46,554 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 69/79   Jobs: 1   Epoch: 8.62/10.0 (86.2% complete)   lr: 0.000233   
2021-10-23 15:38:57,243 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 70/79   Jobs: 1   Epoch: 8.75/10.0 (87.5% complete)   lr: 0.000227   
2021-10-23 15:39:07,966 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 71/79   Jobs: 1   Epoch: 8.88/10.0 (88.8% complete)   lr: 0.000220   
2021-10-23 15:39:18,629 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 72/79   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000214   
2021-10-23 15:39:29,339 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 73/79   Jobs: 1   Epoch: 9.12/10.0 (91.2% complete)   lr: 0.000208   
2021-10-23 15:39:40,002 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 74/79   Jobs: 1   Epoch: 9.25/10.0 (92.5% complete)   lr: 0.000202   
2021-10-23 15:39:50,700 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 75/79   Jobs: 1   Epoch: 9.38/10.0 (93.8% complete)   lr: 0.000196   
2021-10-23 15:40:01,392 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 76/79   Jobs: 1   Epoch: 9.50/10.0 (95.0% complete)   lr: 0.000191   
2021-10-23 15:40:12,076 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 77/79   Jobs: 1   Epoch: 9.62/10.0 (96.2% complete)   lr: 0.000185   
2021-10-23 15:40:22,739 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 78/79   Jobs: 1   Epoch: 9.75/10.0 (97.5% complete)   lr: 0.000180   
2021-10-23 15:40:33,429 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 79/79   Jobs: 1   Epoch: 9.88/10.0 (98.8% complete)   lr: 0.000170   
2021-10-23 15:40:44,122 [steps/nnet3/train_dnn.py:401 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 15:40:44,122 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 61, 62, 63]) models.
2021-10-23 15:40:55,977 [steps/nnet3/train_dnn.py:410 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2021-10-23 15:41:38,744 [steps/nnet3/train_dnn.py:421 - train - INFO ] Re-adjusting priors based on computed posteriors
2021-10-23 15:41:38,846 [steps/nnet3/train_dnn.py:431 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp/egs
exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp: num-iters=80 nj=1..1 num-params=8.3M dim=40+100->952 combine=-0.04->-0.03 (over 4) loglike:train/valid[52,79,combined]=(-0.055,-0.039,-0.027/-2.05,-2.10,-2.09) accuracy:train/valid[52,79,combined]=(0.9894,0.9935,0.9963/0.58,0.58,0.58)
[2021-10-23 15:41:38] run_propor.sh: ok
run_tdnn_trisat_nochain_lda_noivector.sh: creating neural net configs
tree-info exp/tri4b_ali_train_sp/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs/network.xconfig --config-dir exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs
nnet3-init exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs/init.config exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs/init.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs/init.raw
nnet3-info exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs/init.raw 
nnet3-init exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs/ref.config exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs/ref.raw 
nnet3-init exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs/ref.config exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/configs/ref.raw 
2021-10-23 15:41:39,626 [steps/nnet3/train_dnn.py:36 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir  --cleanup.remove-egs true --cleanup.preserve-model-interval 100 --feat-dir=data/train_sp_hires --ali-dir exp/tri4b_ali_train_sp --lang data/lang --reporting.email= --dir=exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', '', '--cleanup.remove-egs', 'true', '--cleanup.preserve-model-interval', '100', '--feat-dir=data/train_sp_hires', '--ali-dir', 'exp/tri4b_ali_train_sp', '--lang', 'data/lang', '--reporting.email=', '--dir=exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp']
2021-10-23 15:41:39,642 [steps/nnet3/train_dnn.py:178 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/tri4b_ali_train_sp',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': None,
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'input_model': None,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 10.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': [],
 'use_gpu': 'yes'}
2021-10-23 15:41:39,651 [steps/nnet3/train_dnn.py:228 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2021-10-23 15:41:39,700 [steps/nnet3/train_dnn.py:238 - train - INFO ] Generating egs
steps/nnet3/get_egs.sh --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 13 --right-context 13 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 8 --srand 0 data/train_sp_hires exp/tri4b_ali_train_sp exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/egs
File data/train_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
*** steps/nnet3/get_egs.sh: warning: the --frames-per-eg is too large to generate one archive with
*** as many as --samples-per-iter egs in it.  Consider reducing --frames-per-eg.
steps/nnet3/get_egs.sh: creating 1 archives, each with 110347 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (13,13)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/egs/ali.ark,exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/egs/ali.scp 
LOG (copy-int-vector[5.5.0~1-5caf]:main():copy-int-vector.cc:83) Copied 1890 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
2021-10-23 15:41:50,906 [steps/nnet3/train_dnn.py:276 - train - INFO ] Computing the preconditioning matrix for input features
2021-10-23 15:41:52,190 [steps/nnet3/train_dnn.py:287 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2021-10-23 15:41:52,311 [steps/nnet3/train_dnn.py:294 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 15:41:52,587 [steps/nnet3/train_dnn.py:319 - train - INFO ] Training will run for 10.0 epochs = 80 iterations
2021-10-23 15:41:52,587 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 0/79   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.001700   
2021-10-23 15:42:04,203 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 1/79   Jobs: 1   Epoch: 0.12/10.0 (1.2% complete)   lr: 0.001652   
2021-10-23 15:42:14,760 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 2/79   Jobs: 1   Epoch: 0.25/10.0 (2.5% complete)   lr: 0.001605   
2021-10-23 15:42:25,322 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 3/79   Jobs: 1   Epoch: 0.38/10.0 (3.8% complete)   lr: 0.001559   
2021-10-23 15:42:35,887 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 4/79   Jobs: 1   Epoch: 0.50/10.0 (5.0% complete)   lr: 0.001515   
2021-10-23 15:42:46,477 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 5/79   Jobs: 1   Epoch: 0.62/10.0 (6.2% complete)   lr: 0.001472   
2021-10-23 15:42:57,083 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 6/79   Jobs: 1   Epoch: 0.75/10.0 (7.5% complete)   lr: 0.001430   
2021-10-23 15:43:07,713 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 7/79   Jobs: 1   Epoch: 0.88/10.0 (8.8% complete)   lr: 0.001390   
2021-10-23 15:43:18,362 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 8/79   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.001350   
2021-10-23 15:43:29,006 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 9/79   Jobs: 1   Epoch: 1.12/10.0 (11.2% complete)   lr: 0.001312   
2021-10-23 15:43:39,640 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 10/79   Jobs: 1   Epoch: 1.25/10.0 (12.5% complete)   lr: 0.001275   
2021-10-23 15:43:50,295 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 11/79   Jobs: 1   Epoch: 1.38/10.0 (13.8% complete)   lr: 0.001239   
2021-10-23 15:44:00,917 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 12/79   Jobs: 1   Epoch: 1.50/10.0 (15.0% complete)   lr: 0.001204   
2021-10-23 15:44:11,570 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 13/79   Jobs: 1   Epoch: 1.62/10.0 (16.2% complete)   lr: 0.001169   
2021-10-23 15:44:22,203 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 14/79   Jobs: 1   Epoch: 1.75/10.0 (17.5% complete)   lr: 0.001136   
2021-10-23 15:44:32,894 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 15/79   Jobs: 1   Epoch: 1.88/10.0 (18.8% complete)   lr: 0.001104   
2021-10-23 15:44:43,569 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 16/79   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.001073   
2021-10-23 15:44:54,220 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 17/79   Jobs: 1   Epoch: 2.12/10.0 (21.2% complete)   lr: 0.001042   
2021-10-23 15:45:04,835 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 18/79   Jobs: 1   Epoch: 2.25/10.0 (22.5% complete)   lr: 0.001013   
2021-10-23 15:45:15,497 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 19/79   Jobs: 1   Epoch: 2.38/10.0 (23.8% complete)   lr: 0.000984   
2021-10-23 15:45:26,116 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 20/79   Jobs: 1   Epoch: 2.50/10.0 (25.0% complete)   lr: 0.000956   
2021-10-23 15:45:37,633 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 21/79   Jobs: 1   Epoch: 2.62/10.0 (26.2% complete)   lr: 0.000929   
2021-10-23 15:45:48,135 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 22/79   Jobs: 1   Epoch: 2.75/10.0 (27.5% complete)   lr: 0.000903   
2021-10-23 15:45:58,730 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 23/79   Jobs: 1   Epoch: 2.88/10.0 (28.8% complete)   lr: 0.000877   
2021-10-23 15:46:09,369 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 24/79   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000852   
2021-10-23 15:46:19,977 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 25/79   Jobs: 1   Epoch: 3.12/10.0 (31.2% complete)   lr: 0.000828   
2021-10-23 15:46:30,583 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 26/79   Jobs: 1   Epoch: 3.25/10.0 (32.5% complete)   lr: 0.000804   
2021-10-23 15:46:41,222 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 27/79   Jobs: 1   Epoch: 3.38/10.0 (33.8% complete)   lr: 0.000782   
2021-10-23 15:46:51,869 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 28/79   Jobs: 1   Epoch: 3.50/10.0 (35.0% complete)   lr: 0.000759   
2021-10-23 15:47:02,462 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 29/79   Jobs: 1   Epoch: 3.62/10.0 (36.2% complete)   lr: 0.000738   
2021-10-23 15:47:13,078 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 30/79   Jobs: 1   Epoch: 3.75/10.0 (37.5% complete)   lr: 0.000717   
2021-10-23 15:47:23,739 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 31/79   Jobs: 1   Epoch: 3.88/10.0 (38.8% complete)   lr: 0.000697   
2021-10-23 15:47:34,376 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 32/79   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000677   
2021-10-23 15:47:44,955 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 33/79   Jobs: 1   Epoch: 4.12/10.0 (41.2% complete)   lr: 0.000658   
2021-10-23 15:47:55,550 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 34/79   Jobs: 1   Epoch: 4.25/10.0 (42.5% complete)   lr: 0.000639   
2021-10-23 15:48:06,214 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 35/79   Jobs: 1   Epoch: 4.38/10.0 (43.8% complete)   lr: 0.000621   
2021-10-23 15:48:16,855 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 36/79   Jobs: 1   Epoch: 4.50/10.0 (45.0% complete)   lr: 0.000603   
2021-10-23 15:48:27,497 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 37/79   Jobs: 1   Epoch: 4.62/10.0 (46.2% complete)   lr: 0.000586   
2021-10-23 15:48:38,098 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 38/79   Jobs: 1   Epoch: 4.75/10.0 (47.5% complete)   lr: 0.000569   
2021-10-23 15:48:48,718 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 39/79   Jobs: 1   Epoch: 4.88/10.0 (48.8% complete)   lr: 0.000553   
2021-10-23 15:48:59,352 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 40/79   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000538   
2021-10-23 15:49:10,798 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 41/79   Jobs: 1   Epoch: 5.12/10.0 (51.2% complete)   lr: 0.000522   
2021-10-23 15:49:21,454 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 42/79   Jobs: 1   Epoch: 5.25/10.0 (52.5% complete)   lr: 0.000508   
2021-10-23 15:49:32,091 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 43/79   Jobs: 1   Epoch: 5.38/10.0 (53.8% complete)   lr: 0.000493   
2021-10-23 15:49:42,737 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 44/79   Jobs: 1   Epoch: 5.50/10.0 (55.0% complete)   lr: 0.000479   
2021-10-23 15:49:53,381 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 45/79   Jobs: 1   Epoch: 5.62/10.0 (56.2% complete)   lr: 0.000466   
2021-10-23 15:50:04,028 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 46/79   Jobs: 1   Epoch: 5.75/10.0 (57.5% complete)   lr: 0.000452   
2021-10-23 15:50:14,677 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 47/79   Jobs: 1   Epoch: 5.88/10.0 (58.8% complete)   lr: 0.000439   
2021-10-23 15:50:25,317 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 48/79   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000427   
2021-10-23 15:50:35,990 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 49/79   Jobs: 1   Epoch: 6.12/10.0 (61.2% complete)   lr: 0.000415   
2021-10-23 15:50:46,604 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 50/79   Jobs: 1   Epoch: 6.25/10.0 (62.5% complete)   lr: 0.000403   
2021-10-23 15:50:57,283 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 51/79   Jobs: 1   Epoch: 6.38/10.0 (63.8% complete)   lr: 0.000392   
2021-10-23 15:51:07,918 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 52/79   Jobs: 1   Epoch: 6.50/10.0 (65.0% complete)   lr: 0.000381   
2021-10-23 15:51:18,574 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 53/79   Jobs: 1   Epoch: 6.62/10.0 (66.2% complete)   lr: 0.000370   
2021-10-23 15:51:29,238 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 54/79   Jobs: 1   Epoch: 6.75/10.0 (67.5% complete)   lr: 0.000359   
2021-10-23 15:51:39,857 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 55/79   Jobs: 1   Epoch: 6.88/10.0 (68.8% complete)   lr: 0.000349   
2021-10-23 15:51:50,507 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 56/79   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000339   
2021-10-23 15:52:01,174 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 57/79   Jobs: 1   Epoch: 7.12/10.0 (71.2% complete)   lr: 0.000330   
2021-10-23 15:52:11,791 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 58/79   Jobs: 1   Epoch: 7.25/10.0 (72.5% complete)   lr: 0.000320   
2021-10-23 15:52:22,474 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 59/79   Jobs: 1   Epoch: 7.38/10.0 (73.8% complete)   lr: 0.000311   
2021-10-23 15:52:33,143 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 60/79   Jobs: 1   Epoch: 7.50/10.0 (75.0% complete)   lr: 0.000302   
2021-10-23 15:52:44,659 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 61/79   Jobs: 1   Epoch: 7.62/10.0 (76.2% complete)   lr: 0.000294   
2021-10-23 15:52:55,162 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 62/79   Jobs: 1   Epoch: 7.75/10.0 (77.5% complete)   lr: 0.000285   
2021-10-23 15:53:05,774 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 63/79   Jobs: 1   Epoch: 7.88/10.0 (78.8% complete)   lr: 0.000277   
2021-10-23 15:53:16,408 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 64/79   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000269   
2021-10-23 15:53:27,018 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 65/79   Jobs: 1   Epoch: 8.12/10.0 (81.2% complete)   lr: 0.000262   
2021-10-23 15:53:37,668 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 66/79   Jobs: 1   Epoch: 8.25/10.0 (82.5% complete)   lr: 0.000254   
2021-10-23 15:53:48,293 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 67/79   Jobs: 1   Epoch: 8.38/10.0 (83.8% complete)   lr: 0.000247   
2021-10-23 15:53:58,892 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 68/79   Jobs: 1   Epoch: 8.50/10.0 (85.0% complete)   lr: 0.000240   
2021-10-23 15:54:09,515 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 69/79   Jobs: 1   Epoch: 8.62/10.0 (86.2% complete)   lr: 0.000233   
2021-10-23 15:54:20,166 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 70/79   Jobs: 1   Epoch: 8.75/10.0 (87.5% complete)   lr: 0.000227   
2021-10-23 15:54:30,797 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 71/79   Jobs: 1   Epoch: 8.88/10.0 (88.8% complete)   lr: 0.000220   
2021-10-23 15:54:41,373 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 72/79   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000214   
2021-10-23 15:54:51,994 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 73/79   Jobs: 1   Epoch: 9.12/10.0 (91.2% complete)   lr: 0.000208   
2021-10-23 15:55:02,607 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 74/79   Jobs: 1   Epoch: 9.25/10.0 (92.5% complete)   lr: 0.000202   
2021-10-23 15:55:13,238 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 75/79   Jobs: 1   Epoch: 9.38/10.0 (93.8% complete)   lr: 0.000196   
2021-10-23 15:55:23,860 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 76/79   Jobs: 1   Epoch: 9.50/10.0 (95.0% complete)   lr: 0.000191   
2021-10-23 15:55:34,484 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 77/79   Jobs: 1   Epoch: 9.62/10.0 (96.2% complete)   lr: 0.000185   
2021-10-23 15:55:45,104 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 78/79   Jobs: 1   Epoch: 9.75/10.0 (97.5% complete)   lr: 0.000180   
2021-10-23 15:55:55,743 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 79/79   Jobs: 1   Epoch: 9.88/10.0 (98.8% complete)   lr: 0.000170   
2021-10-23 15:56:06,340 [steps/nnet3/train_dnn.py:401 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 15:56:06,340 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 61, 62, 63]) models.
2021-10-23 15:56:18,067 [steps/nnet3/train_dnn.py:410 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2021-10-23 15:57:00,177 [steps/nnet3/train_dnn.py:421 - train - INFO ] Re-adjusting priors based on computed posteriors
2021-10-23 15:57:00,267 [steps/nnet3/train_dnn.py:431 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp/egs
exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp: num-iters=80 nj=1..1 num-params=8.0M dim=40->952 combine=-0.03->-0.02 (over 4) loglike:train/valid[52,79,combined]=(-0.050,-0.026,-0.021/-2.17,-2.24,-2.23) accuracy:train/valid[52,79,combined]=(0.9902,0.9975,0.9985/0.55,0.55,0.55)
[2021-10-23 15:57:00] run_propor.sh: ok
run_tdnn_trisat_chain_delta_ivector_fs3.sh --fb-num-epochs 10 --decode false
run_tdnn_trisat_chain_delta_ivector_fs3.sh: creating lang directory with one state per phone.
run_tdnn_trisat_chain_delta_ivector_fs3.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri4b exp/chain/tri4b_train_sp_lats
steps/align_fmllr_lats.sh: feature type is lda
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri4b/final.alimdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
11 warnings in exp/chain/tri4b_train_sp_lats/log/align_pass1.*.log
8 warnings in exp/chain/tri4b_train_sp_lats/log/generate_lattices.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri4b_ali_train_sp exp/chain/tree_sp_trisat_chain_delta_ivector_fs3
steps/nnet3/chain/build_tree.sh: feature type is lda
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri4b_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri4b_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trisat_chain_delta_ivector_fs3.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trisat_chain_delta_ivector_fs3/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/configs/
nnet3-init exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/configs//ref.config exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/configs//ref.config exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/configs//ref.raw 
2021-10-23 15:57:41,636 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 15:57:41,652 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri4b_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trisat_chain_delta_ivector_fs3',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 15:57:41,667 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 15:57:41,755 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trisat_chain_delta_ivector_fs3/final.mdl exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 15:57:41,925 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 15 --right-context 15 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp exp/chain/tri4b_train_sp_lats exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/tree 
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (15,15)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 15:57:53,673 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/egs to exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp
2021-10-23 15:57:53,674 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 15:57:54,004 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 30 iterations
2021-10-23 15:57:54,005 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/29   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 15:58:04,369 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/29   Jobs: 1   Epoch: 0.33/10.0 (3.3% complete)   lr: 0.000139   
2021-10-23 15:58:13,724 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/29   Jobs: 1   Epoch: 0.67/10.0 (6.7% complete)   lr: 0.000129   
2021-10-23 15:58:23,030 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/29   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 15:58:32,385 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/29   Jobs: 1   Epoch: 1.33/10.0 (13.3% complete)   lr: 0.000110   
2021-10-23 15:58:41,697 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/29   Jobs: 1   Epoch: 1.67/10.0 (16.7% complete)   lr: 0.000102   
2021-10-23 15:58:51,062 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/29   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 15:59:00,404 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/29   Jobs: 1   Epoch: 2.33/10.0 (23.3% complete)   lr: 0.000088   
2021-10-23 15:59:09,982 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/29   Jobs: 1   Epoch: 2.67/10.0 (26.7% complete)   lr: 0.000081   
2021-10-23 15:59:19,339 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/29   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 15:59:28,934 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 10/29   Jobs: 1   Epoch: 3.33/10.0 (33.3% complete)   lr: 0.000070   
2021-10-23 15:59:38,319 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 11/29   Jobs: 1   Epoch: 3.67/10.0 (36.7% complete)   lr: 0.000064   
2021-10-23 15:59:47,896 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 12/29   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 15:59:57,273 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 13/29   Jobs: 1   Epoch: 4.33/10.0 (43.3% complete)   lr: 0.000055   
2021-10-23 16:00:06,883 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 14/29   Jobs: 1   Epoch: 4.67/10.0 (46.7% complete)   lr: 0.000051   
2021-10-23 16:00:16,495 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 15/29   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 16:00:26,073 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 16/29   Jobs: 1   Epoch: 5.33/10.0 (53.3% complete)   lr: 0.000044   
2021-10-23 16:00:35,460 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 17/29   Jobs: 1   Epoch: 5.67/10.0 (56.7% complete)   lr: 0.000041   
2021-10-23 16:00:45,043 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 18/29   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 16:00:54,420 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 19/29   Jobs: 1   Epoch: 6.33/10.0 (63.3% complete)   lr: 0.000035   
2021-10-23 16:01:04,000 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 20/29   Jobs: 1   Epoch: 6.67/10.0 (66.7% complete)   lr: 0.000032   
2021-10-23 16:01:14,349 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 21/29   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 16:01:23,908 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 22/29   Jobs: 1   Epoch: 7.33/10.0 (73.3% complete)   lr: 0.000028   
2021-10-23 16:01:33,469 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 23/29   Jobs: 1   Epoch: 7.67/10.0 (76.7% complete)   lr: 0.000026   
2021-10-23 16:01:42,851 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 24/29   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 16:01:52,432 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 25/29   Jobs: 1   Epoch: 8.33/10.0 (83.3% complete)   lr: 0.000022   
2021-10-23 16:02:01,829 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 26/29   Jobs: 1   Epoch: 8.67/10.0 (86.7% complete)   lr: 0.000020   
2021-10-23 16:02:11,409 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 27/29   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000019   
2021-10-23 16:02:20,783 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 28/29   Jobs: 1   Epoch: 9.33/10.0 (93.3% complete)   lr: 0.000017   
2021-10-23 16:02:30,363 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 29/29   Jobs: 1   Epoch: 9.67/10.0 (96.7% complete)   lr: 0.000015   
2021-10-23 16:02:39,711 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 16:02:39,711 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) models.
2021-10-23 16:02:48,814 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp/egs
exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp: num-iters=30 nj=1..1 num-params=9.0M dim=40+100->608 combine=-0.056->-0.056 (over 1) xent:train/valid[19,29]=(-1.93,-1.78/-2.05,-1.95) logprob:train/valid[19,29]=(-0.064,-0.052/-0.105,-0.096)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --egs.dir  --egs.stage -10 --egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trisat_chain_delta_ivector_fs3 --lat-dir exp/chain/tri4b_train_sp_lats --dir exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trisat_chain_delta_ivector_fs3', '--lat-dir', 'exp/chain/tri4b_train_sp_lats', '--dir', 'exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp']
run_tdnn_trisat_chain_delta_ivector_fs3.sh: success!
[2021-10-23 16:02:56] run_propor.sh: ok
run_tdnn_trisat_chain_delta_noivector_fs3.sh --fb-num-epochs 10 --decode false
run_tdnn_trisat_chain_delta_noivector_fs3.sh: creating lang directory with one state per phone.
run_tdnn_trisat_chain_delta_noivector_fs3.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri4b exp/chain/tri4b_train_sp_lats
steps/align_fmllr_lats.sh: feature type is lda
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri4b/final.alimdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/tri4b_train_sp_lats/log/generate_lattices.*.log
11 warnings in exp/chain/tri4b_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri4b_ali_train_sp exp/chain/tree_sp_trisat_chain_delta_noivector_fs3
steps/nnet3/chain/build_tree.sh: feature type is lda
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri4b_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri4b_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trisat_chain_delta_noivector_fs3.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trisat_chain_delta_noivector_fs3/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/configs/
nnet3-init exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/configs//ref.config exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/configs//ref.config exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/configs//ref.raw 
2021-10-23 16:03:38,583 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 16:03:38,599 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri4b_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trisat_chain_delta_noivector_fs3',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 16:03:38,608 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 16:03:38,699 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trisat_chain_delta_noivector_fs3/final.mdl exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 16:03:38,884 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 15 --right-context 15 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp exp/chain/tri4b_train_sp_lats exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/tree 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (15,15)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 16:03:50,606 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/egs to exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp
2021-10-23 16:03:50,607 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 16:03:50,892 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 30 iterations
2021-10-23 16:03:50,892 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/29   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 16:04:01,200 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/29   Jobs: 1   Epoch: 0.33/10.0 (3.3% complete)   lr: 0.000139   
2021-10-23 16:04:10,455 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/29   Jobs: 1   Epoch: 0.67/10.0 (6.7% complete)   lr: 0.000129   
2021-10-23 16:04:19,752 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/29   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 16:04:29,029 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/29   Jobs: 1   Epoch: 1.33/10.0 (13.3% complete)   lr: 0.000110   
2021-10-23 16:04:38,286 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/29   Jobs: 1   Epoch: 1.67/10.0 (16.7% complete)   lr: 0.000102   
2021-10-23 16:04:47,575 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/29   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 16:04:56,842 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/29   Jobs: 1   Epoch: 2.33/10.0 (23.3% complete)   lr: 0.000088   
2021-10-23 16:05:06,313 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/29   Jobs: 1   Epoch: 2.67/10.0 (26.7% complete)   lr: 0.000081   
2021-10-23 16:05:15,784 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/29   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 16:05:25,262 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 10/29   Jobs: 1   Epoch: 3.33/10.0 (33.3% complete)   lr: 0.000070   
2021-10-23 16:05:34,587 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 11/29   Jobs: 1   Epoch: 3.67/10.0 (36.7% complete)   lr: 0.000064   
2021-10-23 16:05:44,075 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 12/29   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 16:05:53,389 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 13/29   Jobs: 1   Epoch: 4.33/10.0 (43.3% complete)   lr: 0.000055   
2021-10-23 16:06:02,909 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 14/29   Jobs: 1   Epoch: 4.67/10.0 (46.7% complete)   lr: 0.000051   
2021-10-23 16:06:12,250 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 15/29   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 16:06:21,784 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 16/29   Jobs: 1   Epoch: 5.33/10.0 (53.3% complete)   lr: 0.000044   
2021-10-23 16:06:31,086 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 17/29   Jobs: 1   Epoch: 5.67/10.0 (56.7% complete)   lr: 0.000041   
2021-10-23 16:06:40,587 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 18/29   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 16:06:49,879 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 19/29   Jobs: 1   Epoch: 6.33/10.0 (63.3% complete)   lr: 0.000035   
2021-10-23 16:06:59,397 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 20/29   Jobs: 1   Epoch: 6.67/10.0 (66.7% complete)   lr: 0.000032   
2021-10-23 16:07:09,699 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 21/29   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 16:07:19,132 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 22/29   Jobs: 1   Epoch: 7.33/10.0 (73.3% complete)   lr: 0.000028   
2021-10-23 16:07:28,637 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 23/29   Jobs: 1   Epoch: 7.67/10.0 (76.7% complete)   lr: 0.000026   
2021-10-23 16:07:37,956 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 24/29   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 16:07:47,498 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 25/29   Jobs: 1   Epoch: 8.33/10.0 (83.3% complete)   lr: 0.000022   
2021-10-23 16:07:56,824 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 26/29   Jobs: 1   Epoch: 8.67/10.0 (86.7% complete)   lr: 0.000020   
2021-10-23 16:08:06,342 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 27/29   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000019   
2021-10-23 16:08:15,677 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 28/29   Jobs: 1   Epoch: 9.33/10.0 (93.3% complete)   lr: 0.000017   
2021-10-23 16:08:25,195 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 29/29   Jobs: 1   Epoch: 9.67/10.0 (96.7% complete)   lr: 0.000015   
2021-10-23 16:08:34,495 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 16:08:34,495 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) models.
2021-10-23 16:08:43,527 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp/egs
exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp: num-iters=30 nj=1..1 num-params=8.9M dim=40->608 combine=-0.062->-0.062 (over 1) xent:train/valid[19,29]=(-1.97,-1.82/-2.04,-1.94) logprob:train/valid[19,29]=(-0.071,-0.058/-0.104,-0.094)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trisat_chain_delta_noivector_fs3 --lat-dir exp/chain/tri4b_train_sp_lats --dir exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trisat_chain_delta_noivector_fs3', '--lat-dir', 'exp/chain/tri4b_train_sp_lats', '--dir', 'exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp']
run_tdnn_trisat_chain_delta_noivector_fs3.sh: success!
[2021-10-23 16:08:50] run_propor.sh: ok
run_tdnn_trisat_chain_delta_ivector_nofs.sh --fb-num-epochs 10 --decode false
run_tdnn_trisat_chain_delta_ivector_nofs.sh: creating lang directory with one state per phone.
run_tdnn_trisat_chain_delta_ivector_nofs.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri4b exp/chain/tri4b_train_sp_lats
steps/align_fmllr_lats.sh: feature type is lda
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri4b/final.alimdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
8 warnings in exp/chain/tri4b_train_sp_lats/log/generate_lattices.*.log
11 warnings in exp/chain/tri4b_train_sp_lats/log/align_pass1.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 1 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri4b_ali_train_sp exp/chain/tree_sp_trisat_chain_delta_ivector_nofs
steps/nnet3/chain/build_tree.sh: feature type is lda
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri4b_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri4b_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trisat_chain_delta_ivector_nofs.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trisat_chain_delta_ivector_nofs/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/configs/
nnet3-init exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/configs//ref.config exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/configs//ref.config exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/configs//ref.raw 
2021-10-23 16:09:33,453 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 16:09:33,469 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 1,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 1,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri4b_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trisat_chain_delta_ivector_nofs',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 16:09:33,485 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 16:09:33,607 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trisat_chain_delta_ivector_nofs/final.mdl exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 16:09:33,809 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 1 --alignment-subsampling-factor 1 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp exp/chain/tri4b_train_sp_lats exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/tree 
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (14,14)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 16:09:46,146 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/egs to exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp
2021-10-23 16:09:46,146 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 16:09:46,445 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 10 iterations
2021-10-23 16:09:46,445 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/9   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 16:10:02,000 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/9   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 16:10:16,380 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/9   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 16:10:31,102 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/9   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 16:10:50,125 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/9   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 16:11:04,574 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/9   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 16:11:19,492 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/9   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 16:11:34,320 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/9   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 16:11:49,175 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/9   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 16:12:04,006 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/9   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000015   
2021-10-23 16:12:18,686 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 16:12:18,686 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([8, 9, 10, 6, 7]) models.
2021-10-23 16:12:25,591 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp/egs
exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp: num-iters=10 nj=1..1 num-params=9.5M dim=40+100->1608 combine=-0.053->-0.053 (over 1) xent:train/valid[5,9]=(-3.15,-2.88/-3.21,-2.96) logprob:train/valid[5,9]=(-0.081,-0.053/-0.127,-0.102)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --chain.frame-subsampling-factor 1 --chain.alignment-subsampling-factor 1 --egs.dir  --egs.stage -10 --egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trisat_chain_delta_ivector_nofs --lat-dir exp/chain/tri4b_train_sp_lats --dir exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--chain.frame-subsampling-factor', '1', '--chain.alignment-subsampling-factor', '1', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts=--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trisat_chain_delta_ivector_nofs', '--lat-dir', 'exp/chain/tri4b_train_sp_lats', '--dir', 'exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp']
run_tdnn_trisat_chain_delta_ivector_nofs.sh: success!
[2021-10-23 16:12:41] run_propor.sh: ok
run_tdnn_trisat_chain_delta_noivector_nofs.sh --fb-num-epochs 10 --decode false
run_tdnn_trisat_chain_delta_noivector_nofs.sh: creating lang directory with one state per phone.
run_tdnn_trisat_chain_delta_noivector_nofs.sh: data/lang_chain already exists, not overwriting it; continuing
steps/align_fmllr_lats.sh --nj 8 --cmd run.pl --mem 2G data/train_sp data/lang_chain exp/tri4b exp/chain/tri4b_train_sp_lats
steps/align_fmllr_lats.sh: feature type is lda
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri4b/final.alimdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
11 warnings in exp/chain/tri4b_train_sp_lats/log/align_pass1.*.log
8 warnings in exp/chain/tri4b_train_sp_lats/log/generate_lattices.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 1 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 7000 data/train_sp data/lang_chain exp/tri4b_ali_train_sp exp/chain/tree_sp_trisat_chain_delta_noivector_nofs
steps/nnet3/chain/build_tree.sh: feature type is lda
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri4b_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri4b_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
run_tdnn_trisat_chain_delta_noivector_nofs.sh: creating neural net configs using the xconfig parser
tree-info exp/chain/tree_sp_trisat_chain_delta_noivector_nofs/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/configs/network.xconfig --config-dir exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/configs/
nnet3-init exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/configs//ref.config exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/configs//ref.raw 
nnet3-init exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/configs//ref.config exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/configs//ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/configs//ref.raw
nnet3-info exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/configs//ref.raw 
2021-10-23 16:13:24,414 [steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2021-10-23 16:13:24,430 [steps/nnet3/chain/train.py:281 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 1,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6',
 'egs_stage': -10,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 1.5e-05,
 'frame_subsampling_factor': 1,
 'frames_per_iter': 2500000,
 'initial_effective_lrate': 0.00015,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'exp/chain/tri4b_train_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 10.0,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'exp/chain/tree_sp_trisat_chain_delta_noivector_nofs',
 'use_gpu': 'yes',
 'xent_regularize': 0.1}
2021-10-23 16:13:24,439 [steps/nnet3/chain/train.py:338 - train - INFO ] Creating phone language-model
2021-10-23 16:13:24,563 [steps/nnet3/chain/train.py:343 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain/tree_sp_trisat_chain_delta_noivector_nofs/final.mdl exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.0~1-5caf]:main():copy-transition-model.cc:62) Copied transition model.
2021-10-23 16:13:24,758 [steps/nnet3/chain/train.py:379 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 1 --alignment-subsampling-factor 1 --stage -10 --frames-per-iter 2500000 --frames-per-eg 150,110,100 --srand 0 data/train_sp_hires exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp exp/chain/tri4b_train_sp_lats exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 1890.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
tree-info exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/tree 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 8827 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (14,14)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2021-10-23 16:13:37,070 [steps/nnet3/chain/train.py:428 - train - INFO ] Copying the properties from exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/egs to exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp
2021-10-23 16:13:37,070 [steps/nnet3/chain/train.py:451 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 16:13:37,366 [steps/nnet3/chain/train.py:485 - train - INFO ] Training will run for 10.0 epochs = 10 iterations
2021-10-23 16:13:37,366 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/9   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.000150   
2021-10-23 16:13:52,374 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 1/9   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.000119   
2021-10-23 16:14:06,685 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 2/9   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.000095   
2021-10-23 16:14:21,314 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 3/9   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000075   
2021-10-23 16:14:36,277 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 4/9   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000060   
2021-10-23 16:14:51,127 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 5/9   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000047   
2021-10-23 16:15:05,899 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 6/9   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000038   
2021-10-23 16:15:20,665 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 7/9   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000030   
2021-10-23 16:15:35,422 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 8/9   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000024   
2021-10-23 16:15:50,177 [steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 9/9   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000015   
2021-10-23 16:16:04,998 [steps/nnet3/chain/train.py:585 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 16:16:04,998 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:571 - combine_models - INFO ] Combining set([8, 9, 10, 6, 7]) models.
2021-10-23 16:16:11,401 [steps/nnet3/chain/train.py:614 - train - INFO ] Cleaning up the experiment directory exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp/egs
exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp: num-iters=10 nj=1..1 num-params=9.4M dim=40->1608 combine=-0.046->-0.046 (over 1) xent:train/valid[5,9]=(-3.00,-2.75/-3.04,-2.82) logprob:train/valid[5,9]=(-0.068,-0.047/-0.103,-0.085)
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --mem 4G --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --chain.frame-subsampling-factor 1 --chain.alignment-subsampling-factor 1 --egs.dir  --egs.stage -10 --egs.opts --frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6 --egs.chunk-width 150,110,100 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 2500000 --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.00015 --trainer.optimization.final-effective-lrate 0.000015 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir data/train_sp_hires --tree-dir exp/chain/tree_sp_trisat_chain_delta_noivector_nofs --lat-dir exp/chain/tri4b_train_sp_lats --dir exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --mem 4G', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--chain.frame-subsampling-factor', '1', '--chain.alignment-subsampling-factor', '1', '--egs.dir', '', '--egs.stage', '-10', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --max-jobs-run 6 --max-shuffle-jobs-run 6', '--egs.chunk-width', '150,110,100', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '2500000', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.00015', '--trainer.optimization.final-effective-lrate', '0.000015', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_sp_hires', '--tree-dir', 'exp/chain/tree_sp_trisat_chain_delta_noivector_nofs', '--lat-dir', 'exp/chain/tri4b_train_sp_lats', '--dir', 'exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp']
run_tdnn_trisat_chain_delta_noivector_nofs.sh: success!
[2021-10-23 16:16:27] run_propor.sh: ok
run_tdnn_trisat_nochain_delta_ivector.sh: creating neural net configs
tree-info exp/tri4b_ali_train_sp/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/configs/network.xconfig --config-dir exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/configs
nnet3-init exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/configs/ref.config exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/configs/ref.raw 
nnet3-init exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/configs/ref.config exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/configs/ref.raw 
2021-10-23 16:16:27,795 [steps/nnet3/train_dnn.py:36 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.online-ivector-dir exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir  --cleanup.remove-egs true --cleanup.preserve-model-interval 100 --feat-dir=data/train_sp_hires --ali-dir exp/tri4b_ali_train_sp --lang data/lang --reporting.email= --dir=exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', '', '--cleanup.remove-egs', 'true', '--cleanup.preserve-model-interval', '100', '--feat-dir=data/train_sp_hires', '--ali-dir', 'exp/tri4b_ali_train_sp', '--lang', 'data/lang', '--reporting.email=', '--dir=exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp']
2021-10-23 16:16:27,810 [steps/nnet3/train_dnn.py:178 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/tri4b_ali_train_sp',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': None,
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'input_model': None,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 10.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3/ivectors_train_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': [],
 'use_gpu': 'yes'}
2021-10-23 16:16:27,826 [steps/nnet3/train_dnn.py:238 - train - INFO ] Generating egs
steps/nnet3/get_egs.sh --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 8 --srand 0 data/train_sp_hires exp/tri4b_ali_train_sp exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/egs
File data/train_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
feat-to-dim scp:exp/nnet3/ivectors_train_sp_hires/ivector_online.scp - 
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
*** steps/nnet3/get_egs.sh: warning: the --frames-per-eg is too large to generate one archive with
*** as many as --samples-per-iter egs in it.  Consider reducing --frames-per-eg.
steps/nnet3/get_egs.sh: creating 1 archives, each with 110347 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (14,14)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/egs/ali.ark,exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/egs/ali.scp 
LOG (copy-int-vector[5.5.0~1-5caf]:main():copy-int-vector.cc:83) Copied 1890 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
2021-10-23 16:16:39,309 [steps/nnet3/train_dnn.py:287 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2021-10-23 16:16:39,415 [steps/nnet3/train_dnn.py:294 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 16:16:39,727 [steps/nnet3/train_dnn.py:319 - train - INFO ] Training will run for 10.0 epochs = 80 iterations
2021-10-23 16:16:39,728 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 0/79   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.001700   
2021-10-23 16:16:51,486 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 1/79   Jobs: 1   Epoch: 0.12/10.0 (1.2% complete)   lr: 0.001652   
2021-10-23 16:17:02,149 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 2/79   Jobs: 1   Epoch: 0.25/10.0 (2.5% complete)   lr: 0.001605   
2021-10-23 16:17:12,818 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 3/79   Jobs: 1   Epoch: 0.38/10.0 (3.8% complete)   lr: 0.001559   
2021-10-23 16:17:23,525 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 4/79   Jobs: 1   Epoch: 0.50/10.0 (5.0% complete)   lr: 0.001515   
2021-10-23 16:17:34,255 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 5/79   Jobs: 1   Epoch: 0.62/10.0 (6.2% complete)   lr: 0.001472   
2021-10-23 16:17:45,060 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 6/79   Jobs: 1   Epoch: 0.75/10.0 (7.5% complete)   lr: 0.001430   
2021-10-23 16:17:55,630 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 7/79   Jobs: 1   Epoch: 0.88/10.0 (8.8% complete)   lr: 0.001390   
2021-10-23 16:18:06,283 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 8/79   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.001350   
2021-10-23 16:18:16,928 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 9/79   Jobs: 1   Epoch: 1.12/10.0 (11.2% complete)   lr: 0.001312   
2021-10-23 16:18:27,592 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 10/79   Jobs: 1   Epoch: 1.25/10.0 (12.5% complete)   lr: 0.001275   
2021-10-23 16:18:38,280 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 11/79   Jobs: 1   Epoch: 1.38/10.0 (13.8% complete)   lr: 0.001239   
2021-10-23 16:18:48,948 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 12/79   Jobs: 1   Epoch: 1.50/10.0 (15.0% complete)   lr: 0.001204   
2021-10-23 16:18:59,604 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 13/79   Jobs: 1   Epoch: 1.62/10.0 (16.2% complete)   lr: 0.001169   
2021-10-23 16:19:10,241 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 14/79   Jobs: 1   Epoch: 1.75/10.0 (17.5% complete)   lr: 0.001136   
2021-10-23 16:19:20,900 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 15/79   Jobs: 1   Epoch: 1.88/10.0 (18.8% complete)   lr: 0.001104   
2021-10-23 16:19:31,544 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 16/79   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.001073   
2021-10-23 16:19:42,169 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 17/79   Jobs: 1   Epoch: 2.12/10.0 (21.2% complete)   lr: 0.001042   
2021-10-23 16:19:52,861 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 18/79   Jobs: 1   Epoch: 2.25/10.0 (22.5% complete)   lr: 0.001013   
2021-10-23 16:20:03,520 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 19/79   Jobs: 1   Epoch: 2.38/10.0 (23.8% complete)   lr: 0.000984   
2021-10-23 16:20:14,197 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 20/79   Jobs: 1   Epoch: 2.50/10.0 (25.0% complete)   lr: 0.000956   
2021-10-23 16:20:25,799 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 21/79   Jobs: 1   Epoch: 2.62/10.0 (26.2% complete)   lr: 0.000929   
2021-10-23 16:20:36,655 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 22/79   Jobs: 1   Epoch: 2.75/10.0 (27.5% complete)   lr: 0.000903   
2021-10-23 16:20:47,470 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 23/79   Jobs: 1   Epoch: 2.88/10.0 (28.8% complete)   lr: 0.000877   
2021-10-23 16:20:58,136 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 24/79   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000852   
2021-10-23 16:21:08,782 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 25/79   Jobs: 1   Epoch: 3.12/10.0 (31.2% complete)   lr: 0.000828   
2021-10-23 16:21:19,434 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 26/79   Jobs: 1   Epoch: 3.25/10.0 (32.5% complete)   lr: 0.000804   
2021-10-23 16:21:30,138 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 27/79   Jobs: 1   Epoch: 3.38/10.0 (33.8% complete)   lr: 0.000782   
2021-10-23 16:21:40,793 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 28/79   Jobs: 1   Epoch: 3.50/10.0 (35.0% complete)   lr: 0.000759   
2021-10-23 16:21:51,468 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 29/79   Jobs: 1   Epoch: 3.62/10.0 (36.2% complete)   lr: 0.000738   
2021-10-23 16:22:02,163 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 30/79   Jobs: 1   Epoch: 3.75/10.0 (37.5% complete)   lr: 0.000717   
2021-10-23 16:22:12,844 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 31/79   Jobs: 1   Epoch: 3.88/10.0 (38.8% complete)   lr: 0.000697   
2021-10-23 16:22:23,514 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 32/79   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000677   
2021-10-23 16:22:34,193 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 33/79   Jobs: 1   Epoch: 4.12/10.0 (41.2% complete)   lr: 0.000658   
2021-10-23 16:22:44,829 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 34/79   Jobs: 1   Epoch: 4.25/10.0 (42.5% complete)   lr: 0.000639   
2021-10-23 16:22:55,485 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 35/79   Jobs: 1   Epoch: 4.38/10.0 (43.8% complete)   lr: 0.000621   
2021-10-23 16:23:06,127 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 36/79   Jobs: 1   Epoch: 4.50/10.0 (45.0% complete)   lr: 0.000603   
2021-10-23 16:23:16,827 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 37/79   Jobs: 1   Epoch: 4.62/10.0 (46.2% complete)   lr: 0.000586   
2021-10-23 16:23:27,508 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 38/79   Jobs: 1   Epoch: 4.75/10.0 (47.5% complete)   lr: 0.000569   
2021-10-23 16:23:38,167 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 39/79   Jobs: 1   Epoch: 4.88/10.0 (48.8% complete)   lr: 0.000553   
2021-10-23 16:23:48,836 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 40/79   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000538   
2021-10-23 16:24:00,389 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 41/79   Jobs: 1   Epoch: 5.12/10.0 (51.2% complete)   lr: 0.000522   
2021-10-23 16:24:11,264 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 42/79   Jobs: 1   Epoch: 5.25/10.0 (52.5% complete)   lr: 0.000508   
2021-10-23 16:24:22,070 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 43/79   Jobs: 1   Epoch: 5.38/10.0 (53.8% complete)   lr: 0.000493   
2021-10-23 16:24:32,724 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 44/79   Jobs: 1   Epoch: 5.50/10.0 (55.0% complete)   lr: 0.000479   
2021-10-23 16:24:43,385 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 45/79   Jobs: 1   Epoch: 5.62/10.0 (56.2% complete)   lr: 0.000466   
2021-10-23 16:24:54,092 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 46/79   Jobs: 1   Epoch: 5.75/10.0 (57.5% complete)   lr: 0.000452   
2021-10-23 16:25:04,751 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 47/79   Jobs: 1   Epoch: 5.88/10.0 (58.8% complete)   lr: 0.000439   
2021-10-23 16:25:15,412 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 48/79   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000427   
2021-10-23 16:25:26,064 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 49/79   Jobs: 1   Epoch: 6.12/10.0 (61.2% complete)   lr: 0.000415   
2021-10-23 16:25:36,724 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 50/79   Jobs: 1   Epoch: 6.25/10.0 (62.5% complete)   lr: 0.000403   
2021-10-23 16:25:47,404 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 51/79   Jobs: 1   Epoch: 6.38/10.0 (63.8% complete)   lr: 0.000392   
2021-10-23 16:25:58,057 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 52/79   Jobs: 1   Epoch: 6.50/10.0 (65.0% complete)   lr: 0.000381   
2021-10-23 16:26:08,723 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 53/79   Jobs: 1   Epoch: 6.62/10.0 (66.2% complete)   lr: 0.000370   
2021-10-23 16:26:19,392 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 54/79   Jobs: 1   Epoch: 6.75/10.0 (67.5% complete)   lr: 0.000359   
2021-10-23 16:26:30,070 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 55/79   Jobs: 1   Epoch: 6.88/10.0 (68.8% complete)   lr: 0.000349   
2021-10-23 16:26:40,757 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 56/79   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000339   
2021-10-23 16:26:51,444 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 57/79   Jobs: 1   Epoch: 7.12/10.0 (71.2% complete)   lr: 0.000330   
2021-10-23 16:27:02,108 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 58/79   Jobs: 1   Epoch: 7.25/10.0 (72.5% complete)   lr: 0.000320   
2021-10-23 16:27:12,783 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 59/79   Jobs: 1   Epoch: 7.38/10.0 (73.8% complete)   lr: 0.000311   
2021-10-23 16:27:23,450 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 60/79   Jobs: 1   Epoch: 7.50/10.0 (75.0% complete)   lr: 0.000302   
2021-10-23 16:27:35,026 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 61/79   Jobs: 1   Epoch: 7.62/10.0 (76.2% complete)   lr: 0.000294   
2021-10-23 16:27:45,900 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 62/79   Jobs: 1   Epoch: 7.75/10.0 (77.5% complete)   lr: 0.000285   
2021-10-23 16:27:56,740 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 63/79   Jobs: 1   Epoch: 7.88/10.0 (78.8% complete)   lr: 0.000277   
2021-10-23 16:28:07,384 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 64/79   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000269   
2021-10-23 16:28:18,044 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 65/79   Jobs: 1   Epoch: 8.12/10.0 (81.2% complete)   lr: 0.000262   
2021-10-23 16:28:28,754 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 66/79   Jobs: 1   Epoch: 8.25/10.0 (82.5% complete)   lr: 0.000254   
2021-10-23 16:28:39,423 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 67/79   Jobs: 1   Epoch: 8.38/10.0 (83.8% complete)   lr: 0.000247   
2021-10-23 16:28:50,071 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 68/79   Jobs: 1   Epoch: 8.50/10.0 (85.0% complete)   lr: 0.000240   
2021-10-23 16:29:00,708 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 69/79   Jobs: 1   Epoch: 8.62/10.0 (86.2% complete)   lr: 0.000233   
2021-10-23 16:29:11,358 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 70/79   Jobs: 1   Epoch: 8.75/10.0 (87.5% complete)   lr: 0.000227   
2021-10-23 16:29:22,060 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 71/79   Jobs: 1   Epoch: 8.88/10.0 (88.8% complete)   lr: 0.000220   
2021-10-23 16:29:32,705 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 72/79   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000214   
2021-10-23 16:29:43,366 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 73/79   Jobs: 1   Epoch: 9.12/10.0 (91.2% complete)   lr: 0.000208   
2021-10-23 16:29:54,018 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 74/79   Jobs: 1   Epoch: 9.25/10.0 (92.5% complete)   lr: 0.000202   
2021-10-23 16:30:04,677 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 75/79   Jobs: 1   Epoch: 9.38/10.0 (93.8% complete)   lr: 0.000196   
2021-10-23 16:30:15,322 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 76/79   Jobs: 1   Epoch: 9.50/10.0 (95.0% complete)   lr: 0.000191   
2021-10-23 16:30:25,986 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 77/79   Jobs: 1   Epoch: 9.62/10.0 (96.2% complete)   lr: 0.000185   
2021-10-23 16:30:36,630 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 78/79   Jobs: 1   Epoch: 9.75/10.0 (97.5% complete)   lr: 0.000180   
2021-10-23 16:30:47,300 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 79/79   Jobs: 1   Epoch: 9.88/10.0 (98.8% complete)   lr: 0.000170   
2021-10-23 16:30:57,959 [steps/nnet3/train_dnn.py:401 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 16:30:57,959 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 61, 62, 63]) models.
2021-10-23 16:31:09,992 [steps/nnet3/train_dnn.py:410 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2021-10-23 16:31:52,885 [steps/nnet3/train_dnn.py:421 - train - INFO ] Re-adjusting priors based on computed posteriors
2021-10-23 16:31:52,970 [steps/nnet3/train_dnn.py:431 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp/egs
exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp: num-iters=80 nj=1..1 num-params=8.2M dim=40+100->952 combine=-0.33->-0.32 (over 5) loglike:train/valid[52,79,combined]=(-0.38,-0.28,-0.26/-1.65,-1.72,-1.72) accuracy:train/valid[52,79,combined]=(0.875,0.914,0.921/0.56,0.56,0.56)
[2021-10-23 16:31:53] run_propor.sh: ok
run_tdnn_trisat_nochain_delta_noivector.sh: creating neural net configs
tree-info exp/tri4b_ali_train_sp/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/configs/network.xconfig --config-dir exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/configs
nnet3-init exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/configs/ref.config exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/configs/ref.raw 
nnet3-init exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/configs/ref.config exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/configs/ref.raw 
LOG (nnet3-init[5.5.0~1-5caf]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/configs/ref.raw
nnet3-info exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/configs/ref.raw 
2021-10-23 16:31:53,783 [steps/nnet3/train_dnn.py:36 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 10 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 1 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir  --cleanup.remove-egs true --cleanup.preserve-model-interval 100 --feat-dir=data/train_sp_hires --ali-dir exp/tri4b_ali_train_sp --lang data/lang --reporting.email= --dir=exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '10', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '1', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', '', '--cleanup.remove-egs', 'true', '--cleanup.preserve-model-interval', '100', '--feat-dir=data/train_sp_hires', '--ali-dir', 'exp/tri4b_ali_train_sp', '--lang', 'data/lang', '--reporting.email=', '--dir=exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp']
2021-10-23 16:31:53,798 [steps/nnet3/train_dnn.py:178 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/tri4b_ali_train_sp',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': None,
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_sp_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'input_model': None,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 10.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': [],
 'use_gpu': 'yes'}
2021-10-23 16:31:53,807 [steps/nnet3/train_dnn.py:238 - train - INFO ] Generating egs
steps/nnet3/get_egs.sh --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir  --left-context 14 --right-context 14 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 8 --srand 0 data/train_sp_hires exp/tri4b_ali_train_sp exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/egs
File data/train_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
*** steps/nnet3/get_egs.sh: warning: the --frames-per-eg is too large to generate one archive with
*** as many as --samples-per-iter egs in it.  Consider reducing --frames-per-eg.
steps/nnet3/get_egs.sh: creating 1 archives, each with 110347 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (14,14)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/egs/ali.ark,exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/egs/ali.scp 
LOG (copy-int-vector[5.5.0~1-5caf]:main():copy-int-vector.cc:83) Copied 1890 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
2021-10-23 16:32:05,029 [steps/nnet3/train_dnn.py:287 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2021-10-23 16:32:05,150 [steps/nnet3/train_dnn.py:294 - train - INFO ] Preparing the initial acoustic model.
2021-10-23 16:32:05,451 [steps/nnet3/train_dnn.py:319 - train - INFO ] Training will run for 10.0 epochs = 80 iterations
2021-10-23 16:32:05,451 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 0/79   Jobs: 1   Epoch: 0.00/10.0 (0.0% complete)   lr: 0.001700   
2021-10-23 16:32:17,224 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 1/79   Jobs: 1   Epoch: 0.12/10.0 (1.2% complete)   lr: 0.001652   
2021-10-23 16:32:27,797 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 2/79   Jobs: 1   Epoch: 0.25/10.0 (2.5% complete)   lr: 0.001605   
2021-10-23 16:32:38,416 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 3/79   Jobs: 1   Epoch: 0.38/10.0 (3.8% complete)   lr: 0.001559   
2021-10-23 16:32:49,081 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 4/79   Jobs: 1   Epoch: 0.50/10.0 (5.0% complete)   lr: 0.001515   
2021-10-23 16:32:59,737 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 5/79   Jobs: 1   Epoch: 0.62/10.0 (6.2% complete)   lr: 0.001472   
2021-10-23 16:33:10,390 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 6/79   Jobs: 1   Epoch: 0.75/10.0 (7.5% complete)   lr: 0.001430   
2021-10-23 16:33:21,096 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 7/79   Jobs: 1   Epoch: 0.88/10.0 (8.8% complete)   lr: 0.001390   
2021-10-23 16:33:31,758 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 8/79   Jobs: 1   Epoch: 1.00/10.0 (10.0% complete)   lr: 0.001350   
2021-10-23 16:33:42,465 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 9/79   Jobs: 1   Epoch: 1.12/10.0 (11.2% complete)   lr: 0.001312   
2021-10-23 16:33:53,164 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 10/79   Jobs: 1   Epoch: 1.25/10.0 (12.5% complete)   lr: 0.001275   
2021-10-23 16:34:03,880 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 11/79   Jobs: 1   Epoch: 1.38/10.0 (13.8% complete)   lr: 0.001239   
2021-10-23 16:34:14,568 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 12/79   Jobs: 1   Epoch: 1.50/10.0 (15.0% complete)   lr: 0.001204   
2021-10-23 16:34:25,260 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 13/79   Jobs: 1   Epoch: 1.62/10.0 (16.2% complete)   lr: 0.001169   
2021-10-23 16:34:35,934 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 14/79   Jobs: 1   Epoch: 1.75/10.0 (17.5% complete)   lr: 0.001136   
2021-10-23 16:34:46,641 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 15/79   Jobs: 1   Epoch: 1.88/10.0 (18.8% complete)   lr: 0.001104   
2021-10-23 16:34:57,323 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 16/79   Jobs: 1   Epoch: 2.00/10.0 (20.0% complete)   lr: 0.001073   
2021-10-23 16:35:07,994 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 17/79   Jobs: 1   Epoch: 2.12/10.0 (21.2% complete)   lr: 0.001042   
2021-10-23 16:35:18,697 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 18/79   Jobs: 1   Epoch: 2.25/10.0 (22.5% complete)   lr: 0.001013   
2021-10-23 16:35:29,381 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 19/79   Jobs: 1   Epoch: 2.38/10.0 (23.8% complete)   lr: 0.000984   
2021-10-23 16:35:40,087 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 20/79   Jobs: 1   Epoch: 2.50/10.0 (25.0% complete)   lr: 0.000956   
2021-10-23 16:35:51,661 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 21/79   Jobs: 1   Epoch: 2.62/10.0 (26.2% complete)   lr: 0.000929   
2021-10-23 16:36:02,186 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 22/79   Jobs: 1   Epoch: 2.75/10.0 (27.5% complete)   lr: 0.000903   
2021-10-23 16:36:12,796 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 23/79   Jobs: 1   Epoch: 2.88/10.0 (28.8% complete)   lr: 0.000877   
2021-10-23 16:36:23,451 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 24/79   Jobs: 1   Epoch: 3.00/10.0 (30.0% complete)   lr: 0.000852   
2021-10-23 16:36:34,017 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 25/79   Jobs: 1   Epoch: 3.12/10.0 (31.2% complete)   lr: 0.000828   
2021-10-23 16:36:44,705 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 26/79   Jobs: 1   Epoch: 3.25/10.0 (32.5% complete)   lr: 0.000804   
2021-10-23 16:36:55,300 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 27/79   Jobs: 1   Epoch: 3.38/10.0 (33.8% complete)   lr: 0.000782   
2021-10-23 16:37:05,928 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 28/79   Jobs: 1   Epoch: 3.50/10.0 (35.0% complete)   lr: 0.000759   
2021-10-23 16:37:16,549 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 29/79   Jobs: 1   Epoch: 3.62/10.0 (36.2% complete)   lr: 0.000738   
2021-10-23 16:37:27,167 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 30/79   Jobs: 1   Epoch: 3.75/10.0 (37.5% complete)   lr: 0.000717   
2021-10-23 16:37:37,825 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 31/79   Jobs: 1   Epoch: 3.88/10.0 (38.8% complete)   lr: 0.000697   
2021-10-23 16:37:48,434 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 32/79   Jobs: 1   Epoch: 4.00/10.0 (40.0% complete)   lr: 0.000677   
2021-10-23 16:37:59,034 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 33/79   Jobs: 1   Epoch: 4.12/10.0 (41.2% complete)   lr: 0.000658   
2021-10-23 16:38:09,644 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 34/79   Jobs: 1   Epoch: 4.25/10.0 (42.5% complete)   lr: 0.000639   
2021-10-23 16:38:20,252 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 35/79   Jobs: 1   Epoch: 4.38/10.0 (43.8% complete)   lr: 0.000621   
2021-10-23 16:38:30,890 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 36/79   Jobs: 1   Epoch: 4.50/10.0 (45.0% complete)   lr: 0.000603   
2021-10-23 16:38:41,548 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 37/79   Jobs: 1   Epoch: 4.62/10.0 (46.2% complete)   lr: 0.000586   
2021-10-23 16:38:52,121 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 38/79   Jobs: 1   Epoch: 4.75/10.0 (47.5% complete)   lr: 0.000569   
2021-10-23 16:39:02,724 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 39/79   Jobs: 1   Epoch: 4.88/10.0 (48.8% complete)   lr: 0.000553   
2021-10-23 16:39:13,384 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 40/79   Jobs: 1   Epoch: 5.00/10.0 (50.0% complete)   lr: 0.000538   
2021-10-23 16:39:24,957 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 41/79   Jobs: 1   Epoch: 5.12/10.0 (51.2% complete)   lr: 0.000522   
2021-10-23 16:39:35,674 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 42/79   Jobs: 1   Epoch: 5.25/10.0 (52.5% complete)   lr: 0.000508   
2021-10-23 16:39:46,367 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 43/79   Jobs: 1   Epoch: 5.38/10.0 (53.8% complete)   lr: 0.000493   
2021-10-23 16:39:57,066 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 44/79   Jobs: 1   Epoch: 5.50/10.0 (55.0% complete)   lr: 0.000479   
2021-10-23 16:40:07,784 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 45/79   Jobs: 1   Epoch: 5.62/10.0 (56.2% complete)   lr: 0.000466   
2021-10-23 16:40:18,481 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 46/79   Jobs: 1   Epoch: 5.75/10.0 (57.5% complete)   lr: 0.000452   
2021-10-23 16:40:29,101 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 47/79   Jobs: 1   Epoch: 5.88/10.0 (58.8% complete)   lr: 0.000439   
2021-10-23 16:40:39,724 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 48/79   Jobs: 1   Epoch: 6.00/10.0 (60.0% complete)   lr: 0.000427   
2021-10-23 16:40:50,344 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 49/79   Jobs: 1   Epoch: 6.12/10.0 (61.2% complete)   lr: 0.000415   
2021-10-23 16:41:00,972 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 50/79   Jobs: 1   Epoch: 6.25/10.0 (62.5% complete)   lr: 0.000403   
2021-10-23 16:41:11,585 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 51/79   Jobs: 1   Epoch: 6.38/10.0 (63.8% complete)   lr: 0.000392   
2021-10-23 16:41:22,205 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 52/79   Jobs: 1   Epoch: 6.50/10.0 (65.0% complete)   lr: 0.000381   
2021-10-23 16:41:32,807 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 53/79   Jobs: 1   Epoch: 6.62/10.0 (66.2% complete)   lr: 0.000370   
2021-10-23 16:41:43,424 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 54/79   Jobs: 1   Epoch: 6.75/10.0 (67.5% complete)   lr: 0.000359   
2021-10-23 16:41:54,081 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 55/79   Jobs: 1   Epoch: 6.88/10.0 (68.8% complete)   lr: 0.000349   
2021-10-23 16:42:04,684 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 56/79   Jobs: 1   Epoch: 7.00/10.0 (70.0% complete)   lr: 0.000339   
2021-10-23 16:42:15,305 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 57/79   Jobs: 1   Epoch: 7.12/10.0 (71.2% complete)   lr: 0.000330   
2021-10-23 16:42:25,907 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 58/79   Jobs: 1   Epoch: 7.25/10.0 (72.5% complete)   lr: 0.000320   
2021-10-23 16:42:36,578 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 59/79   Jobs: 1   Epoch: 7.38/10.0 (73.8% complete)   lr: 0.000311   
2021-10-23 16:42:47,201 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 60/79   Jobs: 1   Epoch: 7.50/10.0 (75.0% complete)   lr: 0.000302   
2021-10-23 16:42:58,723 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 61/79   Jobs: 1   Epoch: 7.62/10.0 (76.2% complete)   lr: 0.000294   
2021-10-23 16:43:09,466 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 62/79   Jobs: 1   Epoch: 7.75/10.0 (77.5% complete)   lr: 0.000285   
2021-10-23 16:43:20,150 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 63/79   Jobs: 1   Epoch: 7.88/10.0 (78.8% complete)   lr: 0.000277   
2021-10-23 16:43:30,835 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 64/79   Jobs: 1   Epoch: 8.00/10.0 (80.0% complete)   lr: 0.000269   
2021-10-23 16:43:41,507 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 65/79   Jobs: 1   Epoch: 8.12/10.0 (81.2% complete)   lr: 0.000262   
2021-10-23 16:43:52,207 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 66/79   Jobs: 1   Epoch: 8.25/10.0 (82.5% complete)   lr: 0.000254   
2021-10-23 16:44:02,904 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 67/79   Jobs: 1   Epoch: 8.38/10.0 (83.8% complete)   lr: 0.000247   
2021-10-23 16:44:13,578 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 68/79   Jobs: 1   Epoch: 8.50/10.0 (85.0% complete)   lr: 0.000240   
2021-10-23 16:44:24,255 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 69/79   Jobs: 1   Epoch: 8.62/10.0 (86.2% complete)   lr: 0.000233   
2021-10-23 16:44:34,939 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 70/79   Jobs: 1   Epoch: 8.75/10.0 (87.5% complete)   lr: 0.000227   
2021-10-23 16:44:45,636 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 71/79   Jobs: 1   Epoch: 8.88/10.0 (88.8% complete)   lr: 0.000220   
2021-10-23 16:44:56,312 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 72/79   Jobs: 1   Epoch: 9.00/10.0 (90.0% complete)   lr: 0.000214   
2021-10-23 16:45:07,015 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 73/79   Jobs: 1   Epoch: 9.12/10.0 (91.2% complete)   lr: 0.000208   
2021-10-23 16:45:17,699 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 74/79   Jobs: 1   Epoch: 9.25/10.0 (92.5% complete)   lr: 0.000202   
2021-10-23 16:45:28,370 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 75/79   Jobs: 1   Epoch: 9.38/10.0 (93.8% complete)   lr: 0.000196   
2021-10-23 16:45:39,058 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 76/79   Jobs: 1   Epoch: 9.50/10.0 (95.0% complete)   lr: 0.000191   
2021-10-23 16:45:49,720 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 77/79   Jobs: 1   Epoch: 9.62/10.0 (96.2% complete)   lr: 0.000185   
2021-10-23 16:46:00,389 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 78/79   Jobs: 1   Epoch: 9.75/10.0 (97.5% complete)   lr: 0.000180   
2021-10-23 16:46:11,063 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 79/79   Jobs: 1   Epoch: 9.88/10.0 (98.8% complete)   lr: 0.000170   
2021-10-23 16:46:21,752 [steps/nnet3/train_dnn.py:401 - train - INFO ] Doing final combination to produce final.mdl
2021-10-23 16:46:21,752 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 61, 62, 63]) models.
2021-10-23 16:46:33,783 [steps/nnet3/train_dnn.py:410 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2021-10-23 16:47:16,511 [steps/nnet3/train_dnn.py:421 - train - INFO ] Re-adjusting priors based on computed posteriors
2021-10-23 16:47:16,594 [steps/nnet3/train_dnn.py:431 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp/egs
exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp: num-iters=80 nj=1..1 num-params=8.0M dim=40->952 combine=-0.47->-0.45 (over 5) loglike:train/valid[52,79,combined]=(-0.55,-0.39,-0.38/-1.69,-1.70,-1.67) accuracy:train/valid[52,79,combined]=(0.805,0.861,0.868/0.54,0.55,0.55)
[2021-10-23 16:47:16] run_propor.sh: ok
[95m[2021-10-23 16:47:16] run_align.sh: extend lex[0m
removed 'alignme/local/dict/lexiconp.txt'
removed 'alignme/local/dict/lexiconp_silprob.txt'
[93m[2021-10-23 16:47:16] run_align.sh: prep lang[0m
utils/prepare_lang.sh alignme/local/dict <UNK> alignme/local/lang_tmp alignme/lang
Checking alignme/local/dict/silence_phones.txt ...
--> reading alignme/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/local/dict/silence_phones.txt is OK

Checking alignme/local/dict/optional_silence.txt ...
--> reading alignme/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/local/dict/optional_silence.txt is OK

Checking alignme/local/dict/nonsilence_phones.txt ...
--> reading alignme/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking alignme/local/dict/lexicon.txt
--> reading alignme/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/local/dict/lexicon.txt is OK

Checking alignme/local/dict/extra_questions.txt ...
--> reading alignme/local/dict/extra_questions.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/local/dict/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory alignme/local/dict]

**Creating alignme/local/dict/lexiconp.txt from alignme/local/dict/lexicon.txt
fstaddselfloops alignme/lang/phones/wdisambig_phones.int alignme/lang/phones/wdisambig_words.int 
prepare_lang.sh: validating output directory
utils/validate_lang.pl alignme/lang
Checking existence of separator file
separator file alignme/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking alignme/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking alignme/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in alignme/lang/phones/context_indep.txt
--> alignme/lang/phones/context_indep.int corresponds to alignme/lang/phones/context_indep.txt
--> alignme/lang/phones/context_indep.csl corresponds to alignme/lang/phones/context_indep.txt
--> alignme/lang/phones/context_indep.{txt, int, csl} are OK

Checking alignme/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 152 entry/entries in alignme/lang/phones/nonsilence.txt
--> alignme/lang/phones/nonsilence.int corresponds to alignme/lang/phones/nonsilence.txt
--> alignme/lang/phones/nonsilence.csl corresponds to alignme/lang/phones/nonsilence.txt
--> alignme/lang/phones/nonsilence.{txt, int, csl} are OK

Checking alignme/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in alignme/lang/phones/silence.txt
--> alignme/lang/phones/silence.int corresponds to alignme/lang/phones/silence.txt
--> alignme/lang/phones/silence.csl corresponds to alignme/lang/phones/silence.txt
--> alignme/lang/phones/silence.{txt, int, csl} are OK

Checking alignme/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.int corresponds to alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.csl corresponds to alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.{txt, int, csl} are OK

Checking alignme/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 13 entry/entries in alignme/lang/phones/disambig.txt
--> alignme/lang/phones/disambig.int corresponds to alignme/lang/phones/disambig.txt
--> alignme/lang/phones/disambig.csl corresponds to alignme/lang/phones/disambig.txt
--> alignme/lang/phones/disambig.{txt, int, csl} are OK

Checking alignme/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in alignme/lang/phones/roots.txt
--> alignme/lang/phones/roots.int corresponds to alignme/lang/phones/roots.txt
--> alignme/lang/phones/roots.{txt, int} are OK

Checking alignme/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in alignme/lang/phones/sets.txt
--> alignme/lang/phones/sets.int corresponds to alignme/lang/phones/sets.txt
--> alignme/lang/phones/sets.{txt, int} are OK

Checking alignme/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in alignme/lang/phones/extra_questions.txt
--> alignme/lang/phones/extra_questions.int corresponds to alignme/lang/phones/extra_questions.txt
--> alignme/lang/phones/extra_questions.{txt, int} are OK

Checking alignme/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 162 entry/entries in alignme/lang/phones/word_boundary.txt
--> alignme/lang/phones/word_boundary.int corresponds to alignme/lang/phones/word_boundary.txt
--> alignme/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> alignme/lang/phones/disambig.txt has "#0" and "#1"
--> alignme/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> alignme/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> alignme/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> alignme/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> alignme/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 33 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 36 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking alignme/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in alignme/lang/oov.txt
--> alignme/lang/oov.int corresponds to alignme/lang/oov.txt
--> alignme/lang/oov.{txt, int} are OK

--> alignme/lang/L.fst is olabel sorted
--> alignme/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory alignme/lang]
utils/validate_lang.pl alignme/lang
Checking existence of separator file
separator file alignme/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking alignme/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking alignme/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in alignme/lang/phones/context_indep.txt
--> alignme/lang/phones/context_indep.int corresponds to alignme/lang/phones/context_indep.txt
--> alignme/lang/phones/context_indep.csl corresponds to alignme/lang/phones/context_indep.txt
--> alignme/lang/phones/context_indep.{txt, int, csl} are OK

Checking alignme/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 152 entry/entries in alignme/lang/phones/nonsilence.txt
--> alignme/lang/phones/nonsilence.int corresponds to alignme/lang/phones/nonsilence.txt
--> alignme/lang/phones/nonsilence.csl corresponds to alignme/lang/phones/nonsilence.txt
--> alignme/lang/phones/nonsilence.{txt, int, csl} are OK

Checking alignme/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in alignme/lang/phones/silence.txt
--> alignme/lang/phones/silence.int corresponds to alignme/lang/phones/silence.txt
--> alignme/lang/phones/silence.csl corresponds to alignme/lang/phones/silence.txt
--> alignme/lang/phones/silence.{txt, int, csl} are OK

Checking alignme/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.int corresponds to alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.csl corresponds to alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.{txt, int, csl} are OK

Checking alignme/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 13 entry/entries in alignme/lang/phones/disambig.txt
--> alignme/lang/phones/disambig.int corresponds to alignme/lang/phones/disambig.txt
--> alignme/lang/phones/disambig.csl corresponds to alignme/lang/phones/disambig.txt
--> alignme/lang/phones/disambig.{txt, int, csl} are OK

Checking alignme/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in alignme/lang/phones/roots.txt
--> alignme/lang/phones/roots.int corresponds to alignme/lang/phones/roots.txt
--> alignme/lang/phones/roots.{txt, int} are OK

Checking alignme/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in alignme/lang/phones/sets.txt
--> alignme/lang/phones/sets.int corresponds to alignme/lang/phones/sets.txt
--> alignme/lang/phones/sets.{txt, int} are OK

Checking alignme/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in alignme/lang/phones/extra_questions.txt
--> alignme/lang/phones/extra_questions.int corresponds to alignme/lang/phones/extra_questions.txt
--> alignme/lang/phones/extra_questions.{txt, int} are OK

Checking alignme/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 162 entry/entries in alignme/lang/phones/word_boundary.txt
--> alignme/lang/phones/word_boundary.int corresponds to alignme/lang/phones/word_boundary.txt
--> alignme/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> alignme/lang/phones/disambig.txt has "#0" and "#1"
--> alignme/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> alignme/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> alignme/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> alignme/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> alignme/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 32 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 83 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking alignme/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in alignme/lang/oov.txt
--> alignme/lang/oov.int corresponds to alignme/lang/oov.txt
--> alignme/lang/oov.{txt, int} are OK

--> alignme/lang/L.fst is olabel sorted
--> alignme/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory alignme/lang]
[94m[2021-10-23 16:47:46] run_align.sh: prep data[0m
fix_data_dir.sh: kept all 399 utterances.
fix_data_dir.sh: old files are kept in alignme/.backup
utils/copy_data_dir.sh: copied data from alignme to alignme_lores
utils/validate_data_dir.sh: Successfully validated data-directory alignme_lores
utils/copy_data_dir.sh: copied data from alignme to alignme_hires
utils/validate_data_dir.sh: Successfully validated data-directory alignme_hires
[96m[2021-10-23 16:47:48] [run_align.sh] computing low resolution mfcc features[0m
steps/make_mfcc.sh --nj 2 alignme_lores
utils/validate_data_dir.sh: Successfully validated data-directory alignme_lores
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for alignme_lores
steps/compute_cmvn_stats.sh alignme_lores
Succeeded creating CMVN stats for alignme_lores
fix_data_dir.sh: kept all 399 utterances.
fix_data_dir.sh: old files are kept in alignme_lores/.backup
[94m[2021-10-23 16:47:49] [run_align.sh] computing high resolution mfcc features[0m
steps/make_mfcc.sh --nj 2 --mfcc-config conf/mfcc_hires.conf alignme_hires
utils/validate_data_dir.sh: Successfully validated data-directory alignme_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for alignme_hires
steps/compute_cmvn_stats.sh alignme_hires
Succeeded creating CMVN stats for alignme_hires
fix_data_dir.sh: kept all 399 utterances.
fix_data_dir.sh: old files are kept in alignme_hires/.backup
[95m[2021-10-23 16:47:50] [run_align.sh] computing ivector features[0m
steps/online/nnet2/extract_ivectors_online.sh --nj 2 alignme_hires exp/nnet3/extractor alignme/ivectors_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to alignme/ivectors_hires using the extractor in exp/nnet3/extractor.
[93m[2021-10-23 16:47:51] run_align.sh: align tdnn_mono_chain_delta_ivector_fs3_sp (mono chain)[0m
[91m[2021-10-23 16:47:51] run_align.sh: align tdnn_mono_chain_delta_ivector_nofs_sp (mono chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu false --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali
[94m[2021-10-23 16:47:51] run_align.sh: align tdnn_mono_chain_lda_ivector_fs3_sp (mono chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu false --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali
[94m[2021-10-23 16:47:51] run_align.sh: align tdnn_mono_chain_lda_ivector_nofs_sp (mono chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu false --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali
steps/nnet3/align.sh --nj 2 --use-gpu false --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp, putting alignments in alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp, putting alignments in alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp, putting alignments in alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp, putting alignments in alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 17.7944862155% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 77.1929824561% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected
ali-to-phones --frame-shift=0.03 --ctm-output exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/final.mdl 'ark:gunzip -c alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/ali.1.gz|' - 
LOG (ali-to-phones[5.5.0~1-5caf]:main():ali-to-phones.cc:134) Done 199 utterances.
ali-to-phones --frame-shift=0.03 --ctm-output exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp/final.mdl 'ark:gunzip -c alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/ali.2.gz|' - 
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali
LOG (ali-to-phones[5.5.0~1-5caf]:main():ali-to-phones.cc:134) Done 200 utterances.
fblocal/ali2ctm2pts.sh: extracting F-001.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-002.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-003.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-004.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-005.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-006.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-007.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-008.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-009.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-010.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-011.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-012.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-013.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-014.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-015.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-016.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-017.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-018.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-019.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-020.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-021.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-022.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-023.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-024.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-025.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-026.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-027.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-028.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-029.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-030.ctm from phoneids.ctmanalyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 11.2781954887% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 44.3609022556% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: extracting F-031.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: chain selected
fblocal/ali2ctm2pts.sh: extracting F-032.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-033.ctm from phoneids.ctmali-to-phones --frame-shift=0.03 --ctm-output exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/final.mdl 'ark:gunzip -c alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali/ali.1.gz|' - 
fblocal/ali2ctm2pts.sh: extracting F-034.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-035.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-036.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-037.ctm from phoneids.ctmLOG (ali-to-phones[5.5.0~1-5caf]:main():ali-to-phones.cc:134) Done 199 utterances.
fblocal/ali2ctm2pts.sh: extracting F-038.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-039.ctm from phoneids.ctmali-to-phones --frame-shift=0.03 --ctm-output exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp/final.mdl 'ark:gunzip -c alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali/ali.2.gz|' - 
fblocal/ali2ctm2pts.sh: extracting F-040.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-041.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-042.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-043.ctm from phoneids.ctmLOG (ali-to-phones[5.5.0~1-5caf]:main():ali-to-phones.cc:134) Done 200 utterances.
fblocal/ali2ctm2pts.sh: extracting F-044.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-001.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-045.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-002.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-046.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-003.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-047.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-004.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-048.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-005.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-049.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-006.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-050.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-007.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-051.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-008.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-052.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-009.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-010.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-053.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-011.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-054.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-055.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-012.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-056.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-013.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-014.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-057.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-058.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-015.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-059.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-016.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-017.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-060.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-061.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-018.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-062.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-019.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-063.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-020.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-021.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-064.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-022.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-065.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-066.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-023.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-024.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-067.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-068.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-025.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-069.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-026.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-070.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-027.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-071.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-028.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-029.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-072.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-073.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-030.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-031.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-074.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-032.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-075.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-033.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-076.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-077.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-034.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-035.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-078.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-036.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-079.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-037.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-080.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-038.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-081.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-082.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-039.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-083.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-040.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-084.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-041.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-042.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-085.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-043.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-086.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-087.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-044.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-088.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-045.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-046.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-089.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-090.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-047.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-048.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-091.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-049.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-092.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-050.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-093.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-051.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-094.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-052.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-095.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-053.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-096.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-097.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-054.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-055.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-098.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-099.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-056.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-100.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-057.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-058.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-101.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-059.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-102.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-060.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-103.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-061.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-104.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-062.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-105.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-106.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-063.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-064.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-107.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-065.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-108.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-066.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-109.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-067.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-110.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-068.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-111.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-112.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-069.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-113.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-070.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-114.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-071.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-115.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-072.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-116.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-073.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-074.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-117.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-118.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-075.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-119.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-076.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-120.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-077.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-121.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-078.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-079.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-122.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-080.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-123.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-081.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-124.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-125.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-082.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-126.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-083.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-084.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-127.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-085.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-128.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-086.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-129.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-087.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-130.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-088.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-131.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-089.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-132.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-133.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-090.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-134.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-091.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-135.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-092.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-136.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-093.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-137.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-094.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-138.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-095.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-096.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-139.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-140.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-097.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-098.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-141.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-099.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-142.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-100.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-143.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-144.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-101.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-145.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-102.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-103.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-146.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-147.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-104.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-105.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-148.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-106.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-149.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-107.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-150.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-151.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-108.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-109.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-152.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-153.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-110.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-154.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-111.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-155.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-112.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-113.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-156.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-114.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-157.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-115.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-158.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-116.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-159.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-117.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-160.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-118.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-161.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-119.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-162.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-120.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-163.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-164.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-121.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-122.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-165.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-123.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-166.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-124.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-167.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-125.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-168.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-169.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-126.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-127.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-170.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-128.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-171.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-129.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-172.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-130.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-173.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-175.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-131.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-176.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-132.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-177.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-133.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-134.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-178.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-135.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-179.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-180.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-136.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-181.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-137.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-138.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-182.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-139.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-183.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-140.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-184.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-185.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-141.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-186.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-142.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-143.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-187.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-188.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-144.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-189.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-145.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-190.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-146.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-147.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-191.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-148.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-192.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-149.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-193.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-150.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-194.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-151.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-195.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-152.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-196.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-153.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-197.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-154.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-198.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-155.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-199.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-200.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-156.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-001.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-157.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-158.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-002.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-159.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-003.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-160.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-004.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-161.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-005.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-162.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-006.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-163.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-007.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-164.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-008.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-009.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-165.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-166.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-010.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-167.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-011.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-168.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-012.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-169.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-013.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-170.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-014.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-171.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-015.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-172.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-016.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-173.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-017.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-175.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-018.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-176.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-019.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-020.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-177.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-021.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-178.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-179.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-022.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-023.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-180.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-024.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-181.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-025.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-182.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-026.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-183.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-184.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-027.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-028.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-185.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-029.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-186.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-030.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-187.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-188.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-031.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-189.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-032.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-033.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-190.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-191.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-034.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-192.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-035.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-193.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-036.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-194.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-037.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-195.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-038.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-196.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-039.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-040.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-197.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-041.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-198.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-199.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-042.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-200.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-043.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-001.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-044.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-002.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-045.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-003.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-046.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-004.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-047.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-005.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-048.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-006.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-049.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-007.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-050.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-008.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-051.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-009.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-052.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-053.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-010.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-011.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-054.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-012.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-055.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-056.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-013.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-057.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-014.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-015.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-058.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-016.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-059.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-060.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-017.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-061.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-018.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-019.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-062.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-020.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-063.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-021.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-064.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-065.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-022.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-023.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-066.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-024.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-067.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-068.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-025.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-026.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-069.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-027.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-070.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-028.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-071.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-029.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-072.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-073.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-030.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-031.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-074.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-032.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-075.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-076.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-033.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-077.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-034.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-078.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-035.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-036.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-079.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-037.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-080.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-038.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-081.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-039.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-082.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-040.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-083.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-041.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-084.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-042.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-085.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-043.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-086.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-044.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-087.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-045.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-088.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-089.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-046.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-047.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-090.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-048.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-091.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-049.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-092.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-050.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-093.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-094.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-051.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-052.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-095.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-053.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-096.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-054.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-097.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-055.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-098.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-056.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-099.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-057.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-100.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-058.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-101.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-059.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-102.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-060.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-103.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-104.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-061.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-062.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-105.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-063.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-106.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-064.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-107.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-065.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-108.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-109.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-066.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-110.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-067.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-068.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-111.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-112.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-069.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-113.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-070.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-071.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-114.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-115.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-072.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-116.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-073.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-074.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-117.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-075.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-118.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-076.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-119.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-077.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-120.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-078.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-121.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-122.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-079.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-080.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-123.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-081.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-124.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-082.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-125.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-083.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-126.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-084.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-127.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-085.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-128.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-086.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-129.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-087.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-130.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-088.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-131.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-089.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-132.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-090.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-133.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-091.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-134.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-092.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-135.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-093.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-136.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-094.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-137.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-095.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-138.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-096.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-139.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-140.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-097.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-141.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-098.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-142.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-099.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-100.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-143.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-101.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-144.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-102.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-145.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-103.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-146.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-104.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-147.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-105.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-148.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-106.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-149.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-107.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-150.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-151.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-108.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-109.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-152.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-110.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-153.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-111.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-154.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-155.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-112.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-156.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-113.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-157.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-114.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-115.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-158.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-159.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-116.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-117.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-160.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-161.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-118.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-162.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-119.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-120.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-163.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-164.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-121.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-165.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-122.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-166.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-123.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-124.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-167.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-125.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-168.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-169.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-126.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-127.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-170.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-128.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-171.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-129.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-172.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-130.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-173.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-174.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-131.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-175.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-132.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-133.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-176.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-177.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-134.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-135.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-178.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-136.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-179.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-180.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-137.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-138.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-181.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-139.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-182.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-140.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-183.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-184.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-141.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-142.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-185.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-143.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-186.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-187.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-144.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-188.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-145.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-189.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-146.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-190.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-147.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-148.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-191.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-149.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-192.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-150.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-193.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-151.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-194.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-152.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-195.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-153.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-196.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-154.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-197.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-155.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-198.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-156.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-199.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-157.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-200.ctm from phoneids.ctm
steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali ctm_tmp
fblocal/ali2ctm2pts.sh: extracting M-158.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-159.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-160.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-161.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-162.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-163.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-164.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-165.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-166.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-167.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-168.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-169.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-170.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-171.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-172.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-173.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-174.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-175.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-176.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-177.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-178.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-179.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-180.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-181.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-182.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-183.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-184.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-185.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-186.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-187.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-188.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-189.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-190.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-191.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-192.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-193.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-194.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-195.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-196.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-197.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-198.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-199.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-200.ctm from phoneids.ctm
steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali ctm_tmp
[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-001.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-002.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-003.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-004.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-005.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-006.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-007.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-008.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-009.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-010.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-011.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-012.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-013.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-014.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-015.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-016.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-017.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-018.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-019.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-020.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-021.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-022.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-023.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-024.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-025.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-026.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-027.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-028.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-029.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-030.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-031.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-032.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-033.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-034.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-035.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-036.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-037.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-038.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-039.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-040.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-041.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-042.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-043.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-044.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-045.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-046.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-047.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-048.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-049.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-050.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-051.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-052.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-053.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-054.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-055.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-056.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-057.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-058.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-059.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-060.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-061.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-062.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-063.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-064.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-065.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-066.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-067.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-068.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-069.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-070.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-071.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-072.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-073.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-074.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-075.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-076.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-077.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-078.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-079.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-080.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-081.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-082.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-083.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-084.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-085.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-086.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-087.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-088.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-089.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-090.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-091.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-092.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-093.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-094.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-095.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-096.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-097.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-098.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-099.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-100.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-101.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-102.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-103.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-104.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-105.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-106.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-107.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-108.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-109.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-110.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-111.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-112.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-113.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-114.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-115.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-116.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-117.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-118.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-119.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-120.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-121.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-122.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-123.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-124.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-125.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-126.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-127.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-128.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-129.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-130.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-131.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-132.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-133.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-134.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-135.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-136.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-137.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-138.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-139.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-140.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-141.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-142.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-143.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-144.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-145.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-146.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-147.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-148.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-149.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-150.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-151.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-152.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-153.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-154.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-155.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-156.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-157.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-158.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-159.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-160.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-161.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-162.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-163.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-164.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-165.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-166.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-167.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-168.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-169.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-170.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-171.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-172.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-173.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-175.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-176.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-177.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-178.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-179.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-180.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-181.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-182.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-183.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-184.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-185.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-186.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-187.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-188.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-189.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-190.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-191.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-192.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-193.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-194.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-195.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-196.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-197.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-198.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-199.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/F-200.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-001.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-002.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-003.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-004.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-005.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-006.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-007.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-008.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-009.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-010.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-011.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-012.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-013.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-014.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-015.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-016.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-017.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-018.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-019.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-020.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-021.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-022.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-023.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-024.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-025.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-026.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-027.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-028.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-029.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-030.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-031.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-032.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-033.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-034.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-035.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-036.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-037.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-038.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-039.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-040.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-041.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-042.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-043.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-044.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-045.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-046.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-047.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-048.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-049.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-050.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-051.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-052.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-053.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-054.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-055.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-056.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-057.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-058.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-059.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-060.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-061.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-062.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-063.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-064.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-065.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-066.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-067.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-068.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-069.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-070.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-071.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-072.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-073.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-074.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-075.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-076.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-077.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-078.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-079.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-080.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-081.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-082.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-083.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-084.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-085.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-086.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-087.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-088.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-089.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-090.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-091.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-092.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-093.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-094.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-095.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-096.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-097.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-098.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-099.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-100.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-101.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-102.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-103.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-104.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-105.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-106.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-107.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-108.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-109.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-110.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-111.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-112.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-113.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-114.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-115.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-116.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-117.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-118.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-119.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-120.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-121.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-122.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-123.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-124.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-125.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-126.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-127.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-128.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-129.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-130.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-131.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-132.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-133.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-134.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-135.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-136.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-137.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-138.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-139.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-140.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-141.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-142.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-143.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-144.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-145.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-146.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-147.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-148.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-149.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-150.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-151.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-152.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-153.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-154.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-155.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-156.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-157.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-158.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-159.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-160.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-161.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-162.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-163.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-164.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-165.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-166.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-167.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-168.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-169.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-170.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-171.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-172.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-173.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-174.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-175.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-176.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-177.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-178.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-179.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-180.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-181.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-182.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-183.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-184.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-185.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-186.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-187.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-188.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-189.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-190.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-191.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-192.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-193.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-194.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-195.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-196.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-197.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-198.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-199.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/M-200.ctm [fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
[fblocal/pts2pb.py] processing file M-001.pts [fblocal/pts2pb.py] processing file M-002.pts [fblocal/pts2pb.py] processing file M-003.pts [fblocal/pts2pb.py] processing file M-004.pts [fblocal/pts2pb.py] processing file M-005.pts [fblocal/pts2pb.py] processing file M-006.pts [fblocal/pts2pb.py] processing file M-007.pts [fblocal/pts2pb.py] processing file M-008.pts [fblocal/pts2pb.py] processing file M-009.pts [fblocal/pts2pb.py] processing file M-010.pts [fblocal/pts2pb.py] processing file M-011.pts [fblocal/pts2pb.py] processing file M-012.pts [fblocal/pts2pb.py] processing file M-013.pts [fblocal/pts2pb.py] processing file M-014.pts [fblocal/pts2pb.py] processing file M-015.pts [fblocal/pts2pb.py] processing file M-016.pts [fblocal/pts2pb.py] processing file M-017.pts [fblocal/pts2pb.py] processing file M-018.pts [fblocal/pts2pb.py] processing file M-019.pts [fblocal/pts2pb.py] processing file M-020.pts [fblocal/pts2pb.py] processing file M-021.pts [fblocal/pts2pb.py] processing file M-022.pts [fblocal/pts2pb.py] processing file M-023.pts [fblocal/pts2pb.py] processing file M-024.pts [fblocal/pts2pb.py] processing file M-025.pts [fblocal/pts2pb.py] processing file M-026.pts [fblocal/pts2pb.py] processing file M-027.pts [fblocal/pts2pb.py] processing file M-028.pts [fblocal/pts2pb.py] processing file M-029.pts [fblocal/pts2pb.py] processing file M-030.pts [fblocal/pts2pb.py] processing file M-031.pts [fblocal/pts2pb.py] processing file M-032.pts [fblocal/pts2pb.py] processing file M-033.pts [fblocal/pts2pb.py] processing file M-034.pts [fblocal/pts2pb.py] processing file M-035.pts [fblocal/pts2pb.py] processing file M-036.pts [fblocal/pts2pb.py] processing file M-037.pts [fblocal/pts2pb.py] processing file M-038.pts [fblocal/pts2pb.py] processing file M-039.pts [fblocal/pts2pb.py] processing file M-040.pts [fblocal/pts2pb.py] processing file M-041.pts [fblocal/pts2pb.py] processing file M-042.pts [fblocal/pts2pb.py] processing file M-043.pts [fblocal/pts2pb.py] processing file M-044.pts [fblocal/pts2pb.py] processing file M-045.pts [fblocal/pts2pb.py] processing file M-046.pts [fblocal/pts2pb.py] processing file M-047.pts [fblocal/pts2pb.py] processing file M-048.pts [fblocal/pts2pb.py] processing file M-049.pts [fblocal/pts2pb.py] processing file M-050.pts [fblocal/pts2pb.py] processing file M-051.pts [fblocal/pts2pb.py] processing file M-052.pts [fblocal/pts2pb.py] processing file M-053.pts [fblocal/pts2pb.py] processing file M-054.pts [fblocal/pts2pb.py] processing file M-055.pts [fblocal/pts2pb.py] processing file M-056.pts [fblocal/pts2pb.py] processing file M-057.pts [fblocal/pts2pb.py] processing file M-058.pts [fblocal/pts2pb.py] processing file M-059.pts [fblocal/pts2pb.py] processing file M-060.pts [fblocal/pts2pb.py] processing file M-061.pts [fblocal/pts2pb.py] processing file M-062.pts [fblocal/pts2pb.py] processing file M-063.pts [fblocal/pts2pb.py] processing file M-064.pts [fblocal/pts2pb.py] processing file M-065.pts [fblocal/pts2pb.py] processing file M-066.pts [fblocal/pts2pb.py] processing file M-067.pts [fblocal/pts2pb.py] processing file M-068.pts [fblocal/pts2pb.py] processing file M-069.pts [fblocal/pts2pb.py] processing file M-070.pts [fblocal/pts2pb.py] processing file M-071.pts [fblocal/pts2pb.py] processing file M-072.pts [fblocal/pts2pb.py] processing file M-073.pts [fblocal/pts2pb.py] processing file M-074.pts [fblocal/pts2pb.py] processing file M-075.pts [fblocal/pts2pb.py] processing file M-076.pts [fblocal/pts2pb.py] processing file M-077.pts [fblocal/pts2pb.py] processing file M-078.pts [fblocal/pts2pb.py] processing file M-079.pts [fblocal/pts2pb.py] processing file M-080.pts [fblocal/pts2pb.py] processing file M-081.pts [fblocal/pts2pb.py] processing file M-082.pts [fblocal/pts2pb.py] processing file M-083.pts [fblocal/pts2pb.py] processing file M-084.pts [fblocal/pts2pb.py] processing file M-085.pts [fblocal/pts2pb.py] processing file M-086.pts [fblocal/pts2pb.py] processing file M-087.pts [fblocal/pts2pb.py] processing file M-088.pts [fblocal/pts2pb.py] processing file M-089.pts [fblocal/pts2pb.py] processing file M-090.pts [fblocal/pts2pb.py] processing file M-091.pts [fblocal/pts2pb.py] processing file M-092.pts [fblocal/pts2pb.py] processing file M-093.pts [fblocal/pts2pb.py] processing file M-094.pts [fblocal/pts2pb.py] processing file M-095.pts [fblocal/pts2pb.py] processing file M-096.pts [fblocal/pts2pb.py] processing file M-097.pts [fblocal/pts2pb.py] processing file M-098.pts [fblocal/pts2pb.py] processing file M-099.pts [fblocal/pts2pb.py] processing file M-100.pts [fblocal/pts2pb.py] processing file M-101.pts [fblocal/pts2pb.py] processing file M-102.pts [fblocal/pts2pb.py] processing file M-103.pts [fblocal/pts2pb.py] processing file M-104.pts [fblocal/pts2pb.py] processing file M-105.pts [fblocal/pts2pb.py] processing file M-106.pts [fblocal/pts2pb.py] processing file M-107.pts [fblocal/pts2pb.py] processing file M-108.pts [fblocal/pts2pb.py] processing file M-109.pts [fblocal/pts2pb.py] processing file M-110.pts [fblocal/pts2pb.py] processing file M-111.pts [fblocal/pts2pb.py] processing file M-112.pts [fblocal/pts2pb.py] processing file M-113.pts [fblocal/pts2pb.py] processing file M-114.pts [fblocal/pts2pb.py] processing file M-115.pts [fblocal/pts2pb.py] processing file M-116.pts [fblocal/pts2pb.py] processing file M-117.pts [fblocal/pts2pb.py] processing file M-118.pts [fblocal/pts2pb.py] processing file M-119.pts [fblocal/pts2pb.py] processing file M-120.pts [fblocal/pts2pb.py] processing file M-121.pts [fblocal/pts2pb.py] processing file M-122.pts [fblocal/pts2pb.py] processing file M-123.pts [fblocal/pts2pb.py] processing file M-124.pts [fblocal/pts2pb.py] processing file M-125.pts [fblocal/pts2pb.py] processing file M-126.pts [fblocal/pts2pb.py] processing file M-127.pts [fblocal/pts2pb.py] processing file M-128.pts [fblocal/pts2pb.py] processing file M-129.pts [fblocal/pts2pb.py] processing file M-130.pts [fblocal/pts2pb.py] processing file M-131.pts [fblocal/pts2pb.py] processing file M-132.pts [fblocal/pts2pb.py] processing file M-133.pts [fblocal/pts2pb.py] processing file M-134.pts [fblocal/pts2pb.py] processing file M-135.pts [fblocal/pts2pb.py] processing file M-136.pts [fblocal/pts2pb.py] processing file M-137.pts [fblocal/pts2pb.py] processing file M-138.pts [fblocal/pts2pb.py] processing file M-139.pts [fblocal/pts2pb.py] processing file M-140.pts [fblocal/pts2pb.py] processing file M-141.pts [fblocal/pts2pb.py] processing file M-142.pts [fblocal/pts2pb.py] processing file M-143.pts [fblocal/pts2pb.py] processing file M-144.pts [fblocal/pts2pb.py] processing file M-145.pts [fblocal/pts2pb.py] processing file M-146.pts [fblocal/pts2pb.py] processing file M-147.pts [fblocal/pts2pb.py] processing file M-148.pts [fblocal/pts2pb.py] processing file M-149.pts [fblocal/pts2pb.py] processing file M-150.pts [fblocal/pts2pb.py] processing file M-151.pts [fblocal/pts2pb.py] processing file M-152.pts [fblocal/pts2pb.py] processing file M-153.pts [fblocal/pts2pb.py] processing file M-154.pts [fblocal/pts2pb.py] processing file M-155.pts [fblocal/pts2pb.py] processing file M-156.pts [fblocal/pts2pb.py] processing file M-157.pts [fblocal/pts2pb.py] processing file M-158.pts [fblocal/pts2pb.py] processing file M-159.pts [fblocal/pts2pb.py] processing file M-160.pts [fblocal/pts2pb.py] processing file M-161.pts [fblocal/pts2pb.py] processing file M-162.pts [fblocal/pts2pb.py] processing file M-163.pts [fblocal/pts2pb.py] processing file M-164.pts [fblocal/pts2pb.py] processing file M-165.pts [fblocal/pts2pb.py] processing file M-166.pts [fblocal/pts2pb.py] processing file M-167.pts [fblocal/pts2pb.py] processing file M-168.pts [fblocal/pts2pb.py] processing file M-169.pts [fblocal/pts2pb.py] processing file M-170.pts [fblocal/pts2pb.py] processing file M-171.pts [fblocal/pts2pb.py] processing file M-172.pts [fblocal/pts2pb.py] processing file M-173.pts [fblocal/pts2pb.py] processing file M-174.pts [fblocal/pts2pb.py] processing file M-175.pts [fblocal/pts2pb.py] processing file M-176.pts [fblocal/pts2pb.py] processing file M-177.pts [fblocal/pts2pb.py] processing file M-178.pts [fblocal/pts2pb.py] processing file M-179.pts [fblocal/pts2pb.py] processing file M-180.pts [fblocal/pts2pb.py] processing file M-181.pts [fblocal/pts2pb.py] processing file M-182.pts [fblocal/pts2pb.py] processing file M-183.pts [fblocal/pts2pb.py] processing file M-184.pts [fblocal/pts2pb.py] processing file M-185.pts [fblocal/pts2pb.py] processing file M-186.pts [fblocal/pts2pb.py] processing file M-187.pts [fblocal/pts2pb.py] processing file M-188.pts [fblocal/pts2pb.py] processing file M-189.pts [fblocal/pts2pb.py] processing file M-190.pts [fblocal/pts2pb.py] processing file M-191.pts [fblocal/pts2pb.py] processing file M-192.pts [fblocal/pts2pb.py] processing file M-193.pts [fblocal/pts2pb.py] processing file M-194.pts [fblocal/pts2pb.py] processing file M-195.pts [fblocal/pts2pb.py] processing file M-196.pts [fblocal/pts2pb.py] processing file M-197.pts [fblocal/pts2pb.py] processing file M-198.pts [fblocal/pts2pb.py] processing file M-199.pts [fblocal/pts2pb.py] processing file M-200.pts run.pl: Error opening log file ctm_tmp/log/get_ctm.2.log (again) at /home/cassio/git-all/kaldi/egs/propor_22b/s5/utils/run.pl line 294.
run.pl: Error opening log file ctm_tmp/log/get_ctm.1.log (again) at /home/cassio/git-all/kaldi/egs/propor_22b/s5/utils/run.pl line 294.
run.pl: 2 / 2 failed, log is in ctm_tmp/log/get_ctm.*.log
ok	output written to alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/ali_m.pb
[fblocal/pts2pb.py] processing file F-001.pts [fblocal/pts2pb.py] processing file F-002.pts [fblocal/pts2pb.py] processing file F-003.pts [fblocal/pts2pb.py] processing file F-004.pts [fblocal/pts2pb.py] processing file F-005.pts [fblocal/pts2pb.py] processing file F-006.pts [fblocal/pts2pb.py] processing file F-007.pts [fblocal/pts2pb.py] processing file F-008.pts [fblocal/pts2pb.py] processing file F-009.pts [fblocal/pts2pb.py] processing file F-010.pts [fblocal/pts2pb.py] processing file F-011.pts [fblocal/pts2pb.py] processing file F-012.pts [fblocal/pts2pb.py] processing file F-013.pts [fblocal/pts2pb.py] processing file F-014.pts [fblocal/pts2pb.py] processing file F-015.pts [fblocal/pts2pb.py] processing file F-016.pts [fblocal/pts2pb.py] processing file F-017.pts [fblocal/pts2pb.py] processing file F-018.pts [fblocal/pts2pb.py] processing file F-019.pts [fblocal/pts2pb.py] processing file F-020.pts [fblocal/pts2pb.py] processing file F-021.pts [fblocal/pts2pb.py] processing file F-022.pts [fblocal/pts2pb.py] processing file F-023.pts [fblocal/pts2pb.py] processing file F-024.pts [fblocal/pts2pb.py] processing file F-025.pts [fblocal/pts2pb.py] processing file F-026.pts [fblocal/pts2pb.py] processing file F-027.pts [fblocal/pts2pb.py] processing file F-028.pts [fblocal/pts2pb.py] processing file F-029.pts [fblocal/pts2pb.py] processing file F-030.pts [fblocal/pts2pb.py] processing file F-031.pts [fblocal/pts2pb.py] processing file F-032.pts [fblocal/pts2pb.py] processing file F-033.pts [fblocal/pts2pb.py] processing file F-034.pts [fblocal/pts2pb.py] processing file F-035.pts [fblocal/pts2pb.py] processing file F-036.pts [fblocal/pts2pb.py] processing file F-037.pts [fblocal/pts2pb.py] processing file F-038.pts [fblocal/pts2pb.py] processing file F-039.pts [fblocal/pts2pb.py] processing file F-040.pts [fblocal/pts2pb.py] processing file F-041.pts [fblocal/pts2pb.py] processing file F-042.pts [fblocal/pts2pb.py] processing file F-043.pts [fblocal/pts2pb.py] processing file F-044.pts [fblocal/pts2pb.py] processing file F-045.pts [fblocal/pts2pb.py] processing file F-046.pts [fblocal/pts2pb.py] processing file F-047.pts [fblocal/pts2pb.py] processing file F-048.pts [fblocal/pts2pb.py] processing file F-049.pts [fblocal/pts2pb.py] processing file F-050.pts [fblocal/pts2pb.py] processing file F-051.pts [fblocal/pts2pb.py] processing file F-052.pts [fblocal/pts2pb.py] processing file F-053.pts [fblocal/pts2pb.py] processing file F-054.pts [fblocal/pts2pb.py] processing file F-055.pts [fblocal/pts2pb.py] processing file F-056.pts [fblocal/pts2pb.py] processing file F-057.pts [fblocal/pts2pb.py] processing file F-058.pts [fblocal/pts2pb.py] processing file F-059.pts [fblocal/pts2pb.py] processing file F-060.pts [fblocal/pts2pb.py] processing file F-061.pts [fblocal/pts2pb.py] processing file F-062.pts [fblocal/pts2pb.py] processing file F-063.pts [fblocal/pts2pb.py] processing file F-064.pts [fblocal/pts2pb.py] processing file F-065.pts [fblocal/pts2pb.py] processing file F-066.pts [fblocal/pts2pb.py] processing file F-067.pts [fblocal/pts2pb.py] processing file F-068.pts [fblocal/pts2pb.py] processing file F-069.pts [fblocal/pts2pb.py] processing file F-070.pts [fblocal/pts2pb.py] processing file F-071.pts [fblocal/pts2pb.py] processing file F-072.pts [fblocal/pts2pb.py] processing file F-073.pts [fblocal/pts2pb.py] processing file F-074.pts [fblocal/pts2pb.py] processing file F-075.pts [fblocal/pts2pb.py] processing file F-076.pts [fblocal/pts2pb.py] processing file F-077.pts [fblocal/pts2pb.py] processing file F-078.pts [fblocal/pts2pb.py] processing file F-079.pts [fblocal/pts2pb.py] processing file F-080.pts [fblocal/pts2pb.py] processing file F-081.pts [fblocal/pts2pb.py] processing file F-082.pts [fblocal/pts2pb.py] processing file F-083.pts [fblocal/pts2pb.py] processing file F-084.pts [fblocal/pts2pb.py] processing file F-085.pts [fblocal/pts2pb.py] processing file F-086.pts [fblocal/pts2pb.py] processing file F-087.pts [fblocal/pts2pb.py] processing file F-088.pts [fblocal/pts2pb.py] processing file F-089.pts [fblocal/pts2pb.py] processing file F-090.pts [fblocal/pts2pb.py] processing file F-091.pts [fblocal/pts2pb.py] processing file F-092.pts [fblocal/pts2pb.py] processing file F-093.pts [fblocal/pts2pb.py] processing file F-094.pts [fblocal/pts2pb.py] processing file F-095.pts [fblocal/pts2pb.py] processing file F-096.pts [fblocal/pts2pb.py] processing file F-097.pts [fblocal/pts2pb.py] processing file F-098.pts [fblocal/pts2pb.py] processing file F-099.pts [fblocal/pts2pb.py] processing file F-100.pts [fblocal/pts2pb.py] processing file F-101.pts [fblocal/pts2pb.py] processing file F-102.pts [fblocal/pts2pb.py] processing file F-103.pts [fblocal/pts2pb.py] processing file F-104.pts [fblocal/pts2pb.py] processing file F-105.pts [fblocal/pts2pb.py] processing file F-106.pts [fblocal/pts2pb.py] processing file F-107.pts [fblocal/pts2pb.py] processing file F-108.pts [fblocal/pts2pb.py] processing file F-109.pts [fblocal/pts2pb.py] processing file F-110.pts [fblocal/pts2pb.py] processing file F-111.pts [fblocal/pts2pb.py] processing file F-112.pts [fblocal/pts2pb.py] processing file F-113.pts [fblocal/pts2pb.py] processing file F-114.pts [fblocal/pts2pb.py] processing file F-115.pts [fblocal/pts2pb.py] processing file F-116.pts [fblocal/pts2pb.py] processing file F-117.pts [fblocal/pts2pb.py] processing file F-118.pts [fblocal/pts2pb.py] processing file F-119.pts [fblocal/pts2pb.py] processing file F-120.pts [fblocal/pts2pb.py] processing file F-121.pts [fblocal/pts2pb.py] processing file F-122.pts [fblocal/pts2pb.py] processing file F-123.pts [fblocal/pts2pb.py] processing file F-124.pts [fblocal/pts2pb.py] processing file F-125.pts [fblocal/pts2pb.py] processing file F-126.pts [fblocal/pts2pb.py] processing file F-127.pts [fblocal/pts2pb.py] processing file F-128.pts [fblocal/pts2pb.py] processing file F-129.pts [fblocal/pts2pb.py] processing file F-130.pts [fblocal/pts2pb.py] processing file F-131.pts [fblocal/pts2pb.py] processing file F-132.pts [fblocal/pts2pb.py] processing file F-133.pts [fblocal/pts2pb.py] processing file F-134.pts [fblocal/pts2pb.py] processing file F-135.pts [fblocal/pts2pb.py] processing file F-136.pts [fblocal/pts2pb.py] processing file F-137.pts [fblocal/pts2pb.py] processing file F-138.pts [fblocal/pts2pb.py] processing file F-139.pts [fblocal/pts2pb.py] processing file F-140.pts [fblocal/pts2pb.py] processing file F-141.pts [fblocal/pts2pb.py] processing file F-142.pts [fblocal/pts2pb.py] processing file F-143.pts [fblocal/pts2pb.py] processing file F-144.pts [fblocal/pts2pb.py] processing file F-145.pts [fblocal/pts2pb.py] processing file F-146.pts [fblocal/pts2pb.py] processing file F-147.pts [fblocal/pts2pb.py] processing file F-148.pts [fblocal/pts2pb.py] processing file F-149.pts [fblocal/pts2pb.py] processing file F-150.pts [fblocal/pts2pb.py] processing file F-151.pts [fblocal/pts2pb.py] processing file F-152.pts [fblocal/pts2pb.py] processing file F-153.pts [fblocal/pts2pb.py] processing file F-154.pts [fblocal/pts2pb.py] processing file F-155.pts [fblocal/pts2pb.py] processing file F-156.pts [fblocal/pts2pb.py] processing file F-157.pts [fblocal/pts2pb.py] processing file F-158.pts [fblocal/pts2pb.py] processing file F-159.pts [fblocal/pts2pb.py] processing file F-160.pts [fblocal/pts2pb.py] processing file F-161.pts [fblocal/pts2pb.py] processing file F-162.pts [fblocal/pts2pb.py] processing file F-163.pts [fblocal/pts2pb.py] processing file F-164.pts [fblocal/pts2pb.py] processing file F-165.pts [fblocal/pts2pb.py] processing file F-166.pts [fblocal/pts2pb.py] processing file F-167.pts [fblocal/pts2pb.py] processing file F-168.pts [fblocal/pts2pb.py] processing file F-169.pts [fblocal/pts2pb.py] processing file F-170.pts [fblocal/pts2pb.py] processing file F-171.pts [fblocal/pts2pb.py] processing file F-172.pts [fblocal/pts2pb.py] processing file F-173.pts [fblocal/pts2pb.py] processing file F-174.pts [fblocal/pts2pb.py] processing file F-175.pts [fblocal/pts2pb.py] processing file F-176.pts [fblocal/pts2pb.py] processing file F-177.pts [fblocal/pts2pb.py] processing file F-178.pts [fblocal/pts2pb.py] processing file F-179.pts [fblocal/pts2pb.py] processing file F-180.pts [fblocal/pts2pb.py] processing file F-181.pts [fblocal/pts2pb.py] processing file F-182.pts [fblocal/pts2pb.py] processing file F-183.pts [fblocal/pts2pb.py] processing file F-184.pts [fblocal/pts2pb.py] processing file F-185.pts [fblocal/pts2pb.py] processing file F-186.pts [fblocal/pts2pb.py] processing file F-187.pts [fblocal/pts2pb.py] processing file F-188.pts [fblocal/pts2pb.py] processing file F-189.pts [fblocal/pts2pb.py] processing file F-190.pts [fblocal/pts2pb.py] processing file F-191.pts [fblocal/pts2pb.py] processing file F-192.pts [fblocal/pts2pb.py] processing file F-193.pts [fblocal/pts2pb.py] processing file F-194.pts [fblocal/pts2pb.py] processing file F-195.pts [fblocal/pts2pb.py] processing file F-196.pts [fblocal/pts2pb.py] processing file F-197.pts [fblocal/pts2pb.py] processing file F-198.pts [fblocal/pts2pb.py] processing file F-199.pts [fblocal/pts2pb.py] processing file F-200.pts ok	output written to alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	19.475	15.000	18.473 | 34.76%	71.50%	93.61%	99.36%	
ali_f                         	19.777	15.000	18.568 | 33.33%	71.70%	93.24%	99.40%	
--------------------------------------------------------------------------------------
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 46.6165413534% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 64.6616541353% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected
ali-to-phones --ctm-output exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/final.mdl 'ark:gunzip -c alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/ali.1.gz|' - 
LOG (ali-to-phones[5.5.0~1-5caf]:main():ali-to-phones.cc:134) Done 199 utterances.
ali-to-phones --ctm-output exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp/final.mdl 'ark:gunzip -c alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/ali.2.gz|' - 
LOG (ali-to-phones[5.5.0~1-5caf]:main():ali-to-phones.cc:134) Done 200 utterances.
fblocal/ali2ctm2pts.sh: extracting F-001.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-002.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-003.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-004.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-005.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-006.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-007.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-008.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-009.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-010.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-011.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-012.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-013.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-014.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-015.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-016.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-017.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-018.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-019.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-020.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-021.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-022.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-023.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-024.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-025.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-026.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-027.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-028.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-029.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-030.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-031.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-032.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-033.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-034.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-035.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-036.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-037.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-038.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-039.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-040.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-041.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-042.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-043.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-044.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-045.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-046.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-047.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-048.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-049.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-050.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-051.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-052.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-053.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-054.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-055.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-056.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-057.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-058.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-059.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-060.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-061.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-062.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-063.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-064.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-065.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-066.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-067.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-068.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-069.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-070.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-071.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-072.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-073.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-074.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-075.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-076.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-077.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-078.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-079.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-080.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-081.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-082.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-083.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-084.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-085.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-086.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-087.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-088.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-089.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-090.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-091.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-092.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-093.ctm from phoneids.ctmsteps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali
fblocal/ali2ctm2pts.sh: extracting F-094.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-095.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-096.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-097.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-098.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-099.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-100.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-101.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-102.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-103.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-104.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-105.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-106.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-107.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-108.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-109.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-110.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-111.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-112.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-113.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-114.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-115.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-116.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-117.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-118.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-119.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-120.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-121.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-122.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-123.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-124.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-125.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-126.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-127.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-128.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-129.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-130.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-131.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-132.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-133.ctm from phoneids.ctmanalyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 34.5864661654% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 79.4486215539% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: extracting F-134.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: chain selected
fblocal/ali2ctm2pts.sh: extracting F-135.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-136.ctm from phoneids.ctmali-to-phones --ctm-output exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/final.mdl 'ark:gunzip -c alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/ali.1.gz|' - 
fblocal/ali2ctm2pts.sh: extracting F-137.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-138.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-139.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-140.ctm from phoneids.ctmLOG (ali-to-phones[5.5.0~1-5caf]:main():ali-to-phones.cc:134) Done 199 utterances.
fblocal/ali2ctm2pts.sh: extracting F-141.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-142.ctm from phoneids.ctmali-to-phones --ctm-output exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp/final.mdl 'ark:gunzip -c alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/ali.2.gz|' - 
fblocal/ali2ctm2pts.sh: extracting F-143.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-144.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-145.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-146.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-147.ctm from phoneids.ctmLOG (ali-to-phones[5.5.0~1-5caf]:main():ali-to-phones.cc:134) Done 200 utterances.
fblocal/ali2ctm2pts.sh: extracting F-148.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-149.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-001.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-150.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-002.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-151.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-003.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-152.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-004.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-153.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-005.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-154.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-006.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-155.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-007.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-156.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-008.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-157.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-009.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-158.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-010.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-159.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-011.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-160.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-012.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-161.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-013.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-162.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-014.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-163.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-015.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-164.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-016.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-165.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-017.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-166.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-018.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-167.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-019.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-168.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-020.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-169.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-021.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-170.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-022.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-171.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-023.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-172.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-024.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-173.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-025.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-175.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-026.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-176.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-027.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-177.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-028.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-178.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-029.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-179.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-030.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-180.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-031.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-181.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-032.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-182.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-033.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-183.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-034.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-184.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-035.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-185.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-036.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-186.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-037.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-187.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-038.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-188.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-039.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-189.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-040.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-190.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-041.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-191.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-042.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-192.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-043.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-193.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-044.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-194.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-045.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-195.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-046.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-196.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-047.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-197.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-048.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-198.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-049.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-199.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-050.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-200.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-051.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-001.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-052.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-002.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-053.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-003.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-054.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-004.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-055.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-005.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-056.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-006.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-057.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-007.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-058.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-008.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-059.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-009.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-060.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-010.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-061.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-011.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-062.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-012.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-063.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-013.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-064.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-014.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-065.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-015.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-066.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-016.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-067.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-017.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-068.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-018.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-069.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-019.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-070.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-020.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-071.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-021.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-072.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-073.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-022.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-074.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-023.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-075.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-024.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-076.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-025.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-077.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-026.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-078.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-027.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-079.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-028.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-080.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-029.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-081.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-030.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-082.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-031.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-083.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-032.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-084.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-033.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-085.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-034.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-086.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-035.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-087.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-036.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-088.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-037.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-089.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-038.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-090.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-039.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-091.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-040.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-092.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-041.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-093.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-042.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-094.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-043.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-095.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-044.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-096.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-045.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-097.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-046.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-098.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-047.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-099.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-048.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-100.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-049.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-101.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-050.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-102.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-051.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-103.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-052.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-104.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-053.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-105.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-054.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-106.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-055.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-107.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-056.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-108.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-057.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-109.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-058.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-110.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-059.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-111.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-060.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-112.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-061.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-113.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-062.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-114.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-063.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-115.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-064.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-116.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-065.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-117.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-066.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-118.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-067.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-119.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-068.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-120.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-069.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-121.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-070.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-122.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-071.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-123.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-072.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-124.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-073.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-125.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-074.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-126.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-075.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-127.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-076.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-128.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-077.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-129.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-078.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-130.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-079.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-131.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-080.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-132.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-081.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-133.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-082.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-134.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-083.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-135.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-084.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-136.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-085.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-137.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-086.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-138.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-087.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-139.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-088.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-140.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-089.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-141.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-090.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-142.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-091.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-143.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-092.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-144.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-093.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-145.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-094.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-146.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-095.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-147.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-096.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-148.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-097.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-149.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-098.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-150.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-099.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-151.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-100.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-152.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-101.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-153.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-102.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-154.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-103.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-155.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-104.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-156.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-105.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-157.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-106.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-158.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-107.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-159.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-108.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-160.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-109.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-161.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-110.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-162.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-111.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-163.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-112.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-164.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-113.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-165.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-114.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-166.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-115.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-167.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-116.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-168.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-117.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-169.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-118.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-170.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-119.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-171.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-120.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-172.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-121.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-173.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-122.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-175.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-123.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-176.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-124.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-177.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-125.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-178.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-126.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-179.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-127.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-180.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-128.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-181.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-129.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-182.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-130.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-183.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-131.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-184.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-132.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-185.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-133.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-186.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-134.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-187.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-135.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-188.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-136.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-189.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-137.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-190.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-138.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-191.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-139.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-192.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-140.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-193.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-141.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-194.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-142.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-195.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-143.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-196.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-144.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-197.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-145.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-198.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-146.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-199.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-147.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting F-200.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-148.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-001.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-149.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-002.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-150.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-003.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-151.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-004.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-152.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-005.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-153.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-006.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-154.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-007.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-155.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-008.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-156.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-009.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-157.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-010.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-158.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-011.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-159.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-012.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-160.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-013.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-161.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-014.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-162.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-015.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-163.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-016.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-164.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-017.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-165.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-018.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-166.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-019.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-167.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-020.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-168.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-021.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-169.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-022.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-170.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-023.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-171.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-024.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-172.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-025.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-173.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-026.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-174.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-027.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-175.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-028.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-176.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-029.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-177.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-030.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-178.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-031.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-179.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-032.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-180.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-033.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-181.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-034.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-182.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-035.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-183.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-036.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-184.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-037.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-185.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-038.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-186.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-039.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-187.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-040.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-188.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-041.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-189.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-042.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-190.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-043.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-191.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-044.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-192.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-045.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-193.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-046.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-194.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-047.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-195.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-048.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-196.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-049.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-197.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-050.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-198.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-051.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-199.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-052.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-200.ctm from phoneids.ctm
steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali ctm_tmp
fblocal/ali2ctm2pts.sh: extracting M-053.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-054.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-055.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-056.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-057.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-058.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-059.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-060.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-061.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-062.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-063.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-064.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-065.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-066.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-067.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-068.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-069.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-070.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-071.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-072.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-073.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-074.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-075.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-076.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-077.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-078.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-079.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-080.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-081.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-082.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-083.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-084.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-085.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-086.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-087.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-088.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-089.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-090.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-091.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-092.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-093.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-094.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-095.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-096.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-097.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-098.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-099.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-100.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-101.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-102.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-103.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-104.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-105.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-106.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-107.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-108.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-109.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-110.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-111.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-112.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-113.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-114.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-115.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-116.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-117.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-118.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-119.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-120.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-121.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-122.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-123.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-124.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-125.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-126.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-127.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-128.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-129.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-130.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-131.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-132.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-133.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-134.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-135.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-136.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-137.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-138.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-139.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-140.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-141.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-142.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-143.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-144.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-145.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-146.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-147.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-148.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-001.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-002.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-003.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-004.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-005.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-006.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-007.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-008.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-009.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-010.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-011.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-012.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-013.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-014.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-015.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-016.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-017.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-018.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-019.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-020.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-021.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-022.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-023.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-024.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-025.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-026.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-027.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-028.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-029.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-030.ctm fblocal/ali2ctm2pts.sh: extracting M-149.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-031.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-032.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-033.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-034.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-035.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-036.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-037.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-038.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-039.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-040.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-041.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-042.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-043.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-044.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-045.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-046.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-047.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-048.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-049.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-050.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-051.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-052.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-053.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-054.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-055.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-056.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-057.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-058.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-059.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-060.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-061.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-062.ctm fblocal/ali2ctm2pts.sh: extracting M-150.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-063.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-064.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-065.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-066.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-067.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-068.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-069.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-070.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-071.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-072.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-073.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-074.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-075.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-076.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-077.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-078.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-079.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-080.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-081.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-082.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-083.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-084.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-085.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-086.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-087.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-088.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-089.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-090.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-091.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-092.ctm fblocal/ali2ctm2pts.sh: extracting M-151.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-093.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-094.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-095.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-096.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-097.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-098.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-099.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-100.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-101.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-102.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-103.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-104.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-105.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-106.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-107.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-108.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-109.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-110.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-111.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-112.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-113.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-114.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-115.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-116.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-117.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-118.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-119.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-120.ctm fblocal/ali2ctm2pts.sh: extracting M-152.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-121.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-122.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-123.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-124.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-125.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-126.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-127.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-128.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-129.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-130.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-131.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-132.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-133.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-134.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-135.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-136.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-137.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-138.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-139.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-140.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-141.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-142.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-143.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-144.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-145.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-146.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-147.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-148.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-149.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-150.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-151.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-152.ctm fblocal/ali2ctm2pts.sh: extracting M-153.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-153.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-154.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-155.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-156.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-157.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-158.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-159.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-160.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-161.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-162.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-163.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-164.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-165.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-166.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-167.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-168.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-169.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-170.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-171.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-172.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-173.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-175.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-176.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-177.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-178.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-179.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-180.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-181.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-182.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-183.ctm fblocal/ali2ctm2pts.sh: extracting M-154.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-184.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-185.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-186.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-187.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-188.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-189.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-190.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-191.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-192.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-193.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-194.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-195.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-196.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-197.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-198.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-199.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/F-200.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-001.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-002.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-003.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-004.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-005.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-006.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-007.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-008.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-009.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-010.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-011.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-012.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-013.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-014.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-015.ctm fblocal/ali2ctm2pts.sh: extracting M-155.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-016.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-017.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-018.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-019.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-020.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-021.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-022.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-023.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-024.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-025.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-026.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-027.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-028.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-029.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-030.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-031.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-032.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-033.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-034.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-035.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-036.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-037.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-038.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-039.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-040.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-041.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-042.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-043.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-044.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-045.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-046.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-047.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-048.ctm fblocal/ali2ctm2pts.sh: extracting M-156.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-049.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-050.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-051.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-052.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-053.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-054.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-055.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-056.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-057.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-058.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-059.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-060.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-061.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-062.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-063.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-064.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-065.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-066.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-067.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-068.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-069.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-070.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-071.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-072.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-073.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-074.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-075.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-076.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-077.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-078.ctm fblocal/ali2ctm2pts.sh: extracting M-157.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-079.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-080.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-081.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-082.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-083.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-084.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-085.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-086.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-087.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-088.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-089.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-090.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-091.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-092.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-093.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-094.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-095.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-096.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-097.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-098.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-099.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-100.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-101.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-102.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-103.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-104.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-105.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-106.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-107.ctm fblocal/ali2ctm2pts.sh: extracting M-158.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-108.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-109.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-110.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-111.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-112.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-113.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-114.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-115.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-116.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-117.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-118.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-119.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-120.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-121.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-122.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-123.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-124.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-125.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-126.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-127.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-128.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-129.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-130.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-131.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-132.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-133.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-134.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-135.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-136.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-137.ctm fblocal/ali2ctm2pts.sh: extracting M-159.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-138.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-139.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-140.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-141.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-142.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-143.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-144.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-145.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-146.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-147.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-148.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-149.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-150.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-151.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-152.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-153.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-154.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-155.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-156.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-157.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-158.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-159.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-160.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-161.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-162.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-163.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-164.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-165.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-166.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-167.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-168.ctm fblocal/ali2ctm2pts.sh: extracting M-160.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-169.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-170.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-171.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-172.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-173.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-174.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-175.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-176.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-177.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-178.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-179.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-180.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-181.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-182.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-183.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-184.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-185.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-186.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-187.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-188.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-189.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-190.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-191.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-192.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-193.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-194.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-195.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-196.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-197.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-198.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-199.ctm fblocal/ali2ctm2pts.sh: extracting M-161.ctm from phoneids.ctm[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/M-200.ctm [fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
fblocal/ali2ctm2pts.sh: extracting M-162.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-163.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-164.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-165.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-166.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-167.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-168.ctm from phoneids.ctm[fblocal/pts2pb.py] processing file M-001.pts [fblocal/pts2pb.py] processing file M-002.pts [fblocal/pts2pb.py] processing file M-003.pts [fblocal/pts2pb.py] processing file M-004.pts [fblocal/pts2pb.py] processing file M-005.pts [fblocal/pts2pb.py] processing file M-006.pts [fblocal/pts2pb.py] processing file M-007.pts [fblocal/pts2pb.py] processing file M-008.pts [fblocal/pts2pb.py] processing file M-009.pts [fblocal/pts2pb.py] processing file M-010.pts [fblocal/pts2pb.py] processing file M-011.pts [fblocal/pts2pb.py] processing file M-012.pts [fblocal/pts2pb.py] processing file M-013.pts [fblocal/pts2pb.py] processing file M-014.pts [fblocal/pts2pb.py] processing file M-015.pts [fblocal/pts2pb.py] processing file M-016.pts [fblocal/pts2pb.py] processing file M-017.pts [fblocal/pts2pb.py] processing file M-018.pts [fblocal/pts2pb.py] processing file M-019.pts [fblocal/pts2pb.py] processing file M-020.pts [fblocal/pts2pb.py] processing file M-021.pts [fblocal/pts2pb.py] processing file M-022.pts [fblocal/pts2pb.py] processing file M-023.pts [fblocal/pts2pb.py] processing file M-024.pts [fblocal/pts2pb.py] processing file M-025.pts [fblocal/pts2pb.py] processing file M-026.pts [fblocal/pts2pb.py] processing file M-027.pts [fblocal/pts2pb.py] processing file M-028.pts [fblocal/pts2pb.py] processing file M-029.pts [fblocal/pts2pb.py] processing file M-030.pts [fblocal/pts2pb.py] processing file M-031.pts [fblocal/pts2pb.py] processing file M-032.pts [fblocal/pts2pb.py] processing file M-033.pts [fblocal/pts2pb.py] processing file M-034.pts [fblocal/pts2pb.py] processing file M-035.pts [fblocal/pts2pb.py] processing file M-036.pts [fblocal/pts2pb.py] processing file M-037.pts [fblocal/pts2pb.py] processing file M-038.pts [fblocal/pts2pb.py] processing file M-039.pts [fblocal/pts2pb.py] processing file M-040.pts [fblocal/pts2pb.py] processing file M-041.pts [fblocal/pts2pb.py] processing file M-042.pts [fblocal/pts2pb.py] processing file M-043.pts [fblocal/pts2pb.py] processing file M-044.pts [fblocal/pts2pb.py] processing file M-045.pts [fblocal/pts2pb.py] processing file M-046.pts [fblocal/pts2pb.py] processing file M-047.pts [fblocal/pts2pb.py] processing file M-048.pts [fblocal/pts2pb.py] processing file M-049.pts [fblocal/pts2pb.py] processing file M-050.pts [fblocal/pts2pb.py] processing file M-051.pts [fblocal/pts2pb.py] processing file M-052.pts [fblocal/pts2pb.py] processing file M-053.pts [fblocal/pts2pb.py] processing file M-054.pts [fblocal/pts2pb.py] processing file M-055.pts [fblocal/pts2pb.py] processing file M-056.pts [fblocal/pts2pb.py] processing file M-057.pts [fblocal/pts2pb.py] processing file M-058.pts [fblocal/pts2pb.py] processing file M-059.pts [fblocal/pts2pb.py] processing file M-060.pts [fblocal/pts2pb.py] processing file M-061.pts [fblocal/pts2pb.py] processing file M-062.pts [fblocal/pts2pb.py] processing file M-063.pts [fblocal/pts2pb.py] processing file M-064.pts [fblocal/pts2pb.py] processing file M-065.pts [fblocal/pts2pb.py] processing file M-066.pts [fblocal/pts2pb.py] processing file M-067.pts [fblocal/pts2pb.py] processing file M-068.pts [fblocal/pts2pb.py] processing file M-069.pts [fblocal/pts2pb.py] processing file M-070.pts [fblocal/pts2pb.py] processing file M-071.pts [fblocal/pts2pb.py] processing file M-072.pts [fblocal/pts2pb.py] processing file M-073.pts [fblocal/pts2pb.py] processing file M-074.pts [fblocal/pts2pb.py] processing file M-075.pts [fblocal/pts2pb.py] processing file M-076.pts [fblocal/pts2pb.py] processing file M-077.pts [fblocal/pts2pb.py] processing file M-078.pts [fblocal/pts2pb.py] processing file M-079.pts [fblocal/pts2pb.py] processing file M-080.pts [fblocal/pts2pb.py] processing file M-081.pts [fblocal/pts2pb.py] processing file M-082.pts [fblocal/pts2pb.py] processing file M-083.pts [fblocal/pts2pb.py] processing file M-084.pts [fblocal/pts2pb.py] processing file M-085.pts [fblocal/pts2pb.py] processing file M-086.pts [fblocal/pts2pb.py] processing file M-087.pts [fblocal/pts2pb.py] processing file M-088.pts [fblocal/pts2pb.py] processing file M-089.pts [fblocal/pts2pb.py] processing file M-090.pts [fblocal/pts2pb.py] processing file M-091.pts [fblocal/pts2pb.py] processing file M-092.pts [fblocal/pts2pb.py] processing file M-093.pts [fblocal/pts2pb.py] processing file M-094.pts [fblocal/pts2pb.py] processing file M-095.pts [fblocal/pts2pb.py] processing file M-096.pts [fblocal/pts2pb.py] processing file M-097.pts [fblocal/pts2pb.py] processing file M-098.pts [fblocal/pts2pb.py] processing file M-099.pts [fblocal/pts2pb.py] processing file M-100.pts [fblocal/pts2pb.py] processing file M-101.pts [fblocal/pts2pb.py] processing file M-102.pts [fblocal/pts2pb.py] processing file M-103.pts [fblocal/pts2pb.py] processing file M-104.pts [fblocal/pts2pb.py] processing file M-105.pts [fblocal/pts2pb.py] processing file M-106.pts [fblocal/pts2pb.py] processing file M-107.pts [fblocal/pts2pb.py] processing file M-108.pts [fblocal/pts2pb.py] processing file M-109.pts [fblocal/pts2pb.py] processing file M-110.pts [fblocal/pts2pb.py] processing file M-111.pts [fblocal/pts2pb.py] processing file M-112.pts [fblocal/pts2pb.py] processing file M-113.pts [fblocal/pts2pb.py] processing file M-114.pts [fblocal/pts2pb.py] processing file M-115.pts [fblocal/pts2pb.py] processing file M-116.pts [fblocal/pts2pb.py] processing file M-117.pts [fblocal/pts2pb.py] processing file M-118.pts [fblocal/pts2pb.py] processing file M-119.pts [fblocal/pts2pb.py] processing file M-120.pts [fblocal/pts2pb.py] processing file M-121.pts [fblocal/pts2pb.py] processing file M-122.pts [fblocal/pts2pb.py] processing file M-123.pts [fblocal/pts2pb.py] processing file M-124.pts [fblocal/pts2pb.py] processing file M-125.pts [fblocal/pts2pb.py] processing file M-126.pts [fblocal/pts2pb.py] processing file M-127.pts [fblocal/pts2pb.py] processing file M-128.pts [fblocal/pts2pb.py] processing file M-129.pts [fblocal/pts2pb.py] processing file M-130.pts [fblocal/pts2pb.py] processing file M-131.pts [fblocal/pts2pb.py] processing file M-132.pts [fblocal/pts2pb.py] processing file M-133.pts [fblocal/pts2pb.py] processing file M-134.pts [fblocal/pts2pb.py] processing file M-135.pts [fblocal/pts2pb.py] processing file M-136.pts [fblocal/pts2pb.py] processing file M-137.pts [fblocal/pts2pb.py] processing file M-138.pts [fblocal/pts2pb.py] processing file M-139.pts [fblocal/pts2pb.py] processing file M-140.pts [fblocal/pts2pb.py] processing file M-141.pts [fblocal/pts2pb.py] processing file M-142.pts [fblocal/pts2pb.py] processing file M-143.pts [fblocal/pts2pb.py] processing file M-144.pts [fblocal/pts2pb.py] processing file M-145.pts [fblocal/pts2pb.py] processing file M-146.pts [fblocal/pts2pb.py] processing file M-147.pts [fblocal/pts2pb.py] processing file M-148.pts [fblocal/pts2pb.py] processing file M-149.pts [fblocal/pts2pb.py] processing file M-150.pts [fblocal/pts2pb.py] processing file M-151.pts [fblocal/pts2pb.py] processing file M-152.pts [fblocal/pts2pb.py] processing file M-153.pts [fblocal/pts2pb.py] processing file M-154.pts [fblocal/pts2pb.py] processing file M-155.pts [fblocal/pts2pb.py] processing file M-156.pts [fblocal/pts2pb.py] processing file M-157.pts [fblocal/pts2pb.py] processing file M-158.pts [fblocal/pts2pb.py] processing file M-159.pts [fblocal/pts2pb.py] processing file M-160.pts [fblocal/pts2pb.py] processing file M-161.pts [fblocal/pts2pb.py] processing file M-162.pts [fblocal/pts2pb.py] processing file M-163.pts [fblocal/pts2pb.py] processing file M-164.pts [fblocal/pts2pb.py] processing file M-165.pts [fblocal/pts2pb.py] processing file M-166.pts [fblocal/pts2pb.py] processing file M-167.pts [fblocal/pts2pb.py] processing file M-168.pts [fblocal/pts2pb.py] processing file M-169.pts [fblocal/pts2pb.py] processing file M-170.pts [fblocal/pts2pb.py] processing file M-171.pts [fblocal/pts2pb.py] processing file M-172.pts [fblocal/pts2pb.py] processing file M-173.pts [fblocal/pts2pb.py] processing file M-174.pts [fblocal/pts2pb.py] processing file M-175.pts [fblocal/pts2pb.py] processing file M-176.pts [fblocal/pts2pb.py] processing file M-177.pts [fblocal/pts2pb.py] processing file M-178.pts [fblocal/pts2pb.py] processing file M-179.pts [fblocal/pts2pb.py] processing file M-180.pts [fblocal/pts2pb.py] processing file M-181.pts [fblocal/pts2pb.py] processing file M-182.pts [fblocal/pts2pb.py] processing file M-183.pts [fblocal/pts2pb.py] processing file M-184.pts [fblocal/pts2pb.py] processing file M-185.pts [fblocal/pts2pb.py] processing file M-186.pts [fblocal/pts2pb.py] processing file M-187.pts [fblocal/pts2pb.py] processing file M-188.pts [fblocal/pts2pb.py] processing file M-189.pts [fblocal/pts2pb.py] processing file M-190.pts [fblocal/pts2pb.py] processing file M-191.pts [fblocal/pts2pb.py] processing file M-192.pts [fblocal/pts2pb.py] processing file M-193.pts [fblocal/pts2pb.py] processing file M-194.pts [fblocal/pts2pb.py] processing file M-195.pts [fblocal/pts2pb.py] processing file M-196.pts [fblocal/pts2pb.py] processing file M-197.pts [fblocal/pts2pb.py] processing file M-198.pts [fblocal/pts2pb.py] processing file M-199.pts [fblocal/pts2pb.py] processing file M-200.pts fblocal/ali2ctm2pts.sh: extracting M-169.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-170.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-171.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-172.ctm from phoneids.ctmok	output written to alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/ali_m.pb
fblocal/ali2ctm2pts.sh: extracting M-173.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-174.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-175.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-176.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-177.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-178.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-179.ctm from phoneids.ctm[fblocal/pts2pb.py] processing file F-001.pts [fblocal/pts2pb.py] processing file F-002.pts [fblocal/pts2pb.py] processing file F-003.pts [fblocal/pts2pb.py] processing file F-004.pts [fblocal/pts2pb.py] processing file F-005.pts [fblocal/pts2pb.py] processing file F-006.pts [fblocal/pts2pb.py] processing file F-007.pts [fblocal/pts2pb.py] processing file F-008.pts [fblocal/pts2pb.py] processing file F-009.pts [fblocal/pts2pb.py] processing file F-010.pts [fblocal/pts2pb.py] processing file F-011.pts [fblocal/pts2pb.py] processing file F-012.pts [fblocal/pts2pb.py] processing file F-013.pts [fblocal/pts2pb.py] processing file F-014.pts [fblocal/pts2pb.py] processing file F-015.pts [fblocal/pts2pb.py] processing file F-016.pts [fblocal/pts2pb.py] processing file F-017.pts [fblocal/pts2pb.py] processing file F-018.pts [fblocal/pts2pb.py] processing file F-019.pts [fblocal/pts2pb.py] processing file F-020.pts [fblocal/pts2pb.py] processing file F-021.pts [fblocal/pts2pb.py] processing file F-022.pts [fblocal/pts2pb.py] processing file F-023.pts [fblocal/pts2pb.py] processing file F-024.pts [fblocal/pts2pb.py] processing file F-025.pts [fblocal/pts2pb.py] processing file F-026.pts [fblocal/pts2pb.py] processing file F-027.pts [fblocal/pts2pb.py] processing file F-028.pts [fblocal/pts2pb.py] processing file F-029.pts [fblocal/pts2pb.py] processing file F-030.pts [fblocal/pts2pb.py] processing file F-031.pts [fblocal/pts2pb.py] processing file F-032.pts [fblocal/pts2pb.py] processing file F-033.pts [fblocal/pts2pb.py] processing file F-034.pts [fblocal/pts2pb.py] processing file F-035.pts [fblocal/pts2pb.py] processing file F-036.pts [fblocal/pts2pb.py] processing file F-037.pts [fblocal/pts2pb.py] processing file F-038.pts [fblocal/pts2pb.py] processing file F-039.pts [fblocal/pts2pb.py] processing file F-040.pts [fblocal/pts2pb.py] processing file F-041.pts [fblocal/pts2pb.py] processing file F-042.pts [fblocal/pts2pb.py] processing file F-043.pts [fblocal/pts2pb.py] processing file F-044.pts [fblocal/pts2pb.py] processing file F-045.pts [fblocal/pts2pb.py] processing file F-046.pts [fblocal/pts2pb.py] processing file F-047.pts [fblocal/pts2pb.py] processing file F-048.pts [fblocal/pts2pb.py] processing file F-049.pts [fblocal/pts2pb.py] processing file F-050.pts [fblocal/pts2pb.py] processing file F-051.pts [fblocal/pts2pb.py] processing file F-052.pts [fblocal/pts2pb.py] processing file F-053.pts [fblocal/pts2pb.py] processing file F-054.pts [fblocal/pts2pb.py] processing file F-055.pts [fblocal/pts2pb.py] processing file F-056.pts [fblocal/pts2pb.py] processing file F-057.pts [fblocal/pts2pb.py] processing file F-058.pts [fblocal/pts2pb.py] processing file F-059.pts [fblocal/pts2pb.py] processing file F-060.pts [fblocal/pts2pb.py] processing file F-061.pts [fblocal/pts2pb.py] processing file F-062.pts [fblocal/pts2pb.py] processing file F-063.pts [fblocal/pts2pb.py] processing file F-064.pts [fblocal/pts2pb.py] processing file F-065.pts [fblocal/pts2pb.py] processing file F-066.pts [fblocal/pts2pb.py] processing file F-067.pts [fblocal/pts2pb.py] processing file F-068.pts [fblocal/pts2pb.py] processing file F-069.pts [fblocal/pts2pb.py] processing file F-070.pts [fblocal/pts2pb.py] processing file F-071.pts [fblocal/pts2pb.py] processing file F-072.pts [fblocal/pts2pb.py] processing file F-073.pts [fblocal/pts2pb.py] processing file F-074.pts [fblocal/pts2pb.py] processing file F-075.pts [fblocal/pts2pb.py] processing file F-076.pts [fblocal/pts2pb.py] processing file F-077.pts [fblocal/pts2pb.py] processing file F-078.pts [fblocal/pts2pb.py] processing file F-079.pts [fblocal/pts2pb.py] processing file F-080.pts [fblocal/pts2pb.py] processing file F-081.pts [fblocal/pts2pb.py] processing file F-082.pts [fblocal/pts2pb.py] processing file F-083.pts [fblocal/pts2pb.py] processing file F-084.pts [fblocal/pts2pb.py] processing file F-085.pts [fblocal/pts2pb.py] processing file F-086.pts [fblocal/pts2pb.py] processing file F-087.pts [fblocal/pts2pb.py] processing file F-088.pts [fblocal/pts2pb.py] processing file F-089.pts [fblocal/pts2pb.py] processing file F-090.pts [fblocal/pts2pb.py] processing file F-091.pts [fblocal/pts2pb.py] processing file F-092.pts [fblocal/pts2pb.py] processing file F-093.pts [fblocal/pts2pb.py] processing file F-094.pts [fblocal/pts2pb.py] processing file F-095.pts [fblocal/pts2pb.py] processing file F-096.pts [fblocal/pts2pb.py] processing file F-097.pts [fblocal/pts2pb.py] processing file F-098.pts [fblocal/pts2pb.py] processing file F-099.pts [fblocal/pts2pb.py] processing file F-100.pts [fblocal/pts2pb.py] processing file F-101.pts [fblocal/pts2pb.py] processing file F-102.pts [fblocal/pts2pb.py] processing file F-103.pts [fblocal/pts2pb.py] processing file F-104.pts [fblocal/pts2pb.py] processing file F-105.pts [fblocal/pts2pb.py] processing file F-106.pts [fblocal/pts2pb.py] processing file F-107.pts [fblocal/pts2pb.py] processing file F-108.pts [fblocal/pts2pb.py] processing file F-109.pts [fblocal/pts2pb.py] processing file F-110.pts [fblocal/pts2pb.py] processing file F-111.pts [fblocal/pts2pb.py] processing file F-112.pts [fblocal/pts2pb.py] processing file F-113.pts [fblocal/pts2pb.py] processing file F-114.pts [fblocal/pts2pb.py] processing file F-115.pts [fblocal/pts2pb.py] processing file F-116.pts [fblocal/pts2pb.py] processing file F-117.pts [fblocal/pts2pb.py] processing file F-118.pts [fblocal/pts2pb.py] processing file F-119.pts [fblocal/pts2pb.py] processing file F-120.pts [fblocal/pts2pb.py] processing file F-121.pts [fblocal/pts2pb.py] processing file F-122.pts [fblocal/pts2pb.py] processing file F-123.pts [fblocal/pts2pb.py] processing file F-124.pts [fblocal/pts2pb.py] processing file F-125.pts [fblocal/pts2pb.py] processing file F-126.pts [fblocal/pts2pb.py] processing file F-127.pts [fblocal/pts2pb.py] processing file F-128.pts [fblocal/pts2pb.py] processing file F-129.pts [fblocal/pts2pb.py] processing file F-130.pts [fblocal/pts2pb.py] processing file F-131.pts [fblocal/pts2pb.py] processing file F-132.pts [fblocal/pts2pb.py] processing file F-133.pts [fblocal/pts2pb.py] processing file F-134.pts [fblocal/pts2pb.py] processing file F-135.pts [fblocal/pts2pb.py] processing file F-136.pts [fblocal/pts2pb.py] processing file F-137.pts [fblocal/pts2pb.py] processing file F-138.pts [fblocal/pts2pb.py] processing file F-139.pts [fblocal/pts2pb.py] processing file F-140.pts [fblocal/pts2pb.py] processing file F-141.pts [fblocal/pts2pb.py] processing file F-142.pts [fblocal/pts2pb.py] processing file F-143.pts [fblocal/pts2pb.py] processing file F-144.pts [fblocal/pts2pb.py] processing file F-145.pts [fblocal/pts2pb.py] processing file F-146.pts [fblocal/pts2pb.py] processing file F-147.pts [fblocal/pts2pb.py] processing file F-148.pts [fblocal/pts2pb.py] processing file F-149.pts [fblocal/pts2pb.py] processing file F-150.pts [fblocal/pts2pb.py] processing file F-151.pts [fblocal/pts2pb.py] processing file F-152.pts [fblocal/pts2pb.py] processing file F-153.pts [fblocal/pts2pb.py] processing file F-154.pts [fblocal/pts2pb.py] processing file F-155.pts [fblocal/pts2pb.py] processing file F-156.pts [fblocal/pts2pb.py] processing file F-157.pts [fblocal/pts2pb.py] processing file F-158.pts [fblocal/pts2pb.py] processing file F-159.pts [fblocal/pts2pb.py] processing file F-160.pts [fblocal/pts2pb.py] processing file F-161.pts [fblocal/pts2pb.py] processing file F-162.pts [fblocal/pts2pb.py] processing file F-163.pts [fblocal/pts2pb.py] processing file F-164.pts [fblocal/pts2pb.py] processing file F-165.pts [fblocal/pts2pb.py] processing file F-166.pts [fblocal/pts2pb.py] processing file F-167.pts [fblocal/pts2pb.py] processing file F-168.pts [fblocal/pts2pb.py] processing file F-169.pts [fblocal/pts2pb.py] processing file F-170.pts [fblocal/pts2pb.py] processing file F-171.pts [fblocal/pts2pb.py] processing file F-172.pts [fblocal/pts2pb.py] processing file F-173.pts [fblocal/pts2pb.py] processing file F-174.pts [fblocal/pts2pb.py] processing file F-175.pts [fblocal/pts2pb.py] processing file F-176.pts [fblocal/pts2pb.py] processing file F-177.pts [fblocal/pts2pb.py] processing file F-178.pts [fblocal/pts2pb.py] processing file F-179.pts [fblocal/pts2pb.py] processing file F-180.pts [fblocal/pts2pb.py] processing file F-181.pts [fblocal/pts2pb.py] processing file F-182.pts [fblocal/pts2pb.py] processing file F-183.pts [fblocal/pts2pb.py] processing file F-184.pts [fblocal/pts2pb.py] processing file F-185.pts [fblocal/pts2pb.py] processing file F-186.pts [fblocal/pts2pb.py] processing file F-187.pts [fblocal/pts2pb.py] processing file F-188.pts [fblocal/pts2pb.py] processing file F-189.pts [fblocal/pts2pb.py] processing file F-190.pts [fblocal/pts2pb.py] processing file F-191.pts [fblocal/pts2pb.py] processing file F-192.pts [fblocal/pts2pb.py] processing file F-193.pts [fblocal/pts2pb.py] processing file F-194.pts [fblocal/pts2pb.py] processing file F-195.pts [fblocal/pts2pb.py] processing file F-196.pts [fblocal/pts2pb.py] processing file F-197.pts [fblocal/pts2pb.py] processing file F-198.pts [fblocal/pts2pb.py] processing file F-199.pts [fblocal/pts2pb.py] processing file F-200.pts fblocal/ali2ctm2pts.sh: extracting M-180.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-181.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-182.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-183.ctm from phoneids.ctmok	output written to alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/ali_f.pb
fblocal/ali2ctm2pts.sh: extracting M-184.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-185.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-186.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-187.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-188.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-189.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-190.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-191.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-192.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-193.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-194.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-195.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-196.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-197.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-198.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-199.ctm from phoneids.ctmfblocal/ali2ctm2pts.sh: extracting M-200.ctm from phoneids.ctm
steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali ctm_tmp
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	43.789	34.000	41.339 | 12.78%	36.03%	69.63%	92.26%	
ali_f                         	62.554	39.000	93.757 | 11.48%	32.24%	61.33%	85.40%	
--------------------------------------------------------------------------------------
[fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-001.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-002.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-003.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-004.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-005.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-006.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-007.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-008.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-009.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-010.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-011.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-012.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-013.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-014.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-015.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-016.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-017.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-018.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-019.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-020.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-021.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-022.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-023.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-024.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-025.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-026.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-027.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-028.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-029.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-030.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-031.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-032.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-033.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-034.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-035.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-036.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-037.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-038.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-039.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-040.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-041.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-042.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-043.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-044.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-045.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-046.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-047.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-048.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-049.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-050.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-051.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-052.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-053.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-054.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-055.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-056.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-057.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-058.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-059.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-060.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-061.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-062.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-063.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-064.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-065.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-066.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-067.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-068.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-069.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-070.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-071.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-072.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-073.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-074.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-075.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-076.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-077.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-078.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-079.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-080.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-081.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-082.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-083.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-084.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-085.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-086.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-087.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-088.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-089.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-090.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-091.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-092.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-093.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-094.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-095.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-096.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-097.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-098.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-099.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-100.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-101.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-102.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-103.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-104.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-105.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-106.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-107.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-108.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-109.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-110.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-111.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-112.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-113.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-114.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-115.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-116.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-117.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-118.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-119.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-120.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-121.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-122.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-123.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-124.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-125.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-126.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-127.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-128.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-129.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-130.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-131.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-132.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-133.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-134.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-135.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-136.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-137.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-138.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-139.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-140.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-141.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-142.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-143.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-144.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-145.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-146.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-147.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-148.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-149.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-150.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-151.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-152.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-153.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-154.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-155.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-156.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-157.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-158.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-159.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-160.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-161.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-162.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-163.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-164.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-165.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-166.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-167.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-168.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-169.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-170.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-171.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-172.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-173.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-175.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-176.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-177.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-178.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-179.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-180.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-181.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-182.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-183.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-184.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-185.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-186.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-187.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-188.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-189.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-190.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-191.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-192.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-193.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-194.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-195.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-196.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-197.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-198.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-199.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/F-200.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-001.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-002.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-003.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-004.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-005.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-006.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-007.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-008.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-009.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-010.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-011.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-012.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-013.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-014.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-015.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-016.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-017.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-018.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-019.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-020.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-021.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-022.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-023.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-024.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-025.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-026.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-027.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-028.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-029.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-030.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-031.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-032.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-033.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-034.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-035.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-036.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-037.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-038.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-039.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-040.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-041.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-042.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-043.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-044.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-045.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-046.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-047.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-048.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-049.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-050.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-051.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-052.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-053.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-054.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-055.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-056.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-057.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-058.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-059.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-060.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-061.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-062.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-063.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-064.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-065.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-066.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-067.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-068.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-069.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-070.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-071.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-072.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-073.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-074.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-075.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-076.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-077.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-078.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-079.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-080.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-081.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-082.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-083.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-084.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-085.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-086.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-087.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-088.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-089.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-090.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-091.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-092.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-093.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-094.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-095.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-096.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-097.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-098.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-099.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-100.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-101.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-102.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-103.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-104.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-105.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-106.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-107.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-108.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-109.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-110.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-111.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-112.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-113.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-114.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-115.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-116.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-117.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-118.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-119.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-120.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-121.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-122.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-123.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-124.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-125.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-126.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-127.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-128.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-129.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-130.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-131.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-132.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-133.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-134.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-135.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-136.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-137.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-138.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-139.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-140.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-141.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-142.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-143.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-144.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-145.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-146.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-147.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-148.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-149.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-150.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-151.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-152.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-153.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-154.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-155.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-156.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-157.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-158.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-159.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-160.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-161.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-162.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-163.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-164.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-165.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-166.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-167.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-168.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-169.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-170.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-171.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-172.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-173.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-174.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-175.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-176.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-177.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-178.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-179.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-180.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-181.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-182.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-183.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-184.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-185.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-186.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-187.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-188.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-189.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-190.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-191.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-192.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-193.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-194.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-195.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-196.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-197.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-198.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-199.ctm [fblocal/ctm2pts.py] processing file alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/M-200.ctm [fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
[fblocal/pts2pb.py] processing file M-001.pts [fblocal/pts2pb.py] processing file M-002.pts [fblocal/pts2pb.py] processing file M-003.pts [fblocal/pts2pb.py] processing file M-004.pts [fblocal/pts2pb.py] processing file M-005.pts [fblocal/pts2pb.py] processing file M-006.pts [fblocal/pts2pb.py] processing file M-007.pts [fblocal/pts2pb.py] processing file M-008.pts [fblocal/pts2pb.py] processing file M-009.pts [fblocal/pts2pb.py] processing file M-010.pts [fblocal/pts2pb.py] processing file M-011.pts [fblocal/pts2pb.py] processing file M-012.pts [fblocal/pts2pb.py] processing file M-013.pts [fblocal/pts2pb.py] processing file M-014.pts [fblocal/pts2pb.py] processing file M-015.pts [fblocal/pts2pb.py] processing file M-016.pts [fblocal/pts2pb.py] processing file M-017.pts [fblocal/pts2pb.py] processing file M-018.pts [fblocal/pts2pb.py] processing file M-019.pts [fblocal/pts2pb.py] processing file M-020.pts [fblocal/pts2pb.py] processing file M-021.pts [fblocal/pts2pb.py] processing file M-022.pts [fblocal/pts2pb.py] processing file M-023.pts [fblocal/pts2pb.py] processing file M-024.pts [fblocal/pts2pb.py] processing file M-025.pts [fblocal/pts2pb.py] processing file M-026.pts [fblocal/pts2pb.py] processing file M-027.pts [fblocal/pts2pb.py] processing file M-028.pts [fblocal/pts2pb.py] processing file M-029.pts [fblocal/pts2pb.py] processing file M-030.pts [fblocal/pts2pb.py] processing file M-031.pts [fblocal/pts2pb.py] processing file M-032.pts [fblocal/pts2pb.py] processing file M-033.pts [fblocal/pts2pb.py] processing file M-034.pts [fblocal/pts2pb.py] processing file M-035.pts [fblocal/pts2pb.py] processing file M-036.pts [fblocal/pts2pb.py] processing file M-037.pts [fblocal/pts2pb.py] processing file M-038.pts [fblocal/pts2pb.py] processing file M-039.pts [fblocal/pts2pb.py] processing file M-040.pts [fblocal/pts2pb.py] processing file M-041.pts [fblocal/pts2pb.py] processing file M-042.pts [fblocal/pts2pb.py] processing file M-043.pts [fblocal/pts2pb.py] processing file M-044.pts [fblocal/pts2pb.py] processing file M-045.pts [fblocal/pts2pb.py] processing file M-046.pts [fblocal/pts2pb.py] processing file M-047.pts [fblocal/pts2pb.py] processing file M-048.pts [fblocal/pts2pb.py] processing file M-049.pts [fblocal/pts2pb.py] processing file M-050.pts [fblocal/pts2pb.py] processing file M-051.pts [fblocal/pts2pb.py] processing file M-052.pts [fblocal/pts2pb.py] processing file M-053.pts [fblocal/pts2pb.py] processing file M-054.pts [fblocal/pts2pb.py] processing file M-055.pts [fblocal/pts2pb.py] processing file M-056.pts [fblocal/pts2pb.py] processing file M-057.pts [fblocal/pts2pb.py] processing file M-058.pts [fblocal/pts2pb.py] processing file M-059.pts [fblocal/pts2pb.py] processing file M-060.pts [fblocal/pts2pb.py] processing file M-061.pts [fblocal/pts2pb.py] processing file M-062.pts [fblocal/pts2pb.py] processing file M-063.pts [fblocal/pts2pb.py] processing file M-064.pts [fblocal/pts2pb.py] processing file M-065.pts [fblocal/pts2pb.py] processing file M-066.pts [fblocal/pts2pb.py] processing file M-067.pts [fblocal/pts2pb.py] processing file M-068.pts [fblocal/pts2pb.py] processing file M-069.pts [fblocal/pts2pb.py] processing file M-070.pts [fblocal/pts2pb.py] processing file M-071.pts [fblocal/pts2pb.py] processing file M-072.pts [fblocal/pts2pb.py] processing file M-073.pts [fblocal/pts2pb.py] processing file M-074.pts [fblocal/pts2pb.py] processing file M-075.pts [fblocal/pts2pb.py] processing file M-076.pts [fblocal/pts2pb.py] processing file M-077.pts [fblocal/pts2pb.py] processing file M-078.pts [fblocal/pts2pb.py] processing file M-079.pts [fblocal/pts2pb.py] processing file M-080.pts [fblocal/pts2pb.py] processing file M-081.pts [fblocal/pts2pb.py] processing file M-082.pts [fblocal/pts2pb.py] processing file M-083.pts [fblocal/pts2pb.py] processing file M-084.pts [fblocal/pts2pb.py] processing file M-085.pts [fblocal/pts2pb.py] processing file M-086.pts [fblocal/pts2pb.py] processing file M-087.pts [fblocal/pts2pb.py] processing file M-088.pts [fblocal/pts2pb.py] processing file M-089.pts [fblocal/pts2pb.py] processing file M-090.pts [fblocal/pts2pb.py] processing file M-091.pts [fblocal/pts2pb.py] processing file M-092.pts [fblocal/pts2pb.py] processing file M-093.pts [fblocal/pts2pb.py] processing file M-094.pts [fblocal/pts2pb.py] processing file M-095.pts [fblocal/pts2pb.py] processing file M-096.pts [fblocal/pts2pb.py] processing file M-097.pts [fblocal/pts2pb.py] processing file M-098.pts [fblocal/pts2pb.py] processing file M-099.pts [fblocal/pts2pb.py] processing file M-100.pts [fblocal/pts2pb.py] processing file M-101.pts [fblocal/pts2pb.py] processing file M-102.pts [fblocal/pts2pb.py] processing file M-103.pts [fblocal/pts2pb.py] processing file M-104.pts [fblocal/pts2pb.py] processing file M-105.pts [fblocal/pts2pb.py] processing file M-106.pts [fblocal/pts2pb.py] processing file M-107.pts [fblocal/pts2pb.py] processing file M-108.pts [fblocal/pts2pb.py] processing file M-109.pts [fblocal/pts2pb.py] processing file M-110.pts [fblocal/pts2pb.py] processing file M-111.pts [fblocal/pts2pb.py] processing file M-112.pts [fblocal/pts2pb.py] processing file M-113.pts [fblocal/pts2pb.py] processing file M-114.pts [fblocal/pts2pb.py] processing file M-115.pts [fblocal/pts2pb.py] processing file M-116.pts [fblocal/pts2pb.py] processing file M-117.pts [fblocal/pts2pb.py] processing file M-118.pts [fblocal/pts2pb.py] processing file M-119.pts [fblocal/pts2pb.py] processing file M-120.pts [fblocal/pts2pb.py] processing file M-121.pts [fblocal/pts2pb.py] processing file M-122.pts [fblocal/pts2pb.py] processing file M-123.pts [fblocal/pts2pb.py] processing file M-124.pts [fblocal/pts2pb.py] processing file M-125.pts [fblocal/pts2pb.py] processing file M-126.pts [fblocal/pts2pb.py] processing file M-127.pts [fblocal/pts2pb.py] processing file M-128.pts [fblocal/pts2pb.py] processing file M-129.pts [fblocal/pts2pb.py] processing file M-130.pts [fblocal/pts2pb.py] processing file M-131.pts [fblocal/pts2pb.py] processing file M-132.pts [fblocal/pts2pb.py] processing file M-133.pts [fblocal/pts2pb.py] processing file M-134.pts [fblocal/pts2pb.py] processing file M-135.pts [fblocal/pts2pb.py] processing file M-136.pts [fblocal/pts2pb.py] processing file M-137.pts [fblocal/pts2pb.py] processing file M-138.pts [fblocal/pts2pb.py] processing file M-139.pts [fblocal/pts2pb.py] processing file M-140.pts [fblocal/pts2pb.py] processing file M-141.pts [fblocal/pts2pb.py] processing file M-142.pts [fblocal/pts2pb.py] processing file M-143.pts [fblocal/pts2pb.py] processing file M-144.pts [fblocal/pts2pb.py] processing file M-145.pts [fblocal/pts2pb.py] processing file M-146.pts [fblocal/pts2pb.py] processing file M-147.pts [fblocal/pts2pb.py] processing file M-148.pts [fblocal/pts2pb.py] processing file M-149.pts [fblocal/pts2pb.py] processing file M-150.pts [fblocal/pts2pb.py] processing file M-151.pts [fblocal/pts2pb.py] processing file M-152.pts [fblocal/pts2pb.py] processing file M-153.pts [fblocal/pts2pb.py] processing file M-154.pts [fblocal/pts2pb.py] processing file M-155.pts [fblocal/pts2pb.py] processing file M-156.pts [fblocal/pts2pb.py] processing file M-157.pts [fblocal/pts2pb.py] processing file M-158.pts [fblocal/pts2pb.py] processing file M-159.pts [fblocal/pts2pb.py] processing file M-160.pts [fblocal/pts2pb.py] processing file M-161.pts [fblocal/pts2pb.py] processing file M-162.pts [fblocal/pts2pb.py] processing file M-163.pts [fblocal/pts2pb.py] processing file M-164.pts [fblocal/pts2pb.py] processing file M-165.pts [fblocal/pts2pb.py] processing file M-166.pts [fblocal/pts2pb.py] processing file M-167.pts [fblocal/pts2pb.py] processing file M-168.pts [fblocal/pts2pb.py] processing file M-169.pts [fblocal/pts2pb.py] processing file M-170.pts [fblocal/pts2pb.py] processing file M-171.pts [fblocal/pts2pb.py] processing file M-172.pts [fblocal/pts2pb.py] processing file M-173.pts [fblocal/pts2pb.py] processing file M-174.pts [fblocal/pts2pb.py] processing file M-175.pts [fblocal/pts2pb.py] processing file M-176.pts [fblocal/pts2pb.py] processing file M-177.pts [fblocal/pts2pb.py] processing file M-178.pts [fblocal/pts2pb.py] processing file M-179.pts [fblocal/pts2pb.py] processing file M-180.pts [fblocal/pts2pb.py] processing file M-181.pts [fblocal/pts2pb.py] processing file M-182.pts [fblocal/pts2pb.py] processing file M-183.pts [fblocal/pts2pb.py] processing file M-184.pts [fblocal/pts2pb.py] processing file M-185.pts [fblocal/pts2pb.py] processing file M-186.pts [fblocal/pts2pb.py] processing file M-187.pts [fblocal/pts2pb.py] processing file M-188.pts [fblocal/pts2pb.py] processing file M-189.pts [fblocal/pts2pb.py] processing file M-190.pts [fblocal/pts2pb.py] processing file M-191.pts [fblocal/pts2pb.py] processing file M-192.pts [fblocal/pts2pb.py] processing file M-193.pts [fblocal/pts2pb.py] processing file M-194.pts [fblocal/pts2pb.py] processing file M-195.pts [fblocal/pts2pb.py] processing file M-196.pts [fblocal/pts2pb.py] processing file M-197.pts [fblocal/pts2pb.py] processing file M-198.pts [fblocal/pts2pb.py] processing file M-199.pts [fblocal/pts2pb.py] processing file M-200.pts ok	output written to alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/ali_m.pb
[fblocal/pts2pb.py] processing file F-001.pts [fblocal/pts2pb.py] processing file F-002.pts [fblocal/pts2pb.py] processing file F-003.pts [fblocal/pts2pb.py] processing file F-004.pts [fblocal/pts2pb.py] processing file F-005.pts [fblocal/pts2pb.py] processing file F-006.pts [fblocal/pts2pb.py] processing file F-007.pts [fblocal/pts2pb.py] processing file F-008.pts [fblocal/pts2pb.py] processing file F-009.pts [fblocal/pts2pb.py] processing file F-010.pts [fblocal/pts2pb.py] processing file F-011.pts [fblocal/pts2pb.py] processing file F-012.pts [fblocal/pts2pb.py] processing file F-013.pts [fblocal/pts2pb.py] processing file F-014.pts [fblocal/pts2pb.py] processing file F-015.pts [fblocal/pts2pb.py] processing file F-016.pts [fblocal/pts2pb.py] processing file F-017.pts [fblocal/pts2pb.py] processing file F-018.pts [fblocal/pts2pb.py] processing file F-019.pts [fblocal/pts2pb.py] processing file F-020.pts [fblocal/pts2pb.py] processing file F-021.pts [fblocal/pts2pb.py] processing file F-022.pts [fblocal/pts2pb.py] processing file F-023.pts [fblocal/pts2pb.py] processing file F-024.pts [fblocal/pts2pb.py] processing file F-025.pts [fblocal/pts2pb.py] processing file F-026.pts [fblocal/pts2pb.py] processing file F-027.pts [fblocal/pts2pb.py] processing file F-028.pts [fblocal/pts2pb.py] processing file F-029.pts [fblocal/pts2pb.py] processing file F-030.pts [fblocal/pts2pb.py] processing file F-031.pts [fblocal/pts2pb.py] processing file F-032.pts [fblocal/pts2pb.py] processing file F-033.pts [fblocal/pts2pb.py] processing file F-034.pts [fblocal/pts2pb.py] processing file F-035.pts [fblocal/pts2pb.py] processing file F-036.pts [fblocal/pts2pb.py] processing file F-037.pts [fblocal/pts2pb.py] processing file F-038.pts [fblocal/pts2pb.py] processing file F-039.pts [fblocal/pts2pb.py] processing file F-040.pts [fblocal/pts2pb.py] processing file F-041.pts [fblocal/pts2pb.py] processing file F-042.pts [fblocal/pts2pb.py] processing file F-043.pts [fblocal/pts2pb.py] processing file F-044.pts [fblocal/pts2pb.py] processing file F-045.pts [fblocal/pts2pb.py] processing file F-046.pts [fblocal/pts2pb.py] processing file F-047.pts [fblocal/pts2pb.py] processing file F-048.pts [fblocal/pts2pb.py] processing file F-049.pts [fblocal/pts2pb.py] processing file F-050.pts [fblocal/pts2pb.py] processing file F-051.pts [fblocal/pts2pb.py] processing file F-052.pts [fblocal/pts2pb.py] processing file F-053.pts [fblocal/pts2pb.py] processing file F-054.pts [fblocal/pts2pb.py] processing file F-055.pts [fblocal/pts2pb.py] processing file F-056.pts [fblocal/pts2pb.py] processing file F-057.pts [fblocal/pts2pb.py] processing file F-058.pts [fblocal/pts2pb.py] processing file F-059.pts [fblocal/pts2pb.py] processing file F-060.pts [fblocal/pts2pb.py] processing file F-061.pts [fblocal/pts2pb.py] processing file F-062.pts [fblocal/pts2pb.py] processing file F-063.pts [fblocal/pts2pb.py] processing file F-064.pts [fblocal/pts2pb.py] processing file F-065.pts [fblocal/pts2pb.py] processing file F-066.pts [fblocal/pts2pb.py] processing file F-067.pts [fblocal/pts2pb.py] processing file F-068.pts [fblocal/pts2pb.py] processing file F-069.pts [fblocal/pts2pb.py] processing file F-070.pts [fblocal/pts2pb.py] processing file F-071.pts [fblocal/pts2pb.py] processing file F-072.pts [fblocal/pts2pb.py] processing file F-073.pts [fblocal/pts2pb.py] processing file F-074.pts [fblocal/pts2pb.py] processing file F-075.pts [fblocal/pts2pb.py] processing file F-076.pts [fblocal/pts2pb.py] processing file F-077.pts [fblocal/pts2pb.py] processing file F-078.pts [fblocal/pts2pb.py] processing file F-079.pts [fblocal/pts2pb.py] processing file F-080.pts [fblocal/pts2pb.py] processing file F-081.pts [fblocal/pts2pb.py] processing file F-082.pts [fblocal/pts2pb.py] processing file F-083.pts [fblocal/pts2pb.py] processing file F-084.pts [fblocal/pts2pb.py] processing file F-085.pts [fblocal/pts2pb.py] processing file F-086.pts [fblocal/pts2pb.py] processing file F-087.pts [fblocal/pts2pb.py] processing file F-088.pts [fblocal/pts2pb.py] processing file F-089.pts [fblocal/pts2pb.py] processing file F-090.pts [fblocal/pts2pb.py] processing file F-091.pts [fblocal/pts2pb.py] processing file F-092.pts [fblocal/pts2pb.py] processing file F-093.pts [fblocal/pts2pb.py] processing file F-094.pts [fblocal/pts2pb.py] processing file F-095.pts [fblocal/pts2pb.py] processing file F-096.pts [fblocal/pts2pb.py] processing file F-097.pts [fblocal/pts2pb.py] processing file F-098.pts [fblocal/pts2pb.py] processing file F-099.pts [fblocal/pts2pb.py] processing file F-100.pts [fblocal/pts2pb.py] processing file F-101.pts [fblocal/pts2pb.py] processing file F-102.pts [fblocal/pts2pb.py] processing file F-103.pts [fblocal/pts2pb.py] processing file F-104.pts [fblocal/pts2pb.py] processing file F-105.pts [fblocal/pts2pb.py] processing file F-106.pts [fblocal/pts2pb.py] processing file F-107.pts [fblocal/pts2pb.py] processing file F-108.pts [fblocal/pts2pb.py] processing file F-109.pts [fblocal/pts2pb.py] processing file F-110.pts [fblocal/pts2pb.py] processing file F-111.pts [fblocal/pts2pb.py] processing file F-112.pts [fblocal/pts2pb.py] processing file F-113.pts [fblocal/pts2pb.py] processing file F-114.pts [fblocal/pts2pb.py] processing file F-115.pts [fblocal/pts2pb.py] processing file F-116.pts [fblocal/pts2pb.py] processing file F-117.pts [fblocal/pts2pb.py] processing file F-118.pts [fblocal/pts2pb.py] processing file F-119.pts [fblocal/pts2pb.py] processing file F-120.pts [fblocal/pts2pb.py] processing file F-121.pts [fblocal/pts2pb.py] processing file F-122.pts [fblocal/pts2pb.py] processing file F-123.pts [fblocal/pts2pb.py] processing file F-124.pts [fblocal/pts2pb.py] processing file F-125.pts [fblocal/pts2pb.py] processing file F-126.pts [fblocal/pts2pb.py] processing file F-127.pts [fblocal/pts2pb.py] processing file F-128.pts [fblocal/pts2pb.py] processing file F-129.pts [fblocal/pts2pb.py] processing file F-130.pts [fblocal/pts2pb.py] processing file F-131.pts [fblocal/pts2pb.py] processing file F-132.pts [fblocal/pts2pb.py] processing file F-133.pts [fblocal/pts2pb.py] processing file F-134.pts [fblocal/pts2pb.py] processing file F-135.pts [fblocal/pts2pb.py] processing file F-136.pts [fblocal/pts2pb.py] processing file F-137.pts [fblocal/pts2pb.py] processing file F-138.pts [fblocal/pts2pb.py] processing file F-139.pts [fblocal/pts2pb.py] processing file F-140.pts [fblocal/pts2pb.py] processing file F-141.pts [fblocal/pts2pb.py] processing file F-142.pts [fblocal/pts2pb.py] processing file F-143.pts [fblocal/pts2pb.py] processing file F-144.pts [fblocal/pts2pb.py] processing file F-145.pts [fblocal/pts2pb.py] processing file F-146.pts [fblocal/pts2pb.py] processing file F-147.pts [fblocal/pts2pb.py] processing file F-148.pts [fblocal/pts2pb.py] processing file F-149.pts [fblocal/pts2pb.py] processing file F-150.pts [fblocal/pts2pb.py] processing file F-151.pts [fblocal/pts2pb.py] processing file F-152.pts [fblocal/pts2pb.py] processing file F-153.pts [fblocal/pts2pb.py] processing file F-154.pts [fblocal/pts2pb.py] processing file F-155.pts [fblocal/pts2pb.py] processing file F-156.pts [fblocal/pts2pb.py] processing file F-157.pts [fblocal/pts2pb.py] processing file F-158.pts [fblocal/pts2pb.py] processing file F-159.pts [fblocal/pts2pb.py] processing file F-160.pts [fblocal/pts2pb.py] processing file F-161.pts [fblocal/pts2pb.py] processing file F-162.pts [fblocal/pts2pb.py] processing file F-163.pts [fblocal/pts2pb.py] processing file F-164.pts [fblocal/pts2pb.py] processing file F-165.pts [fblocal/pts2pb.py] processing file F-166.pts [fblocal/pts2pb.py] processing file F-167.pts [fblocal/pts2pb.py] processing file F-168.pts [fblocal/pts2pb.py] processing file F-169.pts [fblocal/pts2pb.py] processing file F-170.pts [fblocal/pts2pb.py] processing file F-171.pts [fblocal/pts2pb.py] processing file F-172.pts [fblocal/pts2pb.py] processing file F-173.pts [fblocal/pts2pb.py] processing file F-174.pts [fblocal/pts2pb.py] processing file F-175.pts [fblocal/pts2pb.py] processing file F-176.pts [fblocal/pts2pb.py] processing file F-177.pts [fblocal/pts2pb.py] processing file F-178.pts [fblocal/pts2pb.py] processing file F-179.pts [fblocal/pts2pb.py] processing file F-180.pts [fblocal/pts2pb.py] processing file F-181.pts [fblocal/pts2pb.py] processing file F-182.pts [fblocal/pts2pb.py] processing file F-183.pts [fblocal/pts2pb.py] processing file F-184.pts [fblocal/pts2pb.py] processing file F-185.pts [fblocal/pts2pb.py] processing file F-186.pts [fblocal/pts2pb.py] processing file F-187.pts [fblocal/pts2pb.py] processing file F-188.pts [fblocal/pts2pb.py] processing file F-189.pts [fblocal/pts2pb.py] processing file F-190.pts [fblocal/pts2pb.py] processing file F-191.pts [fblocal/pts2pb.py] processing file F-192.pts [fblocal/pts2pb.py] processing file F-193.pts [fblocal/pts2pb.py] processing file F-194.pts [fblocal/pts2pb.py] processing file F-195.pts [fblocal/pts2pb.py] processing file F-196.pts [fblocal/pts2pb.py] processing file F-197.pts [fblocal/pts2pb.py] processing file F-198.pts [fblocal/pts2pb.py] processing file F-199.pts [fblocal/pts2pb.py] processing file F-200.pts ok	output written to alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	50.236	39.000	49.604 | 10.72%	31.01%	62.04%	89.69%	
ali_f                         	49.721	39.000	46.506 | 10.91%	31.24%	61.94%	89.47%	
--------------------------------------------------------------------------------------
run_align.sh: error: problem aligning with mono chain models with ivectors
Sat 23 Oct 11:51:10 -03 2021
Sat 23 Oct 16:48:18 -03 2021
[92m[2021-10-24 13:47:26] run_align.sh: extend lex[0m
removed 'alignme/local/dict/lexiconp.txt'
removed 'alignme/local/dict/lexiconp_silprob.txt'
[91m[2021-10-24 13:47:26] run_align.sh: prep lang[0m
utils/prepare_lang.sh alignme/local/dict <UNK> alignme/local/lang_tmp alignme/lang
Checking alignme/local/dict/silence_phones.txt ...
--> reading alignme/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/local/dict/silence_phones.txt is OK

Checking alignme/local/dict/optional_silence.txt ...
--> reading alignme/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/local/dict/optional_silence.txt is OK

Checking alignme/local/dict/nonsilence_phones.txt ...
--> reading alignme/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking alignme/local/dict/lexicon.txt
--> reading alignme/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/local/dict/lexicon.txt is OK

Checking alignme/local/dict/extra_questions.txt ...
--> reading alignme/local/dict/extra_questions.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/local/dict/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory alignme/local/dict]

**Creating alignme/local/dict/lexiconp.txt from alignme/local/dict/lexicon.txt
prepare_lang.sh: validating output directory
utils/validate_lang.pl alignme/lang
Checking existence of separator file
separator file alignme/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking alignme/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking alignme/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in alignme/lang/phones/context_indep.txt
--> alignme/lang/phones/context_indep.int corresponds to alignme/lang/phones/context_indep.txt
--> alignme/lang/phones/context_indep.csl corresponds to alignme/lang/phones/context_indep.txt
--> alignme/lang/phones/context_indep.{txt, int, csl} are OK

Checking alignme/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 152 entry/entries in alignme/lang/phones/nonsilence.txt
--> alignme/lang/phones/nonsilence.int corresponds to alignme/lang/phones/nonsilence.txt
--> alignme/lang/phones/nonsilence.csl corresponds to alignme/lang/phones/nonsilence.txt
--> alignme/lang/phones/nonsilence.{txt, int, csl} are OK

Checking alignme/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in alignme/lang/phones/silence.txt
--> alignme/lang/phones/silence.int corresponds to alignme/lang/phones/silence.txt
--> alignme/lang/phones/silence.csl corresponds to alignme/lang/phones/silence.txt
--> alignme/lang/phones/silence.{txt, int, csl} are OK

Checking alignme/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.int corresponds to alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.csl corresponds to alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.{txt, int, csl} are OK

Checking alignme/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 13 entry/entries in alignme/lang/phones/disambig.txt
--> alignme/lang/phones/disambig.int corresponds to alignme/lang/phones/disambig.txt
--> alignme/lang/phones/disambig.csl corresponds to alignme/lang/phones/disambig.txt
--> alignme/lang/phones/disambig.{txt, int, csl} are OK

Checking alignme/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in alignme/lang/phones/roots.txt
--> alignme/lang/phones/roots.int corresponds to alignme/lang/phones/roots.txt
--> alignme/lang/phones/roots.{txt, int} are OK

Checking alignme/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in alignme/lang/phones/sets.txt
--> alignme/lang/phones/sets.int corresponds to alignme/lang/phones/sets.txt
--> alignme/lang/phones/sets.{txt, int} are OK

Checking alignme/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in alignme/lang/phones/extra_questions.txt
--> alignme/lang/phones/extra_questions.int corresponds to alignme/lang/phones/extra_questions.txt
--> alignme/lang/phones/extra_questions.{txt, int} are OK

Checking alignme/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 162 entry/entries in alignme/lang/phones/word_boundary.txt
--> alignme/lang/phones/word_boundary.int corresponds to alignme/lang/phones/word_boundary.txt
--> alignme/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> alignme/lang/phones/disambig.txt has "#0" and "#1"
--> alignme/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> alignme/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> alignme/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> alignme/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> alignme/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 32 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 82 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking alignme/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in alignme/lang/oov.txt
--> alignme/lang/oov.int corresponds to alignme/lang/oov.txt
--> alignme/lang/oov.{txt, int} are OK

--> alignme/lang/L.fst is olabel sorted
--> alignme/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory alignme/lang]
utils/validate_lang.pl alignme/lang
Checking existence of separator file
separator file alignme/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking alignme/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> alignme/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking alignme/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in alignme/lang/phones/context_indep.txt
--> alignme/lang/phones/context_indep.int corresponds to alignme/lang/phones/context_indep.txt
--> alignme/lang/phones/context_indep.csl corresponds to alignme/lang/phones/context_indep.txt
--> alignme/lang/phones/context_indep.{txt, int, csl} are OK

Checking alignme/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 152 entry/entries in alignme/lang/phones/nonsilence.txt
--> alignme/lang/phones/nonsilence.int corresponds to alignme/lang/phones/nonsilence.txt
--> alignme/lang/phones/nonsilence.csl corresponds to alignme/lang/phones/nonsilence.txt
--> alignme/lang/phones/nonsilence.{txt, int, csl} are OK

Checking alignme/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in alignme/lang/phones/silence.txt
--> alignme/lang/phones/silence.int corresponds to alignme/lang/phones/silence.txt
--> alignme/lang/phones/silence.csl corresponds to alignme/lang/phones/silence.txt
--> alignme/lang/phones/silence.{txt, int, csl} are OK

Checking alignme/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.int corresponds to alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.csl corresponds to alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.{txt, int, csl} are OK

Checking alignme/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 13 entry/entries in alignme/lang/phones/disambig.txt
--> alignme/lang/phones/disambig.int corresponds to alignme/lang/phones/disambig.txt
--> alignme/lang/phones/disambig.csl corresponds to alignme/lang/phones/disambig.txt
--> alignme/lang/phones/disambig.{txt, int, csl} are OK

Checking alignme/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in alignme/lang/phones/roots.txt
--> alignme/lang/phones/roots.int corresponds to alignme/lang/phones/roots.txt
--> alignme/lang/phones/roots.{txt, int} are OK

Checking alignme/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 40 entry/entries in alignme/lang/phones/sets.txt
--> alignme/lang/phones/sets.int corresponds to alignme/lang/phones/sets.txt
--> alignme/lang/phones/sets.{txt, int} are OK

Checking alignme/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in alignme/lang/phones/extra_questions.txt
--> alignme/lang/phones/extra_questions.int corresponds to alignme/lang/phones/extra_questions.txt
--> alignme/lang/phones/extra_questions.{txt, int} are OK

Checking alignme/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 162 entry/entries in alignme/lang/phones/word_boundary.txt
--> alignme/lang/phones/word_boundary.int corresponds to alignme/lang/phones/word_boundary.txt
--> alignme/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading alignme/lang/phones/optional_silence.txt
--> alignme/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> alignme/lang/phones/disambig.txt has "#0" and "#1"
--> alignme/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> alignme/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> alignme/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> alignme/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> alignme/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 49 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 9 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking alignme/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in alignme/lang/oov.txt
--> alignme/lang/oov.int corresponds to alignme/lang/oov.txt
--> alignme/lang/oov.{txt, int} are OK

--> alignme/lang/L.fst is olabel sorted
--> alignme/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory alignme/lang]
[94m[2021-10-24 13:48:20] run_align.sh: prep data[0m
fix_data_dir.sh: kept all 399 utterances.
fix_data_dir.sh: old files are kept in alignme/.backup
utils/copy_data_dir.sh: copied data from alignme to alignme_lores
utils/validate_data_dir.sh: Successfully validated data-directory alignme_lores
utils/copy_data_dir.sh: copied data from alignme to alignme_hires
utils/validate_data_dir.sh: Successfully validated data-directory alignme_hires
[91m[2021-10-24 13:48:22] [run_align.sh] computing low resolution mfcc features[0m
steps/make_mfcc.sh --nj 2 alignme_lores
utils/validate_data_dir.sh: Successfully validated data-directory alignme_lores
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for alignme_lores
steps/compute_cmvn_stats.sh alignme_lores
Succeeded creating CMVN stats for alignme_lores
fix_data_dir.sh: kept all 399 utterances.
fix_data_dir.sh: old files are kept in alignme_lores/.backup
[96m[2021-10-24 13:48:24] [run_align.sh] computing high resolution mfcc features[0m
steps/make_mfcc.sh --nj 2 --mfcc-config conf/mfcc_hires.conf alignme_hires
utils/validate_data_dir.sh: Successfully validated data-directory alignme_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for alignme_hires
steps/compute_cmvn_stats.sh alignme_hires
Succeeded creating CMVN stats for alignme_hires
fix_data_dir.sh: kept all 399 utterances.
fix_data_dir.sh: old files are kept in alignme_hires/.backup
[95m[2021-10-24 13:48:25] [run_align.sh] computing ivector features[0m
steps/online/nnet2/extract_ivectors_online.sh --nj 2 alignme_hires exp/nnet3/extractor alignme/ivectors_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to alignme/ivectors_hires using the extractor in exp/nnet3/extractor.
run_align.sh: #####################################
run_align.sh: ### align with GMM models routine ###
run_align.sh: #####################################
[96m[2021-10-24 13:48:27] [run_align.sh] align mono[0m
steps/align_si.sh --nj 2 alignme_lores alignme/lang exp/mono alignme/results/mono_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in alignme_lores using model from exp/mono, putting alignments in alignme/results/mono_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/mono_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 0.751879699248% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 28.8220551378% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/mono_ali/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

steps/get_train_ctm.sh alignme alignme/lang alignme/results/mono_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/mono_ali/ali_m.pb
ok	output written to alignme/results/mono_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	18.882	12.000	24.981 | 41.41%	77.18%	93.59%	98.20%	
ali_f                         	16.314	11.000	18.677 | 42.85%	81.40%	95.59%	99.15%	
--------------------------------------------------------------------------------------
[96m[2021-10-24 13:48:32] [run_align.sh] align tri-deltas[0m
steps/align_si.sh --nj 2 alignme_lores alignme/lang exp/tri1 alignme/results/tri1_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in alignme_lores using model from exp/tri1, putting alignments in alignme/results/tri1_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tri1_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 15.5778894472% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 62.5628140704% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tri1_ali/log/analyze_alignments.log
steps/align_si.sh: done aligning data.
fblocal/ali2ctm2pts.sh: file missing: male_M-101

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tri1_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed

[33mfblocal/pts2pb.py: file sizes differ: 25 vs 0. this should not be happening[0m
ok	output written to alignme/results/tri1_ali/ali_m.pb
ok	output written to alignme/results/tri1_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	19.860	12.000	27.467 | 40.93%	76.36%	92.26%	97.70%	
ali_f                         	19.962	11.000	33.725 | 42.68%	78.69%	92.59%	97.38%	
--------------------------------------------------------------------------------------
[91m[2021-10-24 13:48:38] [run_align.sh] align tri-lda[0m
steps/align_fmllr.sh --nj 2 alignme_lores alignme/lang exp/tri2b alignme/results/tri2b_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in alignme_lores using exp/tri2b/final.mdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tri2b_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 3.50877192982% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 56.64160401% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tri2b_ali/log/analyze_alignments.log
2 warnings in alignme/results/tri2b_ali/log/analyze_alignments.log
31 warnings in alignme/results/tri2b_ali/log/align_pass1.*.log
3 warnings in alignme/results/tri2b_ali/log/fmllr.*.log
4 warnings in alignme/results/tri2b_ali/log/align_pass2.*.log

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tri2b_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tri2b_ali/ali_m.pb
ok	output written to alignme/results/tri2b_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	16.742	11.000	18.142 | 42.78%	78.83%	94.58%	99.31%	
ali_f                         	17.204	12.000	20.715 | 41.30%	78.76%	94.87%	99.25%	
--------------------------------------------------------------------------------------
[94m[2021-10-24 13:48:52] [run_align.sh] align tri-sat (1st)[0m
steps/align_fmllr.sh --nj 2 alignme_lores alignme/lang exp/tri3b alignme/results/tri3b_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in alignme_lores using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tri3b_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 4.26065162907% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 66.1654135338% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tri3b_ali/log/analyze_alignments.log
2 warnings in alignme/results/tri3b_ali/log/analyze_alignments.log
10 warnings in alignme/results/tri3b_ali/log/align_pass1.*.log
3 warnings in alignme/results/tri3b_ali/log/align_pass2.*.log
1 warnings in alignme/results/tri3b_ali/log/fmllr.*.log

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tri3b_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tri3b_ali/ali_m.pb
ok	output written to alignme/results/tri3b_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	17.362	12.000	18.971 | 40.66%	77.85%	94.25%	99.27%	
ali_f                         	17.212	12.000	19.608 | 40.17%	78.75%	94.91%	99.30%	
--------------------------------------------------------------------------------------
[95m[2021-10-24 13:49:06] [run_align.sh] align tri-sat (2nd)[0m
steps/align_fmllr.sh --nj 2 alignme_lores alignme/lang exp/tri4b alignme/results/tri4b_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in alignme_lores using exp/tri4b/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tri4b_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 3.75939849624% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 69.1729323308% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tri4b_ali/log/analyze_alignments.log
2 warnings in alignme/results/tri4b_ali/log/analyze_alignments.log
5 warnings in alignme/results/tri4b_ali/log/align_pass2.*.log
2 warnings in alignme/results/tri4b_ali/log/fmllr.*.log
25 warnings in alignme/results/tri4b_ali/log/align_pass1.*.log

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tri4b_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tri4b_ali/ali_m.pb
ok	output written to alignme/results/tri4b_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	17.287	12.000	19.852 | 41.65%	78.13%	93.87%	99.16%	
ali_f                         	17.020	12.000	19.641 | 41.25%	79.42%	94.97%	99.30%	
--------------------------------------------------------------------------------------
run_align.sh: ########################################################
run_align.sh: ### align with mono-based TDNN-F mono models routine ###
run_align.sh: ########################################################
[96m[2021-10-24 13:49:14] run_align.sh: align tdnn_mono_chain_delta_ivector_fs3_sp (mono chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_mono_chain_delta_ivector_fs3_sp, putting alignments in alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 17.7944862155% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 77.1929824561% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_mono_chain_delta_ivector_fs3_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	19.475	15.000	18.473 | 34.76%	71.50%	93.61%	99.36%	
ali_f                         	19.777	15.000	18.568 | 33.33%	71.70%	93.24%	99.40%	
--------------------------------------------------------------------------------------
[96m[2021-10-24 13:49:21] run_align.sh: align tdnn_mono_chain_delta_ivector_nofs_sp (mono chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_mono_chain_delta_ivector_nofs_sp, putting alignments in alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 34.5864661654% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 79.4486215539% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_mono_chain_delta_ivector_nofs_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	50.236	39.000	49.604 | 10.72%	31.01%	62.04%	89.69%	
ali_f                         	49.721	39.000	46.506 | 10.91%	31.24%	61.94%	89.47%	
--------------------------------------------------------------------------------------
[92m[2021-10-24 13:49:30] run_align.sh: align tdnn_mono_chain_lda_ivector_fs3_sp (mono chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_mono_chain_lda_ivector_fs3_sp, putting alignments in alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 11.2781954887% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 44.3609022556% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_mono_chain_lda_ivector_fs3_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	20.344	15.000	19.988 | 33.43%	69.95%	93.09%	99.12%	
ali_f                         	22.556	16.000	35.489 | 31.41%	69.23%	92.37%	98.25%	
--------------------------------------------------------------------------------------
[94m[2021-10-24 13:49:37] run_align.sh: align tdnn_mono_chain_lda_ivector_nofs_sp (mono chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_mono_chain_lda_ivector_nofs_sp, putting alignments in alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 46.6165413534% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 64.6616541353% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_mono_chain_lda_ivector_nofs_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	43.767	34.000	41.244 | 12.80%	36.05%	69.63%	92.26%	
ali_f                         	62.554	39.000	93.757 | 11.48%	32.24%	61.33%	85.40%	
--------------------------------------------------------------------------------------
[93m[2021-10-24 13:49:46] run_align.sh: align tdnn_mono_chain_delta_noivector_fs3_sp (mono chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp alignme/results/tdnn_mono_chain_delta_noivector_fs3_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_mono_chain_delta_noivector_fs3_sp, putting alignments in alignme/results/tdnn_mono_chain_delta_noivector_fs3_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_chain_delta_noivector_fs3_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 29.5739348371% of the time at utterance begin.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_chain_delta_noivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_chain_delta_noivector_fs3_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_mono_chain_delta_noivector_fs3_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_mono_chain_delta_noivector_fs3_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	19.575	14.000	18.460 | 34.68%	71.16%	93.44%	99.36%	
ali_f                         	19.285	15.000	18.321 | 34.20%	72.98%	93.76%	99.28%	
--------------------------------------------------------------------------------------
[94m[2021-10-24 13:49:53] run_align.sh: align tdnn_mono_chain_delta_noivector_nofs_sp (mono chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp alignme/results/tdnn_mono_chain_delta_noivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_mono_chain_delta_noivector_nofs_sp, putting alignments in alignme/results/tdnn_mono_chain_delta_noivector_nofs_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_chain_delta_noivector_nofs_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 31.0776942356% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 71.4285714286% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_chain_delta_noivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_chain_delta_noivector_nofs_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_mono_chain_delta_noivector_nofs_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_mono_chain_delta_noivector_nofs_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	48.675	38.000	50.847 | 10.59%	31.22%	62.96%	90.74%	
ali_f                         	47.520	39.000	42.833 | 11.12%	30.43%	63.33%	91.12%	
--------------------------------------------------------------------------------------
[94m[2021-10-24 13:50:02] run_align.sh: align tdnn_mono_chain_lda_noivector_fs3_sp (mono chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp alignme/results/tdnn_mono_chain_lda_noivector_fs3_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_mono_chain_lda_noivector_fs3_sp, putting alignments in alignme/results/tdnn_mono_chain_lda_noivector_fs3_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_chain_lda_noivector_fs3_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 18.5463659148% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 57.8947368421% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_chain_lda_noivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_chain_lda_noivector_fs3_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_mono_chain_lda_noivector_fs3_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_mono_chain_lda_noivector_fs3_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	20.623	15.000	20.991 | 34.36%	70.36%	92.36%	98.76%	
ali_f                         	20.147	15.000	19.733 | 32.62%	71.26%	93.22%	98.94%	
--------------------------------------------------------------------------------------
[94m[2021-10-24 13:50:09] run_align.sh: align tdnn_mono_chain_lda_noivector_nofs_sp (mono chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp alignme/results/tdnn_mono_chain_lda_noivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_mono_chain_lda_noivector_nofs_sp, putting alignments in alignme/results/tdnn_mono_chain_lda_noivector_nofs_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_chain_lda_noivector_nofs_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 47.1177944862% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 51.3784461153% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_chain_lda_noivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_chain_lda_noivector_nofs_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_mono_chain_lda_noivector_nofs_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_mono_chain_lda_noivector_nofs_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	49.731	34.000	79.895 | 12.91%	35.90%	67.79%	90.73%	
ali_f                         	46.948	35.000	53.499 | 11.36%	33.71%	68.48%	91.35%	
--------------------------------------------------------------------------------------
[91m[2021-10-24 13:50:17] run_align.sh: align tdnn_mono_nochain_delta_ivector_sp (mono no chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires alignme_hires alignme/lang exp/nnet3/tdnn_mono_nochain_delta_ivector_sp alignme/results/tdnn_mono_nochain_delta_ivector_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/nnet3/tdnn_mono_nochain_delta_ivector_sp, putting alignments in alignme/results/tdnn_mono_nochain_delta_ivector_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_nochain_delta_ivector_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 0.250626566416% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 41.6040100251% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_nochain_delta_ivector_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: nnet3 selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_nochain_delta_ivector_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_mono_nochain_delta_ivector_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_mono_nochain_delta_ivector_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	17.593	12.000	20.970 | 41.39%	79.20%	94.42%	98.71%	
ali_f                         	16.538	11.000	16.936 | 42.38%	79.29%	95.23%	99.55%	
--------------------------------------------------------------------------------------
[91m[2021-10-24 13:50:26] run_align.sh: align tdnn_mono_nochain_lda_ivector_sp (mono no chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires alignme_hires alignme/lang exp/nnet3/tdnn_mono_nochain_lda_ivector_sp alignme/results/tdnn_mono_nochain_lda_ivector_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/nnet3/tdnn_mono_nochain_lda_ivector_sp, putting alignments in alignme/results/tdnn_mono_nochain_lda_ivector_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_nochain_lda_ivector_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 0.751879699248% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 21.5538847118% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_nochain_lda_ivector_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: nnet3 selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_nochain_lda_ivector_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_mono_nochain_lda_ivector_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_mono_nochain_lda_ivector_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	18.062	12.000	21.329 | 41.03%	78.17%	93.80%	98.88%	
ali_f                         	16.901	12.000	18.799 | 41.29%	80.46%	95.04%	99.06%	
--------------------------------------------------------------------------------------
[91m[2021-10-24 13:50:33] run_align.sh: align tdnn_mono_nochain_delta_noivector_sp (mono no chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true alignme_hires alignme/lang exp/nnet3/tdnn_mono_nochain_delta_noivector_sp alignme/results/tdnn_mono_nochain_delta_noivector_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/nnet3/tdnn_mono_nochain_delta_noivector_sp, putting alignments in alignme/results/tdnn_mono_nochain_delta_noivector_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_nochain_delta_noivector_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 0.250626566416% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 32.5814536341% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_nochain_delta_noivector_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: nnet3 selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_nochain_delta_noivector_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_mono_nochain_delta_noivector_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_mono_nochain_delta_noivector_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	17.528	12.000	19.701 | 40.55%	78.08%	94.77%	98.91%	
ali_f                         	16.440	12.000	16.531 | 41.34%	79.65%	95.72%	99.59%	
--------------------------------------------------------------------------------------
[95m[2021-10-24 13:50:42] run_align.sh: align tdnn_mono_nochain_lda_noivector_sp (mono no chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true alignme_hires alignme/lang exp/nnet3/tdnn_mono_nochain_lda_noivector_sp alignme/results/tdnn_mono_nochain_lda_noivector_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/nnet3/tdnn_mono_nochain_lda_noivector_sp, putting alignments in alignme/results/tdnn_mono_nochain_lda_noivector_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_mono_nochain_lda_noivector_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 1.25313283208% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 17.5438596491% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_mono_nochain_lda_noivector_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: nnet3 selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_mono_nochain_lda_noivector_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_mono_nochain_lda_noivector_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_mono_nochain_lda_noivector_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	19.856	13.000	24.802 | 39.63%	75.27%	92.17%	98.28%	
ali_f                         	17.360	12.000	19.866 | 40.74%	79.05%	94.86%	99.02%	
--------------------------------------------------------------------------------------
run_align.sh: ###################################################################
run_align.sh: ### align with trideltas-based TDNN-F tri-deltas models routine ###
run_align.sh: ###################################################################
[96m[2021-10-24 13:50:49] run_align.sh: align tdnn_trideltas_chain_delta_ivector_fs3_sp (tri-deltas chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp alignme/results/tdnn_trideltas_chain_delta_ivector_fs3_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trideltas_chain_delta_ivector_fs3_sp, putting alignments in alignme/results/tdnn_trideltas_chain_delta_ivector_fs3_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trideltas_chain_delta_ivector_fs3_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 12.5313283208% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 75.6892230576% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trideltas_chain_delta_ivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trideltas_chain_delta_ivector_fs3_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trideltas_chain_delta_ivector_fs3_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trideltas_chain_delta_ivector_fs3_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	20.445	15.000	19.206 | 33.54%	69.42%	92.56%	99.25%	
ali_f                         	20.668	16.000	19.306 | 32.28%	69.47%	92.39%	99.23%	
--------------------------------------------------------------------------------------
[92m[2021-10-24 13:50:57] run_align.sh: align tdnn_trideltas_chain_delta_ivector_nofs_sp (tri-deltas chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp alignme/results/tdnn_trideltas_chain_delta_ivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trideltas_chain_delta_ivector_nofs_sp, putting alignments in alignme/results/tdnn_trideltas_chain_delta_ivector_nofs_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trideltas_chain_delta_ivector_nofs_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 36.0902255639% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 78.9473684211% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trideltas_chain_delta_ivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trideltas_chain_delta_ivector_nofs_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trideltas_chain_delta_ivector_nofs_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trideltas_chain_delta_ivector_nofs_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	50.194	37.000	53.254 | 11.54%	33.52%	62.98%	88.81%	
ali_f                         	50.519	38.000	49.920 | 10.82%	32.43%	61.62%	89.39%	
--------------------------------------------------------------------------------------
[95m[2021-10-24 13:51:08] run_align.sh: align tdnn_trideltas_chain_lda_ivector_fs3_sp (tri-deltas chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp alignme/results/tdnn_trideltas_chain_lda_ivector_fs3_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trideltas_chain_lda_ivector_fs3_sp, putting alignments in alignme/results/tdnn_trideltas_chain_lda_ivector_fs3_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trideltas_chain_lda_ivector_fs3_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 13.0325814536% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 43.6090225564% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trideltas_chain_lda_ivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trideltas_chain_lda_ivector_fs3_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trideltas_chain_lda_ivector_fs3_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trideltas_chain_lda_ivector_fs3_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	19.809	14.000	20.370 | 35.32%	71.95%	93.14%	98.99%	
ali_f                         	22.300	16.000	23.664 | 31.00%	68.66%	90.86%	98.23%	
--------------------------------------------------------------------------------------
[96m[2021-10-24 13:51:16] run_align.sh: align tdnn_trideltas_chain_lda_ivector_nofs_sp (tri-deltas chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp alignme/results/tdnn_trideltas_chain_lda_ivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trideltas_chain_lda_ivector_nofs_sp, putting alignments in alignme/results/tdnn_trideltas_chain_lda_ivector_nofs_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trideltas_chain_lda_ivector_nofs_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 38.0952380952% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 48.1203007519% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trideltas_chain_lda_ivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trideltas_chain_lda_ivector_nofs_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trideltas_chain_lda_ivector_nofs_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trideltas_chain_lda_ivector_nofs_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	44.631	34.000	42.761 | 12.16%	34.68%	68.88%	91.53%	
ali_f                         	69.657	39.000	115.029 | 10.68%	32.01%	61.13%	84.04%	
--------------------------------------------------------------------------------------
[94m[2021-10-24 13:51:24] run_align.sh: align tdnn_trideltas_chain_delta_noivector_fs3_sp (tri-deltas chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp alignme/results/tdnn_trideltas_chain_delta_noivector_fs3_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trideltas_chain_delta_noivector_fs3_sp, putting alignments in alignme/results/tdnn_trideltas_chain_delta_noivector_fs3_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trideltas_chain_delta_noivector_fs3_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 23.8095238095% of the time at utterance begin.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trideltas_chain_delta_noivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trideltas_chain_delta_noivector_fs3_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trideltas_chain_delta_noivector_fs3_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trideltas_chain_delta_noivector_fs3_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	20.394	15.000	19.389 | 33.86%	69.78%	92.62%	99.16%	
ali_f                         	20.519	15.000	19.534 | 32.50%	70.27%	92.44%	99.15%	
--------------------------------------------------------------------------------------
[95m[2021-10-24 13:51:31] run_align.sh: align tdnn_trideltas_chain_delta_noivector_nofs_sp (tri-deltas chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp alignme/results/tdnn_trideltas_chain_delta_noivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trideltas_chain_delta_noivector_nofs_sp, putting alignments in alignme/results/tdnn_trideltas_chain_delta_noivector_nofs_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trideltas_chain_delta_noivector_nofs_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 44.1102756892% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 75.1879699248% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trideltas_chain_delta_noivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trideltas_chain_delta_noivector_nofs_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trideltas_chain_delta_noivector_nofs_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trideltas_chain_delta_noivector_nofs_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	51.372	40.000	54.493 | 10.10%	29.70%	61.70%	89.54%	
ali_f                         	49.540	40.000	44.242 | 10.18%	29.47%	61.54%	90.03%	
--------------------------------------------------------------------------------------
[93m[2021-10-24 13:51:39] run_align.sh: align tdnn_trideltas_chain_lda_noivector_fs3_sp (tri-deltas chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp alignme/results/tdnn_trideltas_chain_lda_noivector_fs3_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trideltas_chain_lda_noivector_fs3_sp, putting alignments in alignme/results/tdnn_trideltas_chain_lda_noivector_fs3_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trideltas_chain_lda_noivector_fs3_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 27.3182957393% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 62.1553884712% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trideltas_chain_lda_noivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trideltas_chain_lda_noivector_fs3_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trideltas_chain_lda_noivector_fs3_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trideltas_chain_lda_noivector_fs3_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	21.562	15.000	22.775 | 33.69%	68.75%	91.72%	98.41%	
ali_f                         	20.992	16.000	20.844 | 31.84%	69.72%	92.43%	98.89%	
--------------------------------------------------------------------------------------
[93m[2021-10-24 13:51:47] run_align.sh: align tdnn_trideltas_chain_lda_noivector_nofs_sp (tri-deltas chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp alignme/results/tdnn_trideltas_chain_lda_noivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trideltas_chain_lda_noivector_nofs_sp, putting alignments in alignme/results/tdnn_trideltas_chain_lda_noivector_nofs_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trideltas_chain_lda_noivector_nofs_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 39.5989974937% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 58.1453634085% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trideltas_chain_lda_noivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trideltas_chain_lda_noivector_nofs_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trideltas_chain_lda_noivector_nofs_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trideltas_chain_lda_noivector_nofs_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	44.044	33.000	44.017 | 13.34%	37.44%	69.18%	92.00%	
ali_f                         	47.839	36.000	57.042 | 11.66%	33.20%	68.17%	91.33%	
--------------------------------------------------------------------------------------
[93m[2021-10-24 13:51:55] run_align.sh: align tdnn_trideltas_nochain_delta_ivector_sp (tri-deltas no chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires alignme_hires alignme/lang exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp alignme/results/tdnn_trideltas_nochain_delta_ivector_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/nnet3/tdnn_trideltas_nochain_delta_ivector_sp, putting alignments in alignme/results/tdnn_trideltas_nochain_delta_ivector_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trideltas_nochain_delta_ivector_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 3.00751879699% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 63.4085213033% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trideltas_nochain_delta_ivector_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: nnet3 selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trideltas_nochain_delta_ivector_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trideltas_nochain_delta_ivector_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trideltas_nochain_delta_ivector_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	16.331	11.000	17.738 | 43.84%	80.18%	94.85%	99.25%	
ali_f                         	16.682	12.000	17.134 | 41.23%	79.78%	95.08%	99.36%	
--------------------------------------------------------------------------------------
[96m[2021-10-24 13:52:03] run_align.sh: align tdnn_trideltas_nochain_lda_ivector_sp (tri-deltas no chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires alignme_hires alignme/lang exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp alignme/results/tdnn_trideltas_nochain_lda_ivector_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/nnet3/tdnn_trideltas_nochain_lda_ivector_sp, putting alignments in alignme/results/tdnn_trideltas_nochain_lda_ivector_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trideltas_nochain_lda_ivector_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 2.25563909774% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 39.8496240602% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trideltas_nochain_lda_ivector_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: nnet3 selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trideltas_nochain_lda_ivector_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trideltas_nochain_lda_ivector_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trideltas_nochain_lda_ivector_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	16.590	11.000	17.903 | 43.32%	79.65%	94.57%	99.23%	
ali_f                         	18.628	12.000	44.966 | 42.40%	80.55%	94.61%	98.81%	
--------------------------------------------------------------------------------------
[96m[2021-10-24 13:52:11] run_align.sh: align tdnn_trideltas_nochain_delta_noivector_sp (tri-deltas no chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true alignme_hires alignme/lang exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp alignme/results/tdnn_trideltas_nochain_delta_noivector_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/nnet3/tdnn_trideltas_nochain_delta_noivector_sp, putting alignments in alignme/results/tdnn_trideltas_nochain_delta_noivector_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trideltas_nochain_delta_noivector_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 4.01002506266% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 54.1353383459% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trideltas_nochain_delta_noivector_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: nnet3 selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trideltas_nochain_delta_noivector_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trideltas_nochain_delta_noivector_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trideltas_nochain_delta_noivector_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	16.349	11.000	17.098 | 42.65%	80.04%	94.92%	99.44%	
ali_f                         	16.154	11.000	16.939 | 42.04%	81.01%	95.46%	99.38%	
--------------------------------------------------------------------------------------
[92m[2021-10-24 13:52:19] run_align.sh: align tdnn_trideltas_nochain_lda_noivector_sp (tri-deltas no chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true alignme_hires alignme/lang exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp alignme/results/tdnn_trideltas_nochain_lda_noivector_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/nnet3/tdnn_trideltas_nochain_lda_noivector_sp, putting alignments in alignme/results/tdnn_trideltas_nochain_lda_noivector_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trideltas_nochain_lda_noivector_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 3.50877192982% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 39.5989974937% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trideltas_nochain_lda_noivector_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: nnet3 selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trideltas_nochain_lda_noivector_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trideltas_nochain_lda_noivector_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trideltas_nochain_lda_noivector_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	17.914	12.000	20.573 | 40.70%	78.21%	93.57%	98.74%	
ali_f                         	18.662	12.000	44.830 | 41.32%	80.59%	94.50%	98.89%	
--------------------------------------------------------------------------------------
run_align.sh: ################################################
run_align.sh: ### align with TDNN-F tri-sat models routine ###
run_align.sh: ################################################
[91m[2021-10-24 13:52:27] run_align.sh: align tdnn_trisat_chain_delta_ivector_fs3_sp (tri-sat chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp alignme/results/tdnn_trisat_chain_delta_ivector_fs3_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trisat_chain_delta_ivector_fs3_sp, putting alignments in alignme/results/tdnn_trisat_chain_delta_ivector_fs3_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trisat_chain_delta_ivector_fs3_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 20.8020050125% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 77.694235589% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trisat_chain_delta_ivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trisat_chain_delta_ivector_fs3_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trisat_chain_delta_ivector_fs3_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trisat_chain_delta_ivector_fs3_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	22.351	17.000	20.018 | 30.43%	64.91%	90.41%	99.34%	
ali_f                         	22.865	18.000	20.688 | 29.41%	64.42%	90.26%	99.02%	
--------------------------------------------------------------------------------------
[94m[2021-10-24 13:52:34] run_align.sh: align tdnn_trisat_chain_delta_ivector_nofs_sp (tri-sat chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp alignme/results/tdnn_trisat_chain_delta_ivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trisat_chain_delta_ivector_nofs_sp, putting alignments in alignme/results/tdnn_trisat_chain_delta_ivector_nofs_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trisat_chain_delta_ivector_nofs_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 36.8421052632% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 74.4360902256% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trisat_chain_delta_ivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trisat_chain_delta_ivector_nofs_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trisat_chain_delta_ivector_nofs_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trisat_chain_delta_ivector_nofs_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	57.165	43.000	60.919 |  9.57%	28.71%	56.45%	86.28%	
ali_f                         	55.387	43.000	61.640 | 10.53%	28.94%	57.32%	87.53%	
--------------------------------------------------------------------------------------
[95m[2021-10-24 13:52:42] run_align.sh: align tdnn_trisat_chain_lda_ivector_fs3_sp (tri-sat chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp alignme/results/tdnn_trisat_chain_lda_ivector_fs3_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trisat_chain_lda_ivector_fs3_sp, putting alignments in alignme/results/tdnn_trisat_chain_lda_ivector_fs3_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trisat_chain_lda_ivector_fs3_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 33.5839598997% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 49.373433584% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trisat_chain_lda_ivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trisat_chain_lda_ivector_fs3_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trisat_chain_lda_ivector_fs3_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trisat_chain_lda_ivector_fs3_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	21.819	16.000	23.075 | 32.62%	68.75%	91.47%	98.35%	
ali_f                         	26.217	18.000	30.249 | 28.85%	63.60%	87.58%	96.57%	
--------------------------------------------------------------------------------------
[92m[2021-10-24 13:52:49] run_align.sh: align tdnn_trisat_chain_lda_ivector_nofs_sp (tri-sat chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp alignme/results/tdnn_trisat_chain_lda_ivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trisat_chain_lda_ivector_nofs_sp, putting alignments in alignme/results/tdnn_trisat_chain_lda_ivector_nofs_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trisat_chain_lda_ivector_nofs_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 42.1052631579% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 52.8822055138% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trisat_chain_lda_ivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trisat_chain_lda_ivector_nofs_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trisat_chain_lda_ivector_nofs_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trisat_chain_lda_ivector_nofs_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	46.828	37.000	41.695 | 12.05%	32.57%	64.31%	91.12%	
ali_f                         	59.506	40.000	75.134 | 10.93%	30.15%	60.73%	86.13%	
--------------------------------------------------------------------------------------
[96m[2021-10-24 13:52:56] run_align.sh: align tdnn_trisat_chain_delta_noivector_fs3_sp (tri-sat chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp alignme/results/tdnn_trisat_chain_delta_noivector_fs3_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trisat_chain_delta_noivector_fs3_sp, putting alignments in alignme/results/tdnn_trisat_chain_delta_noivector_fs3_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trisat_chain_delta_noivector_fs3_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 24.5614035088% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 77.1929824561% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trisat_chain_delta_noivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trisat_chain_delta_noivector_fs3_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trisat_chain_delta_noivector_fs3_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trisat_chain_delta_noivector_fs3_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	22.879	18.000	20.351 | 29.19%	64.23%	90.03%	99.21%	
ali_f                         	22.942	18.000	20.877 | 28.66%	64.20%	90.47%	98.93%	
--------------------------------------------------------------------------------------
[92m[2021-10-24 13:53:03] run_align.sh: align tdnn_trisat_chain_delta_noivector_nofs_sp (tri-sat chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp alignme/results/tdnn_trisat_chain_delta_noivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trisat_chain_delta_noivector_nofs_sp, putting alignments in alignme/results/tdnn_trisat_chain_delta_noivector_nofs_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trisat_chain_delta_noivector_nofs_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 39.8496240602% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 68.671679198% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trisat_chain_delta_noivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trisat_chain_delta_noivector_nofs_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trisat_chain_delta_noivector_nofs_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trisat_chain_delta_noivector_nofs_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	53.474	42.000	55.778 | 10.01%	29.02%	58.23%	89.09%	
ali_f                         	50.898	43.000	45.696 |  9.76%	28.57%	58.34%	89.98%	
--------------------------------------------------------------------------------------
[96m[2021-10-24 13:53:11] run_align.sh: align tdnn_trisat_chain_lda_noivector_fs3_sp (tri-sat chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp alignme/results/tdnn_trisat_chain_lda_noivector_fs3_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trisat_chain_lda_noivector_fs3_sp, putting alignments in alignme/results/tdnn_trisat_chain_lda_noivector_fs3_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trisat_chain_lda_noivector_fs3_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 33.0827067669% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 49.6240601504% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trisat_chain_lda_noivector_fs3_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trisat_chain_lda_noivector_fs3_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trisat_chain_lda_noivector_fs3_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trisat_chain_lda_noivector_fs3_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	22.907	17.000	23.054 | 30.99%	65.65%	90.78%	98.35%	
ali_f                         	24.557	17.000	46.593 | 30.49%	66.20%	90.54%	98.27%	
--------------------------------------------------------------------------------------
[91m[2021-10-24 13:53:18] run_align.sh: align tdnn_trisat_chain_lda_noivector_nofs_sp (tri-sat chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --scale-opts --transition-scale=1.0 --acoustic-scale=1.0 --self-loop-scale=1.0 alignme_hires alignme/lang exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp alignme/results/tdnn_trisat_chain_lda_noivector_nofs_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/chain/tdnn_trisat_chain_lda_noivector_nofs_sp, putting alignments in alignme/results/tdnn_trisat_chain_lda_noivector_nofs_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trisat_chain_lda_noivector_nofs_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 39.5989974937% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 54.1353383459% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trisat_chain_lda_noivector_nofs_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: chain selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trisat_chain_lda_noivector_nofs_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trisat_chain_lda_noivector_nofs_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trisat_chain_lda_noivector_nofs_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	46.708	36.000	44.329 | 13.04%	34.78%	65.21%	90.74%	
ali_f                         	47.472	37.000	50.270 | 11.38%	32.37%	66.29%	91.60%	
--------------------------------------------------------------------------------------
[95m[2021-10-24 13:53:25] run_align.sh: align tdnn_trisat_nochain_delta_ivector_sp (tri-sat no chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires alignme_hires alignme/lang exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp alignme/results/tdnn_trisat_nochain_delta_ivector_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/nnet3/tdnn_trisat_nochain_delta_ivector_sp, putting alignments in alignme/results/tdnn_trisat_nochain_delta_ivector_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trisat_nochain_delta_ivector_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 1.75438596491% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 58.1453634085% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trisat_nochain_delta_ivector_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: nnet3 selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trisat_nochain_delta_ivector_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trisat_nochain_delta_ivector_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trisat_nochain_delta_ivector_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	16.799	12.000	17.169 | 41.33%	78.79%	94.49%	99.34%	
ali_f                         	16.580	12.000	17.262 | 41.68%	80.05%	95.08%	99.42%	
--------------------------------------------------------------------------------------
[93m[2021-10-24 13:53:33] run_align.sh: align tdnn_trisat_nochain_lda_ivector_sp (tri-sat no chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true --online-ivector-dir alignme/ivectors_hires alignme_hires alignme/lang exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp alignme/results/tdnn_trisat_nochain_lda_ivector_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/nnet3/tdnn_trisat_nochain_lda_ivector_sp, putting alignments in alignme/results/tdnn_trisat_nochain_lda_ivector_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trisat_nochain_lda_ivector_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 4.26065162907% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 38.3458646617% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trisat_nochain_lda_ivector_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: nnet3 selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trisat_nochain_lda_ivector_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trisat_nochain_lda_ivector_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trisat_nochain_lda_ivector_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	16.820	12.000	18.058 | 40.92%	79.11%	94.88%	99.44%	
ali_f                         	18.268	11.000	45.822 | 43.49%	81.38%	95.20%	99.06%	
--------------------------------------------------------------------------------------
[95m[2021-10-24 13:53:41] run_align.sh: align tdnn_trisat_nochain_delta_noivector_sp (tri-sat no chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true alignme_hires alignme/lang exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp alignme/results/tdnn_trisat_nochain_delta_noivector_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/nnet3/tdnn_trisat_nochain_delta_noivector_sp, putting alignments in alignme/results/tdnn_trisat_nochain_delta_noivector_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trisat_nochain_delta_noivector_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 3.75939849624% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 44.6115288221% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trisat_nochain_delta_noivector_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: nnet3 selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trisat_nochain_delta_noivector_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trisat_nochain_delta_noivector_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trisat_nochain_delta_noivector_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	15.966	11.000	16.908 | 42.80%	80.44%	95.18%	99.63%	
ali_f                         	15.809	11.000	16.312 | 43.60%	81.31%	95.85%	99.53%	
--------------------------------------------------------------------------------------
[94m[2021-10-24 13:53:49] run_align.sh: align tdnn_trisat_nochain_lda_noivector_sp (tri-sat no chain)[0m
steps/nnet3/align.sh --nj 2 --use-gpu true alignme_hires alignme/lang exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp alignme/results/tdnn_trisat_nochain_lda_noivector_sp_ali
steps/nnet3/align.sh: feature type is raw
steps/nnet3/align.sh: aligning data in alignme_hires using model from exp/nnet3/tdnn_trisat_nochain_lda_noivector_sp, putting alignments in alignme/results/tdnn_trisat_nochain_lda_noivector_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl alignme/lang alignme/results/tdnn_trisat_nochain_lda_noivector_sp_ali
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 3.50877192982% of the time at utterance begin.  This may not be optimal.
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 34.0852130326% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in alignme/results/tdnn_trisat_nochain_lda_noivector_sp_ali/log/analyze_alignments.log
steps/nnet3/align.sh: done aligning data.
fblocal/ali2ctm2pts.sh: nnet3 selected

steps/get_train_ctm.sh alignme alignme/lang alignme/results/tdnn_trisat_nochain_lda_noivector_sp_ali ctm_tmp
[fblocal/ctm2pts.py] mapping file 'alignme/lang/phones.txt'

[fblocal/ctm2pts.py] done. 398 ctm files processed
ok	output written to alignme/results/tdnn_trisat_nochain_lda_noivector_sp_ali/ali_m.pb
ok	output written to alignme/results/tdnn_trisat_nochain_lda_noivector_sp_ali/ali_f.pb
--------------------------------------------------------------------------------------
dataset                       	Œº     	med   	œÉ      | <10ms 	<25ms 	<50ms 	<100ms
--------------------------------------------------------------------------------------
ali_m                         	17.573	12.000	21.205 | 40.79%	78.60%	94.55%	98.88%	
ali_f                         	20.342	12.000	72.295 | 42.30%	80.37%	94.99%	98.57%	
--------------------------------------------------------------------------------------
[91m[2021-10-24 13:53:57] run_align.sh: success![0m
